{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAY9 DEEP LEARNING FULL CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada Day 9'a ait ders notları yazacağım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### DATA IMPUTATION (Boş verileri doldurmak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Çok Kullanılan Yöntemler<br>\n",
    "Lineer Regression (özellikle rakamlar için)<br>\n",
    "Ortalama<br>\n",
    "Median (Orta Değer)<br>\n",
    "Mode (En Çok Tekrar Eden)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"ExampleData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>YOE</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Height   YOE  Salary\n",
       "0    175.0   3.0     6.0\n",
       "1    168.0   4.0     9.0\n",
       "2    160.0  10.0    18.0\n",
       "3      NaN  15.0    25.0\n",
       "4    161.0   NaN    50.0\n",
       "5    162.0   5.0    10.0\n",
       "6    180.0   6.0    11.0\n",
       "7      NaN   7.0     NaN\n",
       "8    172.0   8.0    12.0\n",
       "9    170.0   9.0    14.0\n",
       "10   175.0   3.0     6.0\n",
       "11   168.0   4.0     9.0\n",
       "12   160.0  10.0    18.0\n",
       "13     NaN  15.0    25.0\n",
       "14   161.0   NaN    50.0\n",
       "15   162.0   5.0    10.0\n",
       "16   180.0   6.0    11.0\n",
       "17     NaN   7.0     NaN\n",
       "18   172.0   8.0    12.0\n",
       "19   170.0   9.0    14.0\n",
       "20   161.0   NaN    50.0\n",
       "21   162.0   5.0    10.0\n",
       "22   180.0   6.0    11.0\n",
       "23     NaN   7.0     NaN\n",
       "24   175.0   3.0     6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "imp=IterativeImputer(estimator=lr)\n",
    "imputed_data=imp.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165.275222</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>31.706376</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>169.720689</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.40191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>172.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>165.275222</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>31.706376</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>169.720689</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.40191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>172.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>31.706376</td>\n",
       "      <td>50.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>169.720689</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.40191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>175.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2\n",
       "0   175.000000   3.000000   6.00000\n",
       "1   168.000000   4.000000   9.00000\n",
       "2   160.000000  10.000000  18.00000\n",
       "3   165.275222  15.000000  25.00000\n",
       "4   161.000000  31.706376  50.00000\n",
       "5   162.000000   5.000000  10.00000\n",
       "6   180.000000   6.000000  11.00000\n",
       "7   169.720689   7.000000  12.40191\n",
       "8   172.000000   8.000000  12.00000\n",
       "9   170.000000   9.000000  14.00000\n",
       "10  175.000000   3.000000   6.00000\n",
       "11  168.000000   4.000000   9.00000\n",
       "12  160.000000  10.000000  18.00000\n",
       "13  165.275222  15.000000  25.00000\n",
       "14  161.000000  31.706376  50.00000\n",
       "15  162.000000   5.000000  10.00000\n",
       "16  180.000000   6.000000  11.00000\n",
       "17  169.720689   7.000000  12.40191\n",
       "18  172.000000   8.000000  12.00000\n",
       "19  170.000000   9.000000  14.00000\n",
       "20  161.000000  31.706376  50.00000\n",
       "21  162.000000   5.000000  10.00000\n",
       "22  180.000000   6.000000  11.00000\n",
       "23  169.720689   7.000000  12.40191\n",
       "24  175.000000   3.000000   6.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNNImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data2=knn.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>YOE</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>176.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>166.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>161.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>176.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>161.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>176.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height   YOE Salary\n",
       "0   175.0   3.0    6.0\n",
       "1   168.0   4.0    9.0\n",
       "2   160.0  10.0   18.0\n",
       "3   166.4  15.0   25.0\n",
       "4   161.0  11.8   50.0\n",
       "5   162.0   5.0   10.0\n",
       "6   180.0   6.0   11.0\n",
       "7   176.8   7.0   11.4\n",
       "8   172.0   8.0   12.0\n",
       "9   170.0   9.0   14.0\n",
       "10  175.0   3.0    6.0\n",
       "11  168.0   4.0    9.0\n",
       "12  160.0  10.0   18.0\n",
       "13  166.4  15.0   25.0\n",
       "14  161.0  11.8   50.0\n",
       "15  162.0   5.0   10.0\n",
       "16  180.0   6.0   11.0\n",
       "17  176.8   7.0   11.4\n",
       "18  172.0   8.0   12.0\n",
       "19  170.0   9.0   14.0\n",
       "20  161.0  11.8   50.0\n",
       "21  162.0   5.0   10.0\n",
       "22  180.0   6.0   11.0\n",
       "23  176.8   7.0   11.4\n",
       "24  175.0   3.0    6.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(imputed_data2, columns=[df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=SimpleImputer(strategy='mean') #median or #mode yazılarda da geçerli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data3=imp.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>YOE</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168.7</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.0</td>\n",
       "      <td>7.045455</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>168.7</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>168.7</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>161.0</td>\n",
       "      <td>7.045455</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>168.7</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>161.0</td>\n",
       "      <td>7.045455</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>168.7</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>17.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height        YOE     Salary\n",
       "0   175.0   3.000000   6.000000\n",
       "1   168.0   4.000000   9.000000\n",
       "2   160.0  10.000000  18.000000\n",
       "3   168.7  15.000000  25.000000\n",
       "4   161.0   7.045455  50.000000\n",
       "5   162.0   5.000000  10.000000\n",
       "6   180.0   6.000000  11.000000\n",
       "7   168.7   7.000000  17.590909\n",
       "8   172.0   8.000000  12.000000\n",
       "9   170.0   9.000000  14.000000\n",
       "10  175.0   3.000000   6.000000\n",
       "11  168.0   4.000000   9.000000\n",
       "12  160.0  10.000000  18.000000\n",
       "13  168.7  15.000000  25.000000\n",
       "14  161.0   7.045455  50.000000\n",
       "15  162.0   5.000000  10.000000\n",
       "16  180.0   6.000000  11.000000\n",
       "17  168.7   7.000000  17.590909\n",
       "18  172.0   8.000000  12.000000\n",
       "19  170.0   9.000000  14.000000\n",
       "20  161.0   7.045455  50.000000\n",
       "21  162.0   5.000000  10.000000\n",
       "22  180.0   6.000000  11.000000\n",
       "23  168.7   7.000000  17.590909\n",
       "24  175.0   3.000000   6.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(imputed_data3, columns=[df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install miceforest (tüm yöntemlerden en uygun hangisi ise onunla dolduruyor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=mf.ImputationKernel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>YOE</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>162.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>168.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>160.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>180.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>161.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>162.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>172.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>161.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>162.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>180.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>160.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Height   YOE  Salary\n",
       "0    175.0   3.0     6.0\n",
       "1    168.0   4.0     9.0\n",
       "2    160.0  10.0    18.0\n",
       "3    161.0  15.0    25.0\n",
       "4    161.0   3.0    50.0\n",
       "5    162.0   5.0    10.0\n",
       "6    180.0   6.0    11.0\n",
       "7    162.0   7.0    18.0\n",
       "8    172.0   8.0    12.0\n",
       "9    170.0   9.0    14.0\n",
       "10   175.0   3.0     6.0\n",
       "11   168.0   4.0     9.0\n",
       "12   160.0  10.0    18.0\n",
       "13   180.0  15.0    25.0\n",
       "14   161.0  15.0    50.0\n",
       "15   162.0   5.0    10.0\n",
       "16   180.0   6.0    11.0\n",
       "17   162.0   7.0     6.0\n",
       "18   172.0   8.0    12.0\n",
       "19   170.0   9.0    14.0\n",
       "20   161.0   6.0    50.0\n",
       "21   162.0   5.0    10.0\n",
       "22   180.0   6.0    11.0\n",
       "23   160.0   7.0     9.0\n",
       "24   175.0   3.0     6.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffil(axis=1)Sütunda(axis=0)Satırda İleriye doğru bir önceki ve bir sonrakine göre dolduruyor\n",
    "#bfil Geriye doğru bir önceki ve bir sonrakine göre dolduruyor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALING - NORMALIZATION - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Outcome', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yx=scale(x) #datayı -1 ve 1 arasında numaralandırıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075, ...,  0.20401277,\n",
       "         0.46849198,  1.4259954 ],\n",
       "       [-0.84488505, -1.12339636, -0.16054575, ..., -0.68442195,\n",
       "        -0.36506078, -0.19067191],\n",
       "       [ 1.23388019,  1.94372388, -0.26394125, ..., -1.10325546,\n",
       "         0.60439732, -0.10558415],\n",
       "       ...,\n",
       "       [ 0.3429808 ,  0.00330087,  0.14964075, ..., -0.73518964,\n",
       "        -0.68519336, -0.27575966],\n",
       "       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.24020459,\n",
       "        -0.37110101,  1.17073215],\n",
       "       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.20212881,\n",
       "        -0.47378505, -0.87137393]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.827813</td>\n",
       "      <td>-0.622642</td>\n",
       "      <td>0.356432</td>\n",
       "      <td>1.722735</td>\n",
       "      <td>0.870031</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>-0.908682</td>\n",
       "      <td>2.532136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.547919</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.046245</td>\n",
       "      <td>0.405445</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.610154</td>\n",
       "      <td>-0.398282</td>\n",
       "      <td>-0.531023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.342981</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.279594</td>\n",
       "      <td>-0.735190</td>\n",
       "      <td>-0.685193</td>\n",
       "      <td>-0.275760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>0.159787</td>\n",
       "      <td>-0.470732</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.240205</td>\n",
       "      <td>-0.371101</td>\n",
       "      <td>1.170732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.873019</td>\n",
       "      <td>0.046245</td>\n",
       "      <td>0.656358</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.202129</td>\n",
       "      <td>-0.473785</td>\n",
       "      <td>-0.871374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.639947  0.848324  0.149641  0.907270 -0.692891  0.204013  0.468492   \n",
       "1   -0.844885 -1.123396 -0.160546  0.530902 -0.692891 -0.684422 -0.365061   \n",
       "2    1.233880  1.943724 -0.263941 -1.288212 -0.692891 -1.103255  0.604397   \n",
       "3   -0.844885 -0.998208 -0.160546  0.154533  0.123302 -0.494043 -0.920763   \n",
       "4   -1.141852  0.504055 -1.504687  0.907270  0.765836  1.409746  5.484909   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  1.827813 -0.622642  0.356432  1.722735  0.870031  0.115169 -0.908682   \n",
       "764 -0.547919  0.034598  0.046245  0.405445 -0.692891  0.610154 -0.398282   \n",
       "765  0.342981  0.003301  0.149641  0.154533  0.279594 -0.735190 -0.685193   \n",
       "766 -0.844885  0.159787 -0.470732 -1.288212 -0.692891 -0.240205 -0.371101   \n",
       "767 -0.844885 -0.873019  0.046245  0.656358 -0.692891 -0.202129 -0.473785   \n",
       "\n",
       "            7  \n",
       "0    1.425995  \n",
       "1   -0.190672  \n",
       "2   -0.105584  \n",
       "3   -1.041549  \n",
       "4   -0.020496  \n",
       "..        ...  \n",
       "763  2.532136  \n",
       "764 -0.531023  \n",
       "765 -0.275760  \n",
       "766  1.170732  \n",
       "767 -0.871374  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(yx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedata=normalize(x) #datayı 0 ve 1 arasında numaralandırıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033552</td>\n",
       "      <td>0.827625</td>\n",
       "      <td>0.402628</td>\n",
       "      <td>0.195722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.279603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008424</td>\n",
       "      <td>0.716040</td>\n",
       "      <td>0.555984</td>\n",
       "      <td>0.244296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224079</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.261144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040398</td>\n",
       "      <td>0.924097</td>\n",
       "      <td>0.323181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.161591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.588467</td>\n",
       "      <td>0.436392</td>\n",
       "      <td>0.152076</td>\n",
       "      <td>0.621527</td>\n",
       "      <td>0.185797</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.138852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596386</td>\n",
       "      <td>0.174127</td>\n",
       "      <td>0.152361</td>\n",
       "      <td>0.731335</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.143655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.042321</td>\n",
       "      <td>0.427443</td>\n",
       "      <td>0.321640</td>\n",
       "      <td>0.203141</td>\n",
       "      <td>0.761779</td>\n",
       "      <td>0.139236</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.266623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.811526</td>\n",
       "      <td>0.465629</td>\n",
       "      <td>0.179600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244788</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.026915</td>\n",
       "      <td>0.651352</td>\n",
       "      <td>0.387582</td>\n",
       "      <td>0.123811</td>\n",
       "      <td>0.602905</td>\n",
       "      <td>0.141037</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.161492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.838285</td>\n",
       "      <td>0.399184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200257</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.312694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.736052</td>\n",
       "      <td>0.554018</td>\n",
       "      <td>0.245351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240602</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.182034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.033552  0.827625  0.402628  0.195722  0.000000  0.187893  0.003506   \n",
       "1    0.008424  0.716040  0.555984  0.244296  0.000000  0.224079  0.002957   \n",
       "2    0.040398  0.924097  0.323181  0.000000  0.000000  0.117658  0.003393   \n",
       "3    0.006612  0.588467  0.436392  0.152076  0.621527  0.185797  0.001104   \n",
       "4    0.000000  0.596386  0.174127  0.152361  0.731335  0.187622  0.009960   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  0.042321  0.427443  0.321640  0.203141  0.761779  0.139236  0.000724   \n",
       "764  0.013304  0.811526  0.465629  0.179600  0.000000  0.244788  0.002262   \n",
       "765  0.026915  0.651352  0.387582  0.123811  0.602905  0.141037  0.001319   \n",
       "766  0.006653  0.838285  0.399184  0.000000  0.000000  0.200257  0.002322   \n",
       "767  0.007915  0.736052  0.554018  0.245351  0.000000  0.240602  0.002493   \n",
       "\n",
       "            7  \n",
       "0    0.279603  \n",
       "1    0.261144  \n",
       "2    0.161591  \n",
       "3    0.138852  \n",
       "4    0.143655  \n",
       "..        ...  \n",
       "763  0.266623  \n",
       "764  0.179600  \n",
       "765  0.161492  \n",
       "766  0.312694  \n",
       "767  0.182034  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(normalizedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCS (Principle Component Analysis) Boyut Küçültme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-75.71465491, -35.95078264,  -7.26078895],\n",
       "       [-82.3582676 ,  28.90821322,  -5.49667139],\n",
       "       [-74.63064344, -67.90649647,  19.46180812],\n",
       "       ...,\n",
       "       [ 32.11319827,   3.3766648 ,  -1.58786446],\n",
       "       [-80.21449431, -14.18601977,  12.3512639 ],\n",
       "       [-81.30814972,  21.62149606,  -8.15276833]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.714655</td>\n",
       "      <td>-35.950783</td>\n",
       "      <td>-7.260789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-82.358268</td>\n",
       "      <td>28.908213</td>\n",
       "      <td>-5.496671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.630643</td>\n",
       "      <td>-67.906496</td>\n",
       "      <td>19.461808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.077423</td>\n",
       "      <td>34.898486</td>\n",
       "      <td>-0.053018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.743788</td>\n",
       "      <td>-2.746937</td>\n",
       "      <td>25.212859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>99.237881</td>\n",
       "      <td>25.080927</td>\n",
       "      <td>-19.534825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-78.641239</td>\n",
       "      <td>-7.688010</td>\n",
       "      <td>-4.137227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>32.113198</td>\n",
       "      <td>3.376665</td>\n",
       "      <td>-1.587864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-80.214494</td>\n",
       "      <td>-14.186020</td>\n",
       "      <td>12.351264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-81.308150</td>\n",
       "      <td>21.621496</td>\n",
       "      <td>-8.152768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2\n",
       "0   -75.714655 -35.950783  -7.260789\n",
       "1   -82.358268  28.908213  -5.496671\n",
       "2   -74.630643 -67.906496  19.461808\n",
       "3    11.077423  34.898486  -0.053018\n",
       "4    89.743788  -2.746937  25.212859\n",
       "..         ...        ...        ...\n",
       "763  99.237881  25.080927 -19.534825\n",
       "764 -78.641239  -7.688010  -4.137227\n",
       "765  32.113198   3.376665  -1.587864\n",
       "766 -80.214494 -14.186020  12.351264\n",
       "767 -81.308150  21.621496  -8.152768\n",
       "\n",
       "[768 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "      <th>PCA3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-75.714655</td>\n",
       "      <td>-35.950783</td>\n",
       "      <td>-7.260789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-82.358268</td>\n",
       "      <td>28.908213</td>\n",
       "      <td>-5.496671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.630643</td>\n",
       "      <td>-67.906496</td>\n",
       "      <td>19.461808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.077423</td>\n",
       "      <td>34.898486</td>\n",
       "      <td>-0.053018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.743788</td>\n",
       "      <td>-2.746937</td>\n",
       "      <td>25.212859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>99.237881</td>\n",
       "      <td>25.080927</td>\n",
       "      <td>-19.534825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-78.641239</td>\n",
       "      <td>-7.688010</td>\n",
       "      <td>-4.137227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>32.113198</td>\n",
       "      <td>3.376665</td>\n",
       "      <td>-1.587864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-80.214494</td>\n",
       "      <td>-14.186020</td>\n",
       "      <td>12.351264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-81.308150</td>\n",
       "      <td>21.621496</td>\n",
       "      <td>-8.152768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PCA1       PCA2       PCA3\n",
       "0   -75.714655 -35.950783  -7.260789\n",
       "1   -82.358268  28.908213  -5.496671\n",
       "2   -74.630643 -67.906496  19.461808\n",
       "3    11.077423  34.898486  -0.053018\n",
       "4    89.743788  -2.746937  25.212859\n",
       "..         ...        ...        ...\n",
       "763  99.237881  25.080927 -19.534825\n",
       "764 -78.641239  -7.688010  -4.137227\n",
       "765  32.113198   3.376665  -1.587864\n",
       "766 -80.214494 -14.186020  12.351264\n",
       "767 -81.308150  21.621496  -8.152768\n",
       "\n",
       "[768 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data2, columns=['PCA1','PCA2','PCA3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88854663, 0.06159078, 0.02579012])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759275372391601"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARTIFICAL NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Neural Networks Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Outcome', axis=1)\n",
    "y=df[['Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8]\n",
    "y=df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(80,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5805 - loss: 0.7437 - val_accuracy: 0.5584 - val_loss: 0.7655\n",
      "Epoch 2/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6653 - loss: 0.6824 - val_accuracy: 0.5714 - val_loss: 0.7026\n",
      "Epoch 3/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7030 - loss: 0.6026 - val_accuracy: 0.5519 - val_loss: 0.6752\n",
      "Epoch 4/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6437 - loss: 0.6171 - val_accuracy: 0.5844 - val_loss: 0.6969\n",
      "Epoch 5/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6475 - loss: 0.6442 - val_accuracy: 0.5779 - val_loss: 0.7086\n",
      "Epoch 6/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6822 - loss: 0.6049 - val_accuracy: 0.5844 - val_loss: 0.6354\n",
      "Epoch 7/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.6776 - loss: 0.5935 - val_accuracy: 0.5844 - val_loss: 0.6580\n",
      "Epoch 8/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.6718 - loss: 0.5861 - val_accuracy: 0.5909 - val_loss: 0.6438\n",
      "Epoch 9/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.6892 - loss: 0.5915 - val_accuracy: 0.6494 - val_loss: 0.6327\n",
      "Epoch 10/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.7029 - loss: 0.5816 - val_accuracy: 0.6558 - val_loss: 0.6167\n",
      "Epoch 11/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.6918 - loss: 0.5847 - val_accuracy: 0.5844 - val_loss: 0.6437\n",
      "Epoch 12/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.6762 - loss: 0.5940 - val_accuracy: 0.5584 - val_loss: 0.6708\n",
      "Epoch 13/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.6663 - loss: 0.5733 - val_accuracy: 0.6364 - val_loss: 0.6274\n",
      "Epoch 14/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7050 - loss: 0.5864 - val_accuracy: 0.6494 - val_loss: 0.6154\n",
      "Epoch 15/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.6898 - loss: 0.5990 - val_accuracy: 0.6623 - val_loss: 0.6354\n",
      "Epoch 16/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6677 - loss: 0.5701 - val_accuracy: 0.6753 - val_loss: 0.6427\n",
      "Epoch 17/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.7203 - loss: 0.5670 - val_accuracy: 0.6169 - val_loss: 0.6220\n",
      "Epoch 18/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.7043 - loss: 0.5781 - val_accuracy: 0.6494 - val_loss: 0.6238\n",
      "Epoch 19/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.7055 - loss: 0.5539 - val_accuracy: 0.6494 - val_loss: 0.6170\n",
      "Epoch 20/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.6882 - loss: 0.5714 - val_accuracy: 0.6948 - val_loss: 0.6285\n",
      "Epoch 21/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7427 - loss: 0.5429 - val_accuracy: 0.6688 - val_loss: 0.6195\n",
      "Epoch 22/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.6952 - loss: 0.5509 - val_accuracy: 0.6948 - val_loss: 0.6100\n",
      "Epoch 23/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7258 - loss: 0.5447 - val_accuracy: 0.5649 - val_loss: 0.6683\n",
      "Epoch 24/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.6200 - loss: 0.6145 - val_accuracy: 0.7013 - val_loss: 0.6195\n",
      "Epoch 25/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.6810 - loss: 0.5873 - val_accuracy: 0.6753 - val_loss: 0.6238\n",
      "Epoch 26/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.6687 - loss: 0.5866 - val_accuracy: 0.6688 - val_loss: 0.6673\n",
      "Epoch 27/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.6782 - loss: 0.5604 - val_accuracy: 0.6364 - val_loss: 0.6452\n",
      "Epoch 28/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.6554 - loss: 0.5904 - val_accuracy: 0.6753 - val_loss: 0.6478\n",
      "Epoch 29/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6988 - loss: 0.5604 - val_accuracy: 0.7143 - val_loss: 0.6128\n",
      "Epoch 30/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6530 - loss: 0.6125 - val_accuracy: 0.6753 - val_loss: 0.6720\n",
      "Epoch 31/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.7028 - loss: 0.5591 - val_accuracy: 0.6688 - val_loss: 0.6291\n",
      "Epoch 32/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.6931 - loss: 0.5607 - val_accuracy: 0.7078 - val_loss: 0.6156\n",
      "Epoch 33/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.6983 - loss: 0.5611 - val_accuracy: 0.6688 - val_loss: 0.6170\n",
      "Epoch 34/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6990 - loss: 0.5407 - val_accuracy: 0.6494 - val_loss: 0.6200\n",
      "Epoch 35/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.6905 - loss: 0.5274 - val_accuracy: 0.6753 - val_loss: 0.6369\n",
      "Epoch 36/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.7060 - loss: 0.5580 - val_accuracy: 0.7273 - val_loss: 0.6032\n",
      "Epoch 37/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.6979 - loss: 0.5373 - val_accuracy: 0.6688 - val_loss: 0.6110\n",
      "Epoch 38/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.7081 - loss: 0.5352 - val_accuracy: 0.6688 - val_loss: 0.6072\n",
      "Epoch 39/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.6773 - loss: 0.5459 - val_accuracy: 0.6818 - val_loss: 0.6097\n",
      "Epoch 40/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7086 - loss: 0.5240 - val_accuracy: 0.6818 - val_loss: 0.6096\n",
      "Epoch 41/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.7325 - loss: 0.5311 - val_accuracy: 0.6883 - val_loss: 0.5907\n",
      "Epoch 42/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.7240 - loss: 0.5327 - val_accuracy: 0.6948 - val_loss: 0.6180\n",
      "Epoch 43/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7352 - loss: 0.5233 - val_accuracy: 0.6688 - val_loss: 0.6469\n",
      "Epoch 44/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7399 - loss: 0.5310 - val_accuracy: 0.6818 - val_loss: 0.6045\n",
      "Epoch 45/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.7374 - loss: 0.5214 - val_accuracy: 0.6818 - val_loss: 0.6058\n",
      "Epoch 46/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.7228 - loss: 0.5246 - val_accuracy: 0.7013 - val_loss: 0.5842\n",
      "Epoch 47/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.7409 - loss: 0.5219 - val_accuracy: 0.7532 - val_loss: 0.5795\n",
      "Epoch 48/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7537 - loss: 0.5195 - val_accuracy: 0.7403 - val_loss: 0.5972\n",
      "Epoch 49/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.7050 - loss: 0.5437 - val_accuracy: 0.6883 - val_loss: 0.6115\n",
      "Epoch 50/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.7117 - loss: 0.5557 - val_accuracy: 0.7208 - val_loss: 0.5957\n",
      "Epoch 51/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7297 - loss: 0.5153 - val_accuracy: 0.7013 - val_loss: 0.5887\n",
      "Epoch 52/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.7297 - loss: 0.5313 - val_accuracy: 0.7338 - val_loss: 0.5669\n",
      "Epoch 53/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.7445 - loss: 0.4916 - val_accuracy: 0.7597 - val_loss: 0.5947\n",
      "Epoch 54/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.7440 - loss: 0.5089 - val_accuracy: 0.7143 - val_loss: 0.6134\n",
      "Epoch 55/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7835 - loss: 0.4859 - val_accuracy: 0.7403 - val_loss: 0.5799\n",
      "Epoch 56/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7625 - loss: 0.4832 - val_accuracy: 0.7078 - val_loss: 0.6040\n",
      "Epoch 57/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7431 - loss: 0.4839 - val_accuracy: 0.7403 - val_loss: 0.5927\n",
      "Epoch 58/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7668 - loss: 0.5031 - val_accuracy: 0.7273 - val_loss: 0.5566\n",
      "Epoch 59/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7300 - loss: 0.5236 - val_accuracy: 0.7532 - val_loss: 0.5899\n",
      "Epoch 60/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7175 - loss: 0.5259 - val_accuracy: 0.7143 - val_loss: 0.5645\n",
      "Epoch 61/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7185 - loss: 0.5086 - val_accuracy: 0.7013 - val_loss: 0.6287\n",
      "Epoch 62/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7451 - loss: 0.4794 - val_accuracy: 0.6818 - val_loss: 0.6572\n",
      "Epoch 63/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6975 - loss: 0.5398 - val_accuracy: 0.6623 - val_loss: 0.6232\n",
      "Epoch 64/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7140 - loss: 0.5034 - val_accuracy: 0.7078 - val_loss: 0.6107\n",
      "Epoch 65/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7214 - loss: 0.5069 - val_accuracy: 0.7078 - val_loss: 0.5986\n",
      "Epoch 66/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.5204 - val_accuracy: 0.7208 - val_loss: 0.6114\n",
      "Epoch 67/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7170 - loss: 0.5259 - val_accuracy: 0.7273 - val_loss: 0.6051\n",
      "Epoch 68/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7254 - loss: 0.5395 - val_accuracy: 0.7013 - val_loss: 0.6036\n",
      "Epoch 69/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7486 - loss: 0.5217 - val_accuracy: 0.7143 - val_loss: 0.5867\n",
      "Epoch 70/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7712 - loss: 0.4792 - val_accuracy: 0.7403 - val_loss: 0.5819\n",
      "Epoch 71/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.5142 - val_accuracy: 0.7273 - val_loss: 0.5918\n",
      "Epoch 72/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7733 - loss: 0.4702 - val_accuracy: 0.7403 - val_loss: 0.6000\n",
      "Epoch 73/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7637 - loss: 0.4930 - val_accuracy: 0.7273 - val_loss: 0.5832\n",
      "Epoch 74/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7429 - loss: 0.5148 - val_accuracy: 0.7013 - val_loss: 0.6367\n",
      "Epoch 75/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.5408 - val_accuracy: 0.7013 - val_loss: 0.6922\n",
      "Epoch 76/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7595 - loss: 0.5157 - val_accuracy: 0.6883 - val_loss: 0.6430\n",
      "Epoch 77/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.7452 - loss: 0.5094 - val_accuracy: 0.6753 - val_loss: 0.6230\n",
      "Epoch 78/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.7400 - loss: 0.5121 - val_accuracy: 0.6948 - val_loss: 0.6029\n",
      "Epoch 79/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.7125 - loss: 0.5333 - val_accuracy: 0.7208 - val_loss: 0.5637\n",
      "Epoch 80/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7323 - loss: 0.5194 - val_accuracy: 0.7468 - val_loss: 0.6006\n",
      "Epoch 81/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.7433 - loss: 0.4763 - val_accuracy: 0.7532 - val_loss: 0.5612\n",
      "Epoch 82/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7261 - loss: 0.4760 - val_accuracy: 0.7727 - val_loss: 0.5662\n",
      "Epoch 83/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7732 - loss: 0.4834 - val_accuracy: 0.7468 - val_loss: 0.5775\n",
      "Epoch 84/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7778 - loss: 0.4670 - val_accuracy: 0.7468 - val_loss: 0.5796\n",
      "Epoch 85/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.7494 - loss: 0.4743 - val_accuracy: 0.7532 - val_loss: 0.5867\n",
      "Epoch 86/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.7450 - loss: 0.4803 - val_accuracy: 0.7403 - val_loss: 0.6277\n",
      "Epoch 87/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.7665 - loss: 0.4660 - val_accuracy: 0.7857 - val_loss: 0.5538\n",
      "Epoch 88/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.7500 - loss: 0.4798 - val_accuracy: 0.7338 - val_loss: 0.5855\n",
      "Epoch 89/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.7309 - loss: 0.5046 - val_accuracy: 0.7468 - val_loss: 0.5655\n",
      "Epoch 90/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7456 - loss: 0.4899 - val_accuracy: 0.7403 - val_loss: 0.6160\n",
      "Epoch 91/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 0.7752 - loss: 0.4468 - val_accuracy: 0.7338 - val_loss: 0.5706\n",
      "Epoch 92/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.7398 - loss: 0.4891 - val_accuracy: 0.7013 - val_loss: 0.7153\n",
      "Epoch 93/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7472 - loss: 0.5167 - val_accuracy: 0.7597 - val_loss: 0.5854\n",
      "Epoch 94/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.7581 - loss: 0.4711 - val_accuracy: 0.7403 - val_loss: 0.5799\n",
      "Epoch 95/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7763 - loss: 0.4484 - val_accuracy: 0.7597 - val_loss: 0.6003\n",
      "Epoch 96/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7389 - loss: 0.4895 - val_accuracy: 0.7403 - val_loss: 0.5826\n",
      "Epoch 97/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.7524 - loss: 0.4777 - val_accuracy: 0.7013 - val_loss: 0.6492\n",
      "Epoch 98/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7494 - loss: 0.5002 - val_accuracy: 0.7078 - val_loss: 0.6201\n",
      "Epoch 99/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 0.7836 - loss: 0.4407 - val_accuracy: 0.7403 - val_loss: 0.6340\n",
      "Epoch 100/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7899 - loss: 0.4443 - val_accuracy: 0.7273 - val_loss: 0.5628\n",
      "Epoch 101/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7805 - loss: 0.4418 - val_accuracy: 0.7468 - val_loss: 0.6444\n",
      "Epoch 102/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7631 - loss: 0.4597 - val_accuracy: 0.7468 - val_loss: 0.5821\n",
      "Epoch 103/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7895 - loss: 0.4542 - val_accuracy: 0.7403 - val_loss: 0.6169\n",
      "Epoch 104/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7615 - loss: 0.4298 - val_accuracy: 0.7727 - val_loss: 0.5614\n",
      "Epoch 105/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7573 - loss: 0.4567 - val_accuracy: 0.7403 - val_loss: 0.5813\n",
      "Epoch 106/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.7810 - loss: 0.4274 - val_accuracy: 0.7857 - val_loss: 0.5870\n",
      "Epoch 107/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7767 - loss: 0.4259 - val_accuracy: 0.7922 - val_loss: 0.5749\n",
      "Epoch 108/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.7739 - loss: 0.4369 - val_accuracy: 0.7792 - val_loss: 0.5877\n",
      "Epoch 109/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7951 - loss: 0.4342 - val_accuracy: 0.7403 - val_loss: 0.6123\n",
      "Epoch 110/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7864 - loss: 0.4451 - val_accuracy: 0.7597 - val_loss: 0.5782\n",
      "Epoch 111/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7799 - loss: 0.4237 - val_accuracy: 0.7792 - val_loss: 0.5931\n",
      "Epoch 112/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8118 - loss: 0.4063 - val_accuracy: 0.7468 - val_loss: 0.5968\n",
      "Epoch 113/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.7765 - loss: 0.4335 - val_accuracy: 0.7662 - val_loss: 0.5596\n",
      "Epoch 114/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.4548 - val_accuracy: 0.7208 - val_loss: 0.6162\n",
      "Epoch 115/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7734 - loss: 0.4591 - val_accuracy: 0.7532 - val_loss: 0.6112\n",
      "Epoch 116/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.7823 - loss: 0.4373 - val_accuracy: 0.7532 - val_loss: 0.6098\n",
      "Epoch 117/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8043 - loss: 0.3770 - val_accuracy: 0.7597 - val_loss: 0.6026\n",
      "Epoch 118/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7498 - loss: 0.4890 - val_accuracy: 0.7662 - val_loss: 0.6396\n",
      "Epoch 119/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7777 - loss: 0.4137 - val_accuracy: 0.7468 - val_loss: 0.6582\n",
      "Epoch 120/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7629 - loss: 0.4272 - val_accuracy: 0.7013 - val_loss: 0.6398\n",
      "Epoch 121/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8029 - loss: 0.4167 - val_accuracy: 0.7532 - val_loss: 0.6418\n",
      "Epoch 122/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8036 - loss: 0.4427 - val_accuracy: 0.7727 - val_loss: 0.5824\n",
      "Epoch 123/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7716 - loss: 0.3929 - val_accuracy: 0.7662 - val_loss: 0.5897\n",
      "Epoch 124/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.8195 - loss: 0.3956 - val_accuracy: 0.7338 - val_loss: 0.6724\n",
      "Epoch 125/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7833 - loss: 0.4135 - val_accuracy: 0.7662 - val_loss: 0.6309\n",
      "Epoch 126/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7782 - loss: 0.4418 - val_accuracy: 0.7727 - val_loss: 0.6077\n",
      "Epoch 127/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.4093 - val_accuracy: 0.7208 - val_loss: 0.6262\n",
      "Epoch 128/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.8007 - loss: 0.3994 - val_accuracy: 0.7013 - val_loss: 0.6502\n",
      "Epoch 129/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7761 - loss: 0.4472 - val_accuracy: 0.7338 - val_loss: 0.6446\n",
      "Epoch 130/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8063 - loss: 0.3849 - val_accuracy: 0.7468 - val_loss: 0.6742\n",
      "Epoch 131/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8044 - loss: 0.3864 - val_accuracy: 0.7792 - val_loss: 0.6179\n",
      "Epoch 132/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8114 - loss: 0.3765 - val_accuracy: 0.6948 - val_loss: 0.6338\n",
      "Epoch 133/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.8279 - loss: 0.3789 - val_accuracy: 0.6753 - val_loss: 0.7135\n",
      "Epoch 134/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.7971 - loss: 0.3765 - val_accuracy: 0.7597 - val_loss: 0.5936\n",
      "Epoch 135/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8320 - loss: 0.3394 - val_accuracy: 0.7338 - val_loss: 0.6640\n",
      "Epoch 136/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8008 - loss: 0.3865 - val_accuracy: 0.7273 - val_loss: 0.6352\n",
      "Epoch 137/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8069 - loss: 0.3751 - val_accuracy: 0.7208 - val_loss: 0.6813\n",
      "Epoch 138/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.7908 - loss: 0.3882 - val_accuracy: 0.7727 - val_loss: 0.6104\n",
      "Epoch 139/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7911 - loss: 0.4097 - val_accuracy: 0.7468 - val_loss: 0.6293\n",
      "Epoch 140/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.7747 - loss: 0.4277 - val_accuracy: 0.7532 - val_loss: 0.6249\n",
      "Epoch 141/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.7827 - loss: 0.3999 - val_accuracy: 0.6948 - val_loss: 0.6401\n",
      "Epoch 142/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.7955 - loss: 0.3985 - val_accuracy: 0.7532 - val_loss: 0.6732\n",
      "Epoch 143/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8088 - loss: 0.3781 - val_accuracy: 0.7208 - val_loss: 0.6505\n",
      "Epoch 144/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.8201 - loss: 0.3746 - val_accuracy: 0.7078 - val_loss: 0.6775\n",
      "Epoch 145/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8030 - loss: 0.3797 - val_accuracy: 0.7403 - val_loss: 0.5697\n",
      "Epoch 146/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8202 - loss: 0.3840 - val_accuracy: 0.7792 - val_loss: 0.6120\n",
      "Epoch 147/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8127 - loss: 0.3725 - val_accuracy: 0.7597 - val_loss: 0.6009\n",
      "Epoch 148/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.3848 - val_accuracy: 0.7662 - val_loss: 0.5644\n",
      "Epoch 149/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8296 - loss: 0.3809 - val_accuracy: 0.7403 - val_loss: 0.7237\n",
      "Epoch 150/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.3750 - val_accuracy: 0.7403 - val_loss: 0.6392\n",
      "Epoch 151/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.8144 - loss: 0.3825 - val_accuracy: 0.6818 - val_loss: 0.7079\n",
      "Epoch 152/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.7890 - loss: 0.4068 - val_accuracy: 0.7468 - val_loss: 0.6251\n",
      "Epoch 153/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.4020 - val_accuracy: 0.7532 - val_loss: 0.6771\n",
      "Epoch 154/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.8270 - loss: 0.3547 - val_accuracy: 0.7662 - val_loss: 0.6967\n",
      "Epoch 155/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.8236 - loss: 0.3523 - val_accuracy: 0.7597 - val_loss: 0.6488\n",
      "Epoch 156/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8236 - loss: 0.3473 - val_accuracy: 0.7338 - val_loss: 0.7398\n",
      "Epoch 157/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.7880 - loss: 0.3846 - val_accuracy: 0.7662 - val_loss: 0.6390\n",
      "Epoch 158/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8133 - loss: 0.3698 - val_accuracy: 0.7727 - val_loss: 0.6898\n",
      "Epoch 159/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.8213 - loss: 0.3674 - val_accuracy: 0.7338 - val_loss: 0.8633\n",
      "Epoch 160/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.8166 - loss: 0.3553 - val_accuracy: 0.7468 - val_loss: 0.6957\n",
      "Epoch 161/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8345 - loss: 0.3476 - val_accuracy: 0.7662 - val_loss: 0.6579\n",
      "Epoch 162/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.8217 - loss: 0.3532 - val_accuracy: 0.7532 - val_loss: 0.7082\n",
      "Epoch 163/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.3512 - val_accuracy: 0.7727 - val_loss: 0.6711\n",
      "Epoch 164/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7979 - loss: 0.3829 - val_accuracy: 0.7468 - val_loss: 0.7042\n",
      "Epoch 165/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.8335 - loss: 0.3443 - val_accuracy: 0.7468 - val_loss: 0.6841\n",
      "Epoch 166/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.8471 - loss: 0.3400 - val_accuracy: 0.7922 - val_loss: 0.6887\n",
      "Epoch 167/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.8444 - loss: 0.3359 - val_accuracy: 0.7468 - val_loss: 0.7680\n",
      "Epoch 168/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8120 - loss: 0.3823 - val_accuracy: 0.7987 - val_loss: 0.6710\n",
      "Epoch 169/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.8403 - loss: 0.3683 - val_accuracy: 0.7597 - val_loss: 0.6690\n",
      "Epoch 170/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.8394 - loss: 0.3426 - val_accuracy: 0.7338 - val_loss: 0.7030\n",
      "Epoch 171/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.8368 - loss: 0.3617 - val_accuracy: 0.7792 - val_loss: 0.6506\n",
      "Epoch 172/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.8336 - loss: 0.3447 - val_accuracy: 0.7727 - val_loss: 0.6987\n",
      "Epoch 173/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.8402 - loss: 0.3304 - val_accuracy: 0.7532 - val_loss: 0.6225\n",
      "Epoch 174/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.8436 - loss: 0.3655 - val_accuracy: 0.7078 - val_loss: 0.7777\n",
      "Epoch 175/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.8314 - loss: 0.3486 - val_accuracy: 0.7597 - val_loss: 0.7003\n",
      "Epoch 176/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.8469 - loss: 0.3373 - val_accuracy: 0.7727 - val_loss: 0.7066\n",
      "Epoch 177/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.8461 - loss: 0.3187 - val_accuracy: 0.6688 - val_loss: 0.9266\n",
      "Epoch 178/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8222 - loss: 0.3663 - val_accuracy: 0.7532 - val_loss: 0.6164\n",
      "Epoch 179/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.8401 - loss: 0.3741 - val_accuracy: 0.7338 - val_loss: 0.8256\n",
      "Epoch 180/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.8157 - loss: 0.3657 - val_accuracy: 0.7727 - val_loss: 0.6592\n",
      "Epoch 181/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8570 - loss: 0.3274 - val_accuracy: 0.7532 - val_loss: 0.7515\n",
      "Epoch 182/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8279 - loss: 0.3589 - val_accuracy: 0.6753 - val_loss: 0.7526\n",
      "Epoch 183/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8431 - loss: 0.3301 - val_accuracy: 0.7468 - val_loss: 0.6918\n",
      "Epoch 184/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.8788 - loss: 0.3007 - val_accuracy: 0.7403 - val_loss: 0.7318\n",
      "Epoch 185/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.8566 - loss: 0.3028 - val_accuracy: 0.7273 - val_loss: 0.8073\n",
      "Epoch 186/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.8425 - loss: 0.3206 - val_accuracy: 0.7532 - val_loss: 0.7625\n",
      "Epoch 187/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8346 - loss: 0.3457 - val_accuracy: 0.7208 - val_loss: 0.8303\n",
      "Epoch 188/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.8243 - loss: 0.3148 - val_accuracy: 0.7208 - val_loss: 0.7857\n",
      "Epoch 189/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.8352 - loss: 0.3338 - val_accuracy: 0.7468 - val_loss: 0.8246\n",
      "Epoch 190/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.8582 - loss: 0.3198 - val_accuracy: 0.7857 - val_loss: 0.6713\n",
      "Epoch 191/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.8506 - loss: 0.3118 - val_accuracy: 0.7208 - val_loss: 0.7664\n",
      "Epoch 192/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.8301 - loss: 0.3420 - val_accuracy: 0.7532 - val_loss: 0.7303\n",
      "Epoch 193/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.8207 - loss: 0.3623 - val_accuracy: 0.7597 - val_loss: 0.7501\n",
      "Epoch 194/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3063 - val_accuracy: 0.7792 - val_loss: 0.7048\n",
      "Epoch 195/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8605 - loss: 0.3289 - val_accuracy: 0.7857 - val_loss: 0.7435\n",
      "Epoch 196/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.8596 - loss: 0.3119 - val_accuracy: 0.7792 - val_loss: 0.7066\n",
      "Epoch 197/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.8759 - loss: 0.2743 - val_accuracy: 0.7597 - val_loss: 0.7350\n",
      "Epoch 198/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.8422 - loss: 0.3221 - val_accuracy: 0.7403 - val_loss: 0.7796\n",
      "Epoch 199/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8524 - loss: 0.2951 - val_accuracy: 0.7532 - val_loss: 0.6990\n",
      "Epoch 200/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.8921 - loss: 0.2523 - val_accuracy: 0.7727 - val_loss: 0.7589\n",
      "Epoch 201/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8743 - loss: 0.2689 - val_accuracy: 0.7403 - val_loss: 0.7799\n",
      "Epoch 202/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.8705 - loss: 0.2866 - val_accuracy: 0.7338 - val_loss: 0.8959\n",
      "Epoch 203/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.8574 - loss: 0.3128 - val_accuracy: 0.7273 - val_loss: 0.8574\n",
      "Epoch 204/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8438 - loss: 0.3313 - val_accuracy: 0.7338 - val_loss: 0.7239\n",
      "Epoch 205/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8688 - loss: 0.2905 - val_accuracy: 0.7468 - val_loss: 0.8649\n",
      "Epoch 206/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.8600 - loss: 0.2921 - val_accuracy: 0.7338 - val_loss: 0.7848\n",
      "Epoch 207/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.8886 - loss: 0.2654 - val_accuracy: 0.7532 - val_loss: 0.8091\n",
      "Epoch 208/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2707 - val_accuracy: 0.7013 - val_loss: 0.9379\n",
      "Epoch 209/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.8819 - loss: 0.2734 - val_accuracy: 0.7468 - val_loss: 0.7774\n",
      "Epoch 210/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8742 - loss: 0.2651 - val_accuracy: 0.7468 - val_loss: 0.8992\n",
      "Epoch 211/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.8906 - loss: 0.2619 - val_accuracy: 0.7597 - val_loss: 0.7886\n",
      "Epoch 212/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.8895 - loss: 0.2509 - val_accuracy: 0.7273 - val_loss: 0.8569\n",
      "Epoch 213/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9047 - loss: 0.2433 - val_accuracy: 0.7338 - val_loss: 0.8290\n",
      "Epoch 214/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.8938 - loss: 0.2490 - val_accuracy: 0.7532 - val_loss: 0.9204\n",
      "Epoch 215/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.8753 - loss: 0.2445 - val_accuracy: 0.7403 - val_loss: 0.9188\n",
      "Epoch 216/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.8471 - loss: 0.3401 - val_accuracy: 0.7338 - val_loss: 0.6951\n",
      "Epoch 217/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.8653 - loss: 0.3206 - val_accuracy: 0.7208 - val_loss: 0.7147\n",
      "Epoch 218/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.8419 - loss: 0.3329 - val_accuracy: 0.7013 - val_loss: 0.8104\n",
      "Epoch 219/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8195 - loss: 0.3442 - val_accuracy: 0.7013 - val_loss: 0.7948\n",
      "Epoch 220/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.8550 - loss: 0.3283 - val_accuracy: 0.7727 - val_loss: 0.6964\n",
      "Epoch 221/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.2925 - val_accuracy: 0.7662 - val_loss: 0.7796\n",
      "Epoch 222/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.8897 - loss: 0.2690 - val_accuracy: 0.7403 - val_loss: 0.8162\n",
      "Epoch 223/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.8703 - loss: 0.2582 - val_accuracy: 0.7273 - val_loss: 0.7810\n",
      "Epoch 224/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9076 - loss: 0.2385 - val_accuracy: 0.7338 - val_loss: 0.8464\n",
      "Epoch 225/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8945 - loss: 0.2309 - val_accuracy: 0.7078 - val_loss: 0.8783\n",
      "Epoch 226/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9039 - loss: 0.2358 - val_accuracy: 0.7662 - val_loss: 0.8796\n",
      "Epoch 227/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.8809 - loss: 0.2340 - val_accuracy: 0.7273 - val_loss: 0.8499\n",
      "Epoch 228/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.8927 - loss: 0.2338 - val_accuracy: 0.7597 - val_loss: 0.8637\n",
      "Epoch 229/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8946 - loss: 0.2459 - val_accuracy: 0.7143 - val_loss: 0.9717\n",
      "Epoch 230/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.8910 - loss: 0.2404 - val_accuracy: 0.7208 - val_loss: 0.9707\n",
      "Epoch 231/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.8965 - loss: 0.2352 - val_accuracy: 0.7468 - val_loss: 0.8990\n",
      "Epoch 232/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9023 - loss: 0.2490 - val_accuracy: 0.7273 - val_loss: 0.9065\n",
      "Epoch 233/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9050 - loss: 0.2000 - val_accuracy: 0.7532 - val_loss: 0.9471\n",
      "Epoch 234/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.3082 - val_accuracy: 0.7208 - val_loss: 0.9557\n",
      "Epoch 235/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.8449 - loss: 0.3343 - val_accuracy: 0.7727 - val_loss: 0.8334\n",
      "Epoch 236/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8573 - loss: 0.3129 - val_accuracy: 0.7208 - val_loss: 0.8477\n",
      "Epoch 237/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8760 - loss: 0.2938 - val_accuracy: 0.7273 - val_loss: 0.8717\n",
      "Epoch 238/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8576 - loss: 0.2942 - val_accuracy: 0.6688 - val_loss: 0.9404\n",
      "Epoch 239/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.8638 - loss: 0.3022 - val_accuracy: 0.7208 - val_loss: 0.8955\n",
      "Epoch 240/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.8884 - loss: 0.2322 - val_accuracy: 0.7403 - val_loss: 0.8826\n",
      "Epoch 241/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9343 - loss: 0.1842 - val_accuracy: 0.7338 - val_loss: 0.8591\n",
      "Epoch 242/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9348 - loss: 0.1773 - val_accuracy: 0.7532 - val_loss: 0.9206\n",
      "Epoch 243/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.8772 - loss: 0.2469 - val_accuracy: 0.7468 - val_loss: 0.8585\n",
      "Epoch 244/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9156 - loss: 0.2030 - val_accuracy: 0.7532 - val_loss: 0.9340\n",
      "Epoch 245/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.9189 - loss: 0.2035 - val_accuracy: 0.7597 - val_loss: 0.9225\n",
      "Epoch 246/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9016 - loss: 0.2695 - val_accuracy: 0.7597 - val_loss: 0.9069\n",
      "Epoch 247/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.2347 - val_accuracy: 0.7338 - val_loss: 1.0272\n",
      "Epoch 248/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.9280 - loss: 0.1852 - val_accuracy: 0.7403 - val_loss: 0.9082\n",
      "Epoch 249/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9151 - loss: 0.2072 - val_accuracy: 0.7662 - val_loss: 0.9476\n",
      "Epoch 250/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9127 - loss: 0.2069 - val_accuracy: 0.7532 - val_loss: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30bed7920>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=250, batch_size=32, validation_split=.20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,950</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">620</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │         \u001b[38;5;34m1,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │         \u001b[38;5;34m9,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m5,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m1,950\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m620\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m84\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,811</span> (218.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,811\u001b[0m (218.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,603</span> (72.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,603\u001b[0m (72.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,208</span> (145.35 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m37,208\u001b[0m (145.35 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6769 - loss: 1.5162 - val_accuracy: 0.6558 - val_loss: 0.8669\n",
      "Epoch 2/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.6710 - loss: 0.7289 - val_accuracy: 0.6364 - val_loss: 0.6200\n",
      "Epoch 3/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7086 - loss: 0.5546 - val_accuracy: 0.6883 - val_loss: 0.5542\n",
      "Epoch 4/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.7401 - loss: 0.5089 - val_accuracy: 0.7597 - val_loss: 0.5013\n",
      "Epoch 5/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.7714 - loss: 0.4548 - val_accuracy: 0.7468 - val_loss: 0.5125\n",
      "Epoch 6/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7865 - loss: 0.4524 - val_accuracy: 0.7857 - val_loss: 0.4831\n",
      "Epoch 7/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8145 - loss: 0.4329 - val_accuracy: 0.7987 - val_loss: 0.4876\n",
      "Epoch 8/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8065 - loss: 0.4147 - val_accuracy: 0.8052 - val_loss: 0.4887\n",
      "Epoch 9/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8073 - loss: 0.4014 - val_accuracy: 0.7532 - val_loss: 0.5061\n",
      "Epoch 10/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.3732 - val_accuracy: 0.8182 - val_loss: 0.4778\n",
      "Epoch 11/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8187 - loss: 0.3877 - val_accuracy: 0.7727 - val_loss: 0.4949\n",
      "Epoch 12/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7864 - loss: 0.4162 - val_accuracy: 0.7338 - val_loss: 0.5240\n",
      "Epoch 13/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8184 - loss: 0.3986 - val_accuracy: 0.7922 - val_loss: 0.4945\n",
      "Epoch 14/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4046 - val_accuracy: 0.7662 - val_loss: 0.5103\n",
      "Epoch 15/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8121 - loss: 0.3985 - val_accuracy: 0.7922 - val_loss: 0.5166\n",
      "Epoch 16/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8311 - loss: 0.3796 - val_accuracy: 0.7662 - val_loss: 0.5322\n",
      "Epoch 17/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8021 - loss: 0.3970 - val_accuracy: 0.7662 - val_loss: 0.5197\n",
      "Epoch 18/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.3620 - val_accuracy: 0.7987 - val_loss: 0.5234\n",
      "Epoch 19/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8427 - loss: 0.3496 - val_accuracy: 0.8052 - val_loss: 0.5420\n",
      "Epoch 20/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.8441 - loss: 0.3680 - val_accuracy: 0.7792 - val_loss: 0.5195\n",
      "Epoch 21/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.8581 - loss: 0.3433 - val_accuracy: 0.7987 - val_loss: 0.5227\n",
      "Epoch 22/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.8761 - loss: 0.2882 - val_accuracy: 0.7987 - val_loss: 0.5314\n",
      "Epoch 23/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8838 - loss: 0.2838 - val_accuracy: 0.7792 - val_loss: 0.5453\n",
      "Epoch 24/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.8663 - loss: 0.3261 - val_accuracy: 0.7792 - val_loss: 0.5736\n",
      "Epoch 25/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.8666 - loss: 0.3250 - val_accuracy: 0.7857 - val_loss: 0.5793\n",
      "Epoch 26/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8852 - loss: 0.3007 - val_accuracy: 0.7987 - val_loss: 0.5515\n",
      "Epoch 27/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.8847 - loss: 0.2620 - val_accuracy: 0.7792 - val_loss: 0.5781\n",
      "Epoch 28/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8961 - loss: 0.2769 - val_accuracy: 0.7922 - val_loss: 0.5558\n",
      "Epoch 29/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9100 - loss: 0.2387 - val_accuracy: 0.7792 - val_loss: 0.6133\n",
      "Epoch 30/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8771 - loss: 0.2737 - val_accuracy: 0.7597 - val_loss: 0.6328\n",
      "Epoch 31/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.8804 - loss: 0.2830 - val_accuracy: 0.7597 - val_loss: 0.6230\n",
      "Epoch 32/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.8839 - loss: 0.2619 - val_accuracy: 0.7857 - val_loss: 0.6159\n",
      "Epoch 33/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.9027 - loss: 0.2390 - val_accuracy: 0.7922 - val_loss: 0.5931\n",
      "Epoch 34/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.8828 - loss: 0.2474 - val_accuracy: 0.7662 - val_loss: 0.6559\n",
      "Epoch 35/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9220 - loss: 0.2141 - val_accuracy: 0.7662 - val_loss: 0.6501\n",
      "Epoch 36/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2182 - val_accuracy: 0.7532 - val_loss: 0.7110\n",
      "Epoch 37/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9113 - loss: 0.2297 - val_accuracy: 0.7597 - val_loss: 0.6925\n",
      "Epoch 38/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9183 - loss: 0.2095 - val_accuracy: 0.7468 - val_loss: 0.6819\n",
      "Epoch 39/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.8969 - loss: 0.2791 - val_accuracy: 0.7727 - val_loss: 0.6774\n",
      "Epoch 40/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.9175 - loss: 0.2046 - val_accuracy: 0.7792 - val_loss: 0.6802\n",
      "Epoch 41/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9349 - loss: 0.1920 - val_accuracy: 0.7857 - val_loss: 0.6836\n",
      "Epoch 42/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.9220 - loss: 0.1989 - val_accuracy: 0.7727 - val_loss: 0.7395\n",
      "Epoch 43/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9341 - loss: 0.1860 - val_accuracy: 0.7468 - val_loss: 0.7477\n",
      "Epoch 44/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9505 - loss: 0.1577 - val_accuracy: 0.7792 - val_loss: 0.7352\n",
      "Epoch 45/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9438 - loss: 0.1523 - val_accuracy: 0.7857 - val_loss: 0.7531\n",
      "Epoch 46/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9421 - loss: 0.1776 - val_accuracy: 0.7597 - val_loss: 0.7935\n",
      "Epoch 47/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9524 - loss: 0.1375 - val_accuracy: 0.7468 - val_loss: 0.8104\n",
      "Epoch 48/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.9231 - loss: 0.1706 - val_accuracy: 0.7857 - val_loss: 0.7874\n",
      "Epoch 49/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9443 - loss: 0.1528 - val_accuracy: 0.7532 - val_loss: 0.8403\n",
      "Epoch 50/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9586 - loss: 0.1468 - val_accuracy: 0.7403 - val_loss: 0.8191\n",
      "Epoch 51/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9445 - loss: 0.1448 - val_accuracy: 0.7857 - val_loss: 0.8410\n",
      "Epoch 52/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1349 - val_accuracy: 0.7273 - val_loss: 0.8742\n",
      "Epoch 53/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9630 - loss: 0.1169 - val_accuracy: 0.7273 - val_loss: 0.9149\n",
      "Epoch 54/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9505 - loss: 0.1308 - val_accuracy: 0.7143 - val_loss: 0.9193\n",
      "Epoch 55/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9444 - loss: 0.2003 - val_accuracy: 0.7532 - val_loss: 0.8238\n",
      "Epoch 56/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9580 - loss: 0.1472 - val_accuracy: 0.7597 - val_loss: 0.7833\n",
      "Epoch 57/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9469 - loss: 0.1667 - val_accuracy: 0.7597 - val_loss: 0.8931\n",
      "Epoch 58/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1380 - val_accuracy: 0.7597 - val_loss: 0.8187\n",
      "Epoch 59/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9621 - loss: 0.1265 - val_accuracy: 0.7403 - val_loss: 0.8983\n",
      "Epoch 60/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9630 - loss: 0.1189 - val_accuracy: 0.7338 - val_loss: 0.9034\n",
      "Epoch 61/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9649 - loss: 0.1037 - val_accuracy: 0.7662 - val_loss: 0.9021\n",
      "Epoch 62/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9605 - loss: 0.1133 - val_accuracy: 0.7532 - val_loss: 0.9682\n",
      "Epoch 63/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.9510 - loss: 0.1316 - val_accuracy: 0.7403 - val_loss: 0.9004\n",
      "Epoch 64/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.9668 - loss: 0.1046 - val_accuracy: 0.7532 - val_loss: 0.8824\n",
      "Epoch 65/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9685 - loss: 0.0909 - val_accuracy: 0.7468 - val_loss: 0.9739\n",
      "Epoch 66/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9780 - loss: 0.0891 - val_accuracy: 0.7468 - val_loss: 0.9488\n",
      "Epoch 67/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9766 - loss: 0.0827 - val_accuracy: 0.7468 - val_loss: 1.0306\n",
      "Epoch 68/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9754 - loss: 0.0871 - val_accuracy: 0.7273 - val_loss: 1.0299\n",
      "Epoch 69/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9748 - loss: 0.0849 - val_accuracy: 0.7468 - val_loss: 1.0423\n",
      "Epoch 70/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9743 - loss: 0.0777 - val_accuracy: 0.7338 - val_loss: 1.0602\n",
      "Epoch 71/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9755 - loss: 0.0670 - val_accuracy: 0.7532 - val_loss: 1.1420\n",
      "Epoch 72/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9821 - loss: 0.0705 - val_accuracy: 0.7403 - val_loss: 1.0827\n",
      "Epoch 73/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9780 - loss: 0.0839 - val_accuracy: 0.7468 - val_loss: 1.1544\n",
      "Epoch 74/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9726 - loss: 0.0795 - val_accuracy: 0.6429 - val_loss: 1.4684\n",
      "Epoch 75/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9595 - loss: 0.1291 - val_accuracy: 0.6948 - val_loss: 1.1629\n",
      "Epoch 76/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9608 - loss: 0.1094 - val_accuracy: 0.7662 - val_loss: 1.1243\n",
      "Epoch 77/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 0.9750 - loss: 0.0868 - val_accuracy: 0.7403 - val_loss: 1.2079\n",
      "Epoch 78/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 0.9679 - loss: 0.1063 - val_accuracy: 0.7532 - val_loss: 1.1918\n",
      "Epoch 79/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.0746 - val_accuracy: 0.7532 - val_loss: 1.1733\n",
      "Epoch 80/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9806 - loss: 0.0724 - val_accuracy: 0.7597 - val_loss: 1.2246\n",
      "Epoch 81/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9890 - loss: 0.0511 - val_accuracy: 0.7403 - val_loss: 1.2443\n",
      "Epoch 82/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.9813 - loss: 0.0613 - val_accuracy: 0.7597 - val_loss: 1.3101\n",
      "Epoch 83/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.9802 - loss: 0.0824 - val_accuracy: 0.7468 - val_loss: 1.2771\n",
      "Epoch 84/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9918 - loss: 0.0543 - val_accuracy: 0.7468 - val_loss: 1.3505\n",
      "Epoch 85/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9865 - loss: 0.0678 - val_accuracy: 0.7468 - val_loss: 1.2782\n",
      "Epoch 86/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9723 - loss: 0.1004 - val_accuracy: 0.7208 - val_loss: 1.2660\n",
      "Epoch 87/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9507 - loss: 0.1512 - val_accuracy: 0.7597 - val_loss: 1.2339\n",
      "Epoch 88/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9775 - loss: 0.0789 - val_accuracy: 0.7338 - val_loss: 1.2319\n",
      "Epoch 89/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9612 - loss: 0.0994 - val_accuracy: 0.7338 - val_loss: 1.2812\n",
      "Epoch 90/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9528 - loss: 0.1243 - val_accuracy: 0.7597 - val_loss: 1.2184\n",
      "Epoch 91/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9873 - loss: 0.0736 - val_accuracy: 0.7403 - val_loss: 1.3319\n",
      "Epoch 92/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9826 - loss: 0.0742 - val_accuracy: 0.7468 - val_loss: 1.2782\n",
      "Epoch 93/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9748 - loss: 0.0792 - val_accuracy: 0.7597 - val_loss: 1.2824\n",
      "Epoch 94/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9862 - loss: 0.0649 - val_accuracy: 0.7273 - val_loss: 1.2895\n",
      "Epoch 95/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9925 - loss: 0.0476 - val_accuracy: 0.7338 - val_loss: 1.2565\n",
      "Epoch 96/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9929 - loss: 0.0432 - val_accuracy: 0.7338 - val_loss: 1.3300\n",
      "Epoch 97/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9959 - loss: 0.0430 - val_accuracy: 0.7338 - val_loss: 1.3274\n",
      "Epoch 98/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.9952 - loss: 0.0361 - val_accuracy: 0.7273 - val_loss: 1.3618\n",
      "Epoch 99/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9962 - loss: 0.0351 - val_accuracy: 0.7338 - val_loss: 1.3820\n",
      "Epoch 100/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9992 - loss: 0.0206 - val_accuracy: 0.7273 - val_loss: 1.3755\n",
      "Epoch 101/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9963 - loss: 0.0265 - val_accuracy: 0.7403 - val_loss: 1.3998\n",
      "Epoch 102/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9925 - loss: 0.0275 - val_accuracy: 0.7403 - val_loss: 1.4038\n",
      "Epoch 103/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9957 - loss: 0.0287 - val_accuracy: 0.7338 - val_loss: 1.4523\n",
      "Epoch 104/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9949 - loss: 0.0304 - val_accuracy: 0.7532 - val_loss: 1.4602\n",
      "Epoch 105/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9947 - loss: 0.0330 - val_accuracy: 0.7662 - val_loss: 1.4590\n",
      "Epoch 106/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9855 - loss: 0.0591 - val_accuracy: 0.7273 - val_loss: 1.4866\n",
      "Epoch 107/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9909 - loss: 0.0413 - val_accuracy: 0.7338 - val_loss: 1.5651\n",
      "Epoch 108/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9864 - loss: 0.0600 - val_accuracy: 0.7662 - val_loss: 1.5311\n",
      "Epoch 109/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9857 - loss: 0.0511 - val_accuracy: 0.7403 - val_loss: 1.5449\n",
      "Epoch 110/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9839 - loss: 0.0501 - val_accuracy: 0.7338 - val_loss: 1.5102\n",
      "Epoch 111/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9983 - loss: 0.0165 - val_accuracy: 0.7338 - val_loss: 1.5158\n",
      "Epoch 112/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9962 - loss: 0.0275 - val_accuracy: 0.7273 - val_loss: 1.5493\n",
      "Epoch 113/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9908 - loss: 0.0406 - val_accuracy: 0.7273 - val_loss: 1.5762\n",
      "Epoch 114/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9904 - loss: 0.0481 - val_accuracy: 0.7208 - val_loss: 1.6228\n",
      "Epoch 115/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9868 - loss: 0.0546 - val_accuracy: 0.7338 - val_loss: 1.6036\n",
      "Epoch 116/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9922 - loss: 0.0405 - val_accuracy: 0.7792 - val_loss: 1.6022\n",
      "Epoch 117/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.9919 - loss: 0.0573 - val_accuracy: 0.7273 - val_loss: 1.6529\n",
      "Epoch 118/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9914 - loss: 0.0502 - val_accuracy: 0.7532 - val_loss: 1.6068\n",
      "Epoch 119/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.9927 - loss: 0.0277 - val_accuracy: 0.7403 - val_loss: 1.6554\n",
      "Epoch 120/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9905 - loss: 0.0437 - val_accuracy: 0.7468 - val_loss: 1.6575\n",
      "Epoch 121/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9950 - loss: 0.0297 - val_accuracy: 0.7403 - val_loss: 1.6963\n",
      "Epoch 122/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9943 - loss: 0.0200 - val_accuracy: 0.7403 - val_loss: 1.6773\n",
      "Epoch 123/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9961 - loss: 0.0152 - val_accuracy: 0.7468 - val_loss: 1.7324\n",
      "Epoch 124/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9960 - loss: 0.0257 - val_accuracy: 0.7403 - val_loss: 1.7471\n",
      "Epoch 125/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.9964 - loss: 0.0189 - val_accuracy: 0.7273 - val_loss: 1.7905\n",
      "Epoch 126/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.9961 - loss: 0.0182 - val_accuracy: 0.7143 - val_loss: 1.8315\n",
      "Epoch 127/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9896 - loss: 0.0452 - val_accuracy: 0.7468 - val_loss: 1.7756\n",
      "Epoch 128/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9874 - loss: 0.0375 - val_accuracy: 0.7468 - val_loss: 1.7694\n",
      "Epoch 129/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9672 - loss: 0.1142 - val_accuracy: 0.7078 - val_loss: 1.7309\n",
      "Epoch 130/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9609 - loss: 0.1814 - val_accuracy: 0.7403 - val_loss: 1.7865\n",
      "Epoch 131/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9537 - loss: 0.1858 - val_accuracy: 0.7338 - val_loss: 1.4471\n",
      "Epoch 132/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.9474 - loss: 0.1697 - val_accuracy: 0.7013 - val_loss: 1.6226\n",
      "Epoch 133/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9473 - loss: 0.1508 - val_accuracy: 0.7273 - val_loss: 1.4497\n",
      "Epoch 134/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9819 - loss: 0.0539 - val_accuracy: 0.7468 - val_loss: 1.4558\n",
      "Epoch 135/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9914 - loss: 0.0403 - val_accuracy: 0.7597 - val_loss: 1.4550\n",
      "Epoch 136/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.9898 - loss: 0.0349 - val_accuracy: 0.7273 - val_loss: 1.5529\n",
      "Epoch 137/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.9958 - loss: 0.0241 - val_accuracy: 0.7338 - val_loss: 1.5393\n",
      "Epoch 138/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9933 - loss: 0.0287 - val_accuracy: 0.7403 - val_loss: 1.5909\n",
      "Epoch 139/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9937 - loss: 0.0390 - val_accuracy: 0.7468 - val_loss: 1.5969\n",
      "Epoch 140/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9995 - loss: 0.0125 - val_accuracy: 0.7403 - val_loss: 1.6314\n",
      "Epoch 141/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9974 - loss: 0.0174 - val_accuracy: 0.7468 - val_loss: 1.6400\n",
      "Epoch 142/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9951 - loss: 0.0254 - val_accuracy: 0.7403 - val_loss: 1.6789\n",
      "Epoch 143/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.9948 - loss: 0.0166 - val_accuracy: 0.7338 - val_loss: 1.7076\n",
      "Epoch 144/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9972 - loss: 0.0161 - val_accuracy: 0.7273 - val_loss: 1.7336\n",
      "Epoch 145/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9964 - loss: 0.0139 - val_accuracy: 0.7273 - val_loss: 1.7393\n",
      "Epoch 146/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.9956 - loss: 0.0240 - val_accuracy: 0.7403 - val_loss: 1.7560\n",
      "Epoch 147/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9995 - loss: 0.0077 - val_accuracy: 0.7468 - val_loss: 1.7817\n",
      "Epoch 148/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9952 - loss: 0.0187 - val_accuracy: 0.7403 - val_loss: 1.7939\n",
      "Epoch 149/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.9982 - loss: 0.0110 - val_accuracy: 0.7403 - val_loss: 1.8059\n",
      "Epoch 150/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0084 - val_accuracy: 0.7468 - val_loss: 1.8245\n",
      "Epoch 151/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.9984 - loss: 0.0103 - val_accuracy: 0.7273 - val_loss: 1.8474\n",
      "Epoch 152/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9988 - loss: 0.0117 - val_accuracy: 0.7273 - val_loss: 1.8692\n",
      "Epoch 153/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9995 - loss: 0.0091 - val_accuracy: 0.7338 - val_loss: 1.8854\n",
      "Epoch 154/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9968 - loss: 0.0156 - val_accuracy: 0.7403 - val_loss: 1.8872\n",
      "Epoch 155/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.9943 - loss: 0.0175 - val_accuracy: 0.7403 - val_loss: 1.9094\n",
      "Epoch 156/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9970 - loss: 0.0120 - val_accuracy: 0.7468 - val_loss: 1.9123\n",
      "Epoch 157/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9996 - loss: 0.0083 - val_accuracy: 0.7403 - val_loss: 1.9416\n",
      "Epoch 158/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 0.9996 - loss: 0.0070 - val_accuracy: 0.7468 - val_loss: 1.9399\n",
      "Epoch 159/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9995 - loss: 0.0074 - val_accuracy: 0.7273 - val_loss: 1.9722\n",
      "Epoch 160/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9995 - loss: 0.0063 - val_accuracy: 0.7338 - val_loss: 1.9787\n",
      "Epoch 161/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.9997 - loss: 0.0056 - val_accuracy: 0.7273 - val_loss: 1.9906\n",
      "Epoch 162/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.9998 - loss: 0.0055 - val_accuracy: 0.7338 - val_loss: 2.0039\n",
      "Epoch 163/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9996 - loss: 0.0055 - val_accuracy: 0.7338 - val_loss: 2.0248\n",
      "Epoch 164/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9973 - loss: 0.0115 - val_accuracy: 0.7273 - val_loss: 2.0469\n",
      "Epoch 165/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0136 - val_accuracy: 0.7338 - val_loss: 2.0549\n",
      "Epoch 166/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0049 - val_accuracy: 0.7338 - val_loss: 2.0668\n",
      "Epoch 167/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9994 - loss: 0.0049 - val_accuracy: 0.7338 - val_loss: 2.0960\n",
      "Epoch 168/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.7468 - val_loss: 2.0869\n",
      "Epoch 169/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9901 - loss: 0.0255 - val_accuracy: 0.7403 - val_loss: 2.1149\n",
      "Epoch 170/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.9934 - loss: 0.0281 - val_accuracy: 0.7338 - val_loss: 2.1169\n",
      "Epoch 171/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9737 - loss: 0.0614 - val_accuracy: 0.7338 - val_loss: 2.0969\n",
      "Epoch 172/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9679 - loss: 0.0796 - val_accuracy: 0.7273 - val_loss: 2.3264\n",
      "Epoch 173/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9717 - loss: 0.1033 - val_accuracy: 0.7078 - val_loss: 2.0502\n",
      "Epoch 174/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.9754 - loss: 0.0925 - val_accuracy: 0.7338 - val_loss: 1.7273\n",
      "Epoch 175/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 0.9664 - loss: 0.1322 - val_accuracy: 0.7078 - val_loss: 1.7780\n",
      "Epoch 176/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9557 - loss: 0.1942 - val_accuracy: 0.7532 - val_loss: 1.6076\n",
      "Epoch 177/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.9504 - loss: 0.1447 - val_accuracy: 0.7468 - val_loss: 1.4255\n",
      "Epoch 178/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9867 - loss: 0.0485 - val_accuracy: 0.7403 - val_loss: 1.4824\n",
      "Epoch 179/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.9969 - loss: 0.0247 - val_accuracy: 0.7403 - val_loss: 1.5342\n",
      "Epoch 180/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9894 - loss: 0.0369 - val_accuracy: 0.7208 - val_loss: 1.5077\n",
      "Epoch 181/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0253 - val_accuracy: 0.7403 - val_loss: 1.5344\n",
      "Epoch 182/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.9994 - loss: 0.0103 - val_accuracy: 0.7143 - val_loss: 1.6430\n",
      "Epoch 183/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9985 - loss: 0.0126 - val_accuracy: 0.7273 - val_loss: 1.6268\n",
      "Epoch 184/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0090 - val_accuracy: 0.7208 - val_loss: 1.6641\n",
      "Epoch 185/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0093 - val_accuracy: 0.7208 - val_loss: 1.6839\n",
      "Epoch 186/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9961 - loss: 0.0141 - val_accuracy: 0.7208 - val_loss: 1.7186\n",
      "Epoch 187/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.9977 - loss: 0.0108 - val_accuracy: 0.7273 - val_loss: 1.7215\n",
      "Epoch 188/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9995 - loss: 0.0064 - val_accuracy: 0.7143 - val_loss: 1.7669\n",
      "Epoch 189/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9978 - loss: 0.0092 - val_accuracy: 0.7078 - val_loss: 1.7568\n",
      "Epoch 190/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9928 - loss: 0.0191 - val_accuracy: 0.7273 - val_loss: 1.7731\n",
      "Epoch 191/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0164 - val_accuracy: 0.7143 - val_loss: 1.8266\n",
      "Epoch 192/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.7273 - val_loss: 1.8104\n",
      "Epoch 193/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.9988 - loss: 0.0065 - val_accuracy: 0.7208 - val_loss: 1.8290\n",
      "Epoch 194/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.9997 - loss: 0.0045 - val_accuracy: 0.7208 - val_loss: 1.8406\n",
      "Epoch 195/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.9997 - loss: 0.0039 - val_accuracy: 0.7273 - val_loss: 1.8559\n",
      "Epoch 196/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0053 - val_accuracy: 0.7208 - val_loss: 1.8853\n",
      "Epoch 197/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.7273 - val_loss: 1.8925\n",
      "Epoch 198/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.7273 - val_loss: 1.9066\n",
      "Epoch 199/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0121 - val_accuracy: 0.7273 - val_loss: 1.9206\n",
      "Epoch 200/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9991 - loss: 0.0039 - val_accuracy: 0.7273 - val_loss: 1.9264\n",
      "Epoch 201/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.9977 - loss: 0.0059 - val_accuracy: 0.7273 - val_loss: 1.9463\n",
      "Epoch 202/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9997 - loss: 0.0030 - val_accuracy: 0.7273 - val_loss: 1.9721\n",
      "Epoch 203/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.7273 - val_loss: 1.9823\n",
      "Epoch 204/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.9977 - loss: 0.0050 - val_accuracy: 0.7273 - val_loss: 2.0007\n",
      "Epoch 205/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.7273 - val_loss: 2.0206\n",
      "Epoch 206/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.7208 - val_loss: 2.0415\n",
      "Epoch 207/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9998 - loss: 0.0027 - val_accuracy: 0.7273 - val_loss: 2.0420\n",
      "Epoch 208/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9986 - loss: 0.0032 - val_accuracy: 0.7403 - val_loss: 2.0473\n",
      "Epoch 209/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7403 - val_loss: 2.0667\n",
      "Epoch 210/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7273 - val_loss: 2.0783\n",
      "Epoch 211/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7338 - val_loss: 2.1004\n",
      "Epoch 212/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7273 - val_loss: 2.0935\n",
      "Epoch 213/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.7338 - val_loss: 2.1735\n",
      "Epoch 214/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7338 - val_loss: 2.1260\n",
      "Epoch 215/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9975 - loss: 0.0061 - val_accuracy: 0.7273 - val_loss: 2.1208\n",
      "Epoch 216/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0079 - val_accuracy: 0.7338 - val_loss: 2.1902\n",
      "Epoch 217/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7338 - val_loss: 2.1396\n",
      "Epoch 218/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7403 - val_loss: 2.1630\n",
      "Epoch 219/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7208 - val_loss: 2.1609\n",
      "Epoch 220/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7208 - val_loss: 2.1795\n",
      "Epoch 221/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7338 - val_loss: 2.1868\n",
      "Epoch 222/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0034 - val_accuracy: 0.7338 - val_loss: 2.1919\n",
      "Epoch 223/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 0.7338 - val_loss: 2.1626\n",
      "Epoch 224/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9825 - loss: 0.0911 - val_accuracy: 0.7532 - val_loss: 2.1029\n",
      "Epoch 225/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9783 - loss: 0.0921 - val_accuracy: 0.6948 - val_loss: 1.9983\n",
      "Epoch 226/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9812 - loss: 0.0384 - val_accuracy: 0.7143 - val_loss: 2.0230\n",
      "Epoch 227/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9903 - loss: 0.0302 - val_accuracy: 0.7597 - val_loss: 1.7882\n",
      "Epoch 228/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0205 - val_accuracy: 0.7208 - val_loss: 1.8407\n",
      "Epoch 229/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9901 - loss: 0.0584 - val_accuracy: 0.7208 - val_loss: 1.9177\n",
      "Epoch 230/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0114 - val_accuracy: 0.7468 - val_loss: 1.8193\n",
      "Epoch 231/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0144 - val_accuracy: 0.7143 - val_loss: 1.9358\n",
      "Epoch 232/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.7338 - val_loss: 1.9123\n",
      "Epoch 233/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7338 - val_loss: 1.9370\n",
      "Epoch 234/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7338 - val_loss: 1.9644\n",
      "Epoch 235/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7338 - val_loss: 1.9858\n",
      "Epoch 236/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7338 - val_loss: 2.0093\n",
      "Epoch 237/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7273 - val_loss: 2.0342\n",
      "Epoch 238/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7273 - val_loss: 2.0489\n",
      "Epoch 239/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7273 - val_loss: 2.0689\n",
      "Epoch 240/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7273 - val_loss: 2.0776\n",
      "Epoch 241/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7273 - val_loss: 2.1036\n",
      "Epoch 242/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7273 - val_loss: 2.1174\n",
      "Epoch 243/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7273 - val_loss: 2.1293\n",
      "Epoch 244/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 9.7609e-04 - val_accuracy: 0.7273 - val_loss: 2.1427\n",
      "Epoch 245/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7273 - val_loss: 2.1540\n",
      "Epoch 246/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7338 - val_loss: 2.1717\n",
      "Epoch 247/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7338 - val_loss: 2.1837\n",
      "Epoch 248/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 9.3491e-04 - val_accuracy: 0.7338 - val_loss: 2.1941\n",
      "Epoch 249/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7338 - val_loss: 2.2047\n",
      "Epoch 250/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7338 - val_loss: 2.2097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30dcf3ec0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=250, batch_size=32, validation_split=.20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2649e-04 - val_accuracy: 0.7338 - val_loss: 2.2241\n",
      "Epoch 2/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.0440e-04 - val_accuracy: 0.7338 - val_loss: 2.2342\n",
      "Epoch 3/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.3577e-04 - val_accuracy: 0.7338 - val_loss: 2.2427\n",
      "Epoch 4/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.9279e-04 - val_accuracy: 0.7338 - val_loss: 2.2514\n",
      "Epoch 5/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.1319e-04 - val_accuracy: 0.7338 - val_loss: 2.2635\n",
      "Epoch 6/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.0409e-04 - val_accuracy: 0.7338 - val_loss: 2.2720\n",
      "Epoch 7/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step - accuracy: 1.0000 - loss: 6.3547e-04 - val_accuracy: 0.7403 - val_loss: 2.2801\n",
      "Epoch 8/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.6664e-04 - val_accuracy: 0.7338 - val_loss: 2.2902\n",
      "Epoch 9/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.3479e-04 - val_accuracy: 0.7338 - val_loss: 2.3181\n",
      "Epoch 10/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7403 - val_loss: 2.2856\n",
      "Epoch 11/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 1.0000 - loss: 6.3706e-04 - val_accuracy: 0.7338 - val_loss: 2.3190\n",
      "Epoch 12/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 1.0000 - loss: 8.4257e-04 - val_accuracy: 0.7338 - val_loss: 2.3415\n",
      "Epoch 13/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 1.0000 - loss: 7.6448e-04 - val_accuracy: 0.7403 - val_loss: 2.3298\n",
      "Epoch 14/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 8.1214e-04 - val_accuracy: 0.7403 - val_loss: 2.3428\n",
      "Epoch 15/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 6.7317e-04 - val_accuracy: 0.7403 - val_loss: 2.3549\n",
      "Epoch 16/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 4.7308e-04 - val_accuracy: 0.7338 - val_loss: 2.3633\n",
      "Epoch 17/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 4.8696e-04 - val_accuracy: 0.7403 - val_loss: 2.3688\n",
      "Epoch 18/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 7.0500e-04 - val_accuracy: 0.7403 - val_loss: 2.3812\n",
      "Epoch 19/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 3.2732e-04 - val_accuracy: 0.7403 - val_loss: 2.3879\n",
      "Epoch 20/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 4.9106e-04 - val_accuracy: 0.7403 - val_loss: 2.3909\n",
      "Epoch 21/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 6.5396e-04 - val_accuracy: 0.7403 - val_loss: 2.4020\n",
      "Epoch 22/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 4.2577e-04 - val_accuracy: 0.7403 - val_loss: 2.4104\n",
      "Epoch 23/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 1.0000 - loss: 4.1782e-04 - val_accuracy: 0.7403 - val_loss: 2.4179\n",
      "Epoch 24/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 3.6885e-04 - val_accuracy: 0.7403 - val_loss: 2.4244\n",
      "Epoch 25/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 3.7099e-04 - val_accuracy: 0.7403 - val_loss: 2.4308\n",
      "Epoch 26/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 3.7869e-04 - val_accuracy: 0.7403 - val_loss: 2.4413\n",
      "Epoch 27/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 4.5333e-04 - val_accuracy: 0.7403 - val_loss: 2.4443\n",
      "Epoch 28/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 3.3417e-04 - val_accuracy: 0.7403 - val_loss: 2.4532\n",
      "Epoch 29/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 4.7260e-04 - val_accuracy: 0.7403 - val_loss: 2.4571\n",
      "Epoch 30/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 4.5661e-04 - val_accuracy: 0.7403 - val_loss: 2.4658\n",
      "Epoch 31/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 3.9037e-04 - val_accuracy: 0.7403 - val_loss: 2.4720\n",
      "Epoch 32/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 3.8553e-04 - val_accuracy: 0.7403 - val_loss: 2.4790\n",
      "Epoch 33/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 2.6830e-04 - val_accuracy: 0.7403 - val_loss: 2.4887\n",
      "Epoch 34/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 3.8840e-04 - val_accuracy: 0.7403 - val_loss: 2.4910\n",
      "Epoch 35/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 2.8867e-04 - val_accuracy: 0.7403 - val_loss: 2.5019\n",
      "Epoch 36/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 3.2177e-04 - val_accuracy: 0.7403 - val_loss: 2.5001\n",
      "Epoch 37/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 3.2402e-04 - val_accuracy: 0.7403 - val_loss: 2.5123\n",
      "Epoch 38/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 3.7510e-04 - val_accuracy: 0.7403 - val_loss: 2.5194\n",
      "Epoch 39/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 2.7208e-04 - val_accuracy: 0.7403 - val_loss: 2.5274\n",
      "Epoch 40/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 3.6692e-04 - val_accuracy: 0.7403 - val_loss: 2.5355\n",
      "Epoch 41/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 1.9845e-04 - val_accuracy: 0.7403 - val_loss: 2.5418\n",
      "Epoch 42/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 2.0883e-04 - val_accuracy: 0.7403 - val_loss: 2.5451\n",
      "Epoch 43/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 3.0223e-04 - val_accuracy: 0.7403 - val_loss: 2.5523\n",
      "Epoch 44/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 2.3972e-04 - val_accuracy: 0.7403 - val_loss: 2.5598\n",
      "Epoch 45/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 3.0208e-04 - val_accuracy: 0.7403 - val_loss: 2.5646\n",
      "Epoch 46/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 2.6533e-04 - val_accuracy: 0.7403 - val_loss: 2.5707\n",
      "Epoch 47/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 2.3119e-04 - val_accuracy: 0.7403 - val_loss: 2.5768\n",
      "Epoch 48/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 2.3332e-04 - val_accuracy: 0.7403 - val_loss: 2.5850\n",
      "Epoch 49/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 2.7030e-04 - val_accuracy: 0.7403 - val_loss: 2.5891\n",
      "Epoch 50/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 3.1561e-04 - val_accuracy: 0.7403 - val_loss: 2.5961\n",
      "Epoch 51/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 2.2593e-04 - val_accuracy: 0.7403 - val_loss: 2.6013\n",
      "Epoch 52/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 2.3700e-04 - val_accuracy: 0.7403 - val_loss: 2.6049\n",
      "Epoch 53/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 2.0745e-04 - val_accuracy: 0.7403 - val_loss: 2.6129\n",
      "Epoch 54/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 2.4745e-04 - val_accuracy: 0.7403 - val_loss: 2.6212\n",
      "Epoch 55/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 1.9530e-04 - val_accuracy: 0.7403 - val_loss: 2.6260\n",
      "Epoch 56/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 2.2146e-04 - val_accuracy: 0.7403 - val_loss: 2.6298\n",
      "Epoch 57/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 2.2798e-04 - val_accuracy: 0.7403 - val_loss: 2.6359\n",
      "Epoch 58/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 1.8736e-04 - val_accuracy: 0.7403 - val_loss: 2.6430\n",
      "Epoch 59/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 1.8547e-04 - val_accuracy: 0.7403 - val_loss: 2.6495\n",
      "Epoch 60/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6226e-04 - val_accuracy: 0.7403 - val_loss: 2.6555\n",
      "Epoch 61/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9897e-04 - val_accuracy: 0.7403 - val_loss: 2.6564\n",
      "Epoch 62/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 1.0000 - loss: 2.3662e-04 - val_accuracy: 0.7403 - val_loss: 2.6645\n",
      "Epoch 63/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 1.0000 - loss: 1.7360e-04 - val_accuracy: 0.7403 - val_loss: 2.6704\n",
      "Epoch 64/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 1.9841e-04 - val_accuracy: 0.7403 - val_loss: 2.6763\n",
      "Epoch 65/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 1.5494e-04 - val_accuracy: 0.7403 - val_loss: 2.6839\n",
      "Epoch 66/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 1.9324e-04 - val_accuracy: 0.7403 - val_loss: 2.6925\n",
      "Epoch 67/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.8457e-04 - val_accuracy: 0.7403 - val_loss: 2.6965\n",
      "Epoch 68/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.9283e-04 - val_accuracy: 0.7403 - val_loss: 2.7028\n",
      "Epoch 69/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 1.3679e-04 - val_accuracy: 0.7403 - val_loss: 2.7063\n",
      "Epoch 70/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 2.0497e-04 - val_accuracy: 0.7403 - val_loss: 2.7125\n",
      "Epoch 71/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.3281e-04 - val_accuracy: 0.7403 - val_loss: 2.7159\n",
      "Epoch 72/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 1.2272e-04 - val_accuracy: 0.7403 - val_loss: 2.7213\n",
      "Epoch 73/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 1.5075e-04 - val_accuracy: 0.7403 - val_loss: 2.7283\n",
      "Epoch 74/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 1.3939e-04 - val_accuracy: 0.7403 - val_loss: 2.7309\n",
      "Epoch 75/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 1.4056e-04 - val_accuracy: 0.7403 - val_loss: 2.7383\n",
      "Epoch 76/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.6781e-04 - val_accuracy: 0.7403 - val_loss: 2.7362\n",
      "Epoch 77/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.6415e-04 - val_accuracy: 0.7403 - val_loss: 2.7496\n",
      "Epoch 78/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 2.1783e-04 - val_accuracy: 0.7403 - val_loss: 2.7543\n",
      "Epoch 79/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5880e-04 - val_accuracy: 0.7403 - val_loss: 2.7628\n",
      "Epoch 80/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 1.3493e-04 - val_accuracy: 0.7403 - val_loss: 2.7627\n",
      "Epoch 81/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.1994e-04 - val_accuracy: 0.7403 - val_loss: 2.7701\n",
      "Epoch 82/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 1.3960e-04 - val_accuracy: 0.7403 - val_loss: 2.7751\n",
      "Epoch 83/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.1138e-04 - val_accuracy: 0.7403 - val_loss: 2.7810\n",
      "Epoch 84/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.2895e-04 - val_accuracy: 0.7403 - val_loss: 2.7861\n",
      "Epoch 85/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 1.1043e-04 - val_accuracy: 0.7403 - val_loss: 2.7909\n",
      "Epoch 86/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 1.0856e-04 - val_accuracy: 0.7403 - val_loss: 2.7993\n",
      "Epoch 87/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.2638e-04 - val_accuracy: 0.7403 - val_loss: 2.8017\n",
      "Epoch 88/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 1.0891e-04 - val_accuracy: 0.7403 - val_loss: 2.8076\n",
      "Epoch 89/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.3063e-04 - val_accuracy: 0.7403 - val_loss: 2.8154\n",
      "Epoch 90/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.5838e-04 - val_accuracy: 0.7403 - val_loss: 2.8318\n",
      "Epoch 91/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 2.1978e-04 - val_accuracy: 0.7403 - val_loss: 2.8137\n",
      "Epoch 92/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 1.4821e-04 - val_accuracy: 0.7403 - val_loss: 2.8317\n",
      "Epoch 93/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.2529e-04 - val_accuracy: 0.7403 - val_loss: 2.8497\n",
      "Epoch 94/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.2758e-04 - val_accuracy: 0.7403 - val_loss: 2.8465\n",
      "Epoch 95/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 8.7587e-05 - val_accuracy: 0.7403 - val_loss: 2.8471\n",
      "Epoch 96/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 1.0998e-04 - val_accuracy: 0.7403 - val_loss: 2.8519\n",
      "Epoch 97/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.9881e-05 - val_accuracy: 0.7403 - val_loss: 2.8583\n",
      "Epoch 98/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.2720e-04 - val_accuracy: 0.7403 - val_loss: 2.8624\n",
      "Epoch 99/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 8.5103e-05 - val_accuracy: 0.7403 - val_loss: 2.8688\n",
      "Epoch 100/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.1953e-04 - val_accuracy: 0.7403 - val_loss: 2.8699\n",
      "Epoch 101/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 7.4724e-05 - val_accuracy: 0.7403 - val_loss: 2.8761\n",
      "Epoch 102/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 1.1495e-04 - val_accuracy: 0.7403 - val_loss: 2.8813\n",
      "Epoch 103/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 8.4014e-05 - val_accuracy: 0.7403 - val_loss: 2.8858\n",
      "Epoch 104/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 9.8995e-05 - val_accuracy: 0.7403 - val_loss: 2.8904\n",
      "Epoch 105/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.0904e-04 - val_accuracy: 0.7403 - val_loss: 2.8955\n",
      "Epoch 106/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 9.9485e-05 - val_accuracy: 0.7403 - val_loss: 2.9008\n",
      "Epoch 107/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 8.8143e-05 - val_accuracy: 0.7403 - val_loss: 2.9064\n",
      "Epoch 108/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 9.8785e-05 - val_accuracy: 0.7403 - val_loss: 2.9095\n",
      "Epoch 109/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 9.3542e-05 - val_accuracy: 0.7403 - val_loss: 2.9147\n",
      "Epoch 110/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 6.9071e-05 - val_accuracy: 0.7403 - val_loss: 2.9189\n",
      "Epoch 111/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.0807e-04 - val_accuracy: 0.7403 - val_loss: 2.9299\n",
      "Epoch 112/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 8.8194e-05 - val_accuracy: 0.7403 - val_loss: 2.9322\n",
      "Epoch 113/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.1044e-04 - val_accuracy: 0.7403 - val_loss: 2.9386\n",
      "Epoch 114/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 9.0442e-05 - val_accuracy: 0.7403 - val_loss: 2.9415\n",
      "Epoch 115/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.9023e-05 - val_accuracy: 0.7403 - val_loss: 2.9466\n",
      "Epoch 116/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 8.6920e-05 - val_accuracy: 0.7403 - val_loss: 2.9524\n",
      "Epoch 117/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 5.8082e-05 - val_accuracy: 0.7403 - val_loss: 2.9539\n",
      "Epoch 118/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 7.8998e-05 - val_accuracy: 0.7403 - val_loss: 2.9640\n",
      "Epoch 119/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 7.3783e-05 - val_accuracy: 0.7403 - val_loss: 2.9655\n",
      "Epoch 120/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 6.6575e-05 - val_accuracy: 0.7403 - val_loss: 2.9708\n",
      "Epoch 121/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 6.6361e-05 - val_accuracy: 0.7403 - val_loss: 2.9753\n",
      "Epoch 122/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 6.0506e-05 - val_accuracy: 0.7403 - val_loss: 2.9805\n",
      "Epoch 123/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 5.9283e-05 - val_accuracy: 0.7403 - val_loss: 2.9807\n",
      "Epoch 124/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9311e-05 - val_accuracy: 0.7403 - val_loss: 2.9867\n",
      "Epoch 125/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.2460e-05 - val_accuracy: 0.7403 - val_loss: 2.9944\n",
      "Epoch 126/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.7137e-05 - val_accuracy: 0.7403 - val_loss: 2.9987\n",
      "Epoch 127/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.1586e-05 - val_accuracy: 0.7403 - val_loss: 3.0019\n",
      "Epoch 128/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.3679e-05 - val_accuracy: 0.7403 - val_loss: 3.0099\n",
      "Epoch 129/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.1605e-05 - val_accuracy: 0.7403 - val_loss: 3.0144\n",
      "Epoch 130/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.6072e-05 - val_accuracy: 0.7403 - val_loss: 3.0189\n",
      "Epoch 131/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0552e-05 - val_accuracy: 0.7403 - val_loss: 3.0227\n",
      "Epoch 132/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2859e-05 - val_accuracy: 0.7403 - val_loss: 3.0264\n",
      "Epoch 133/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0060e-05 - val_accuracy: 0.7403 - val_loss: 3.0331\n",
      "Epoch 134/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.9380e-05 - val_accuracy: 0.7403 - val_loss: 3.0365\n",
      "Epoch 135/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 5.7596e-05 - val_accuracy: 0.7403 - val_loss: 3.0396\n",
      "Epoch 136/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.4469e-05 - val_accuracy: 0.7403 - val_loss: 3.0438\n",
      "Epoch 137/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 7.2456e-05 - val_accuracy: 0.7403 - val_loss: 3.0486\n",
      "Epoch 138/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 6.1872e-05 - val_accuracy: 0.7403 - val_loss: 3.0506\n",
      "Epoch 139/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 5.4984e-05 - val_accuracy: 0.7403 - val_loss: 3.0554\n",
      "Epoch 140/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 5.5025e-05 - val_accuracy: 0.7403 - val_loss: 3.0649\n",
      "Epoch 141/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 5.3780e-05 - val_accuracy: 0.7403 - val_loss: 3.0696\n",
      "Epoch 142/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 5.7062e-05 - val_accuracy: 0.7403 - val_loss: 3.0728\n",
      "Epoch 143/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 6.0499e-05 - val_accuracy: 0.7403 - val_loss: 3.0781\n",
      "Epoch 144/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 6.6561e-05 - val_accuracy: 0.7403 - val_loss: 3.0856\n",
      "Epoch 145/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 4.1390e-05 - val_accuracy: 0.7403 - val_loss: 3.0870\n",
      "Epoch 146/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 4.8555e-05 - val_accuracy: 0.7403 - val_loss: 3.0910\n",
      "Epoch 147/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 3.8442e-05 - val_accuracy: 0.7403 - val_loss: 3.0990\n",
      "Epoch 148/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 5.8533e-05 - val_accuracy: 0.7403 - val_loss: 3.1011\n",
      "Epoch 149/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 5.6789e-05 - val_accuracy: 0.7403 - val_loss: 3.1040\n",
      "Epoch 150/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 4.0210e-05 - val_accuracy: 0.7403 - val_loss: 3.1120\n",
      "Epoch 151/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 6.2525e-05 - val_accuracy: 0.7403 - val_loss: 3.1085\n",
      "Epoch 152/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 6.6136e-05 - val_accuracy: 0.7403 - val_loss: 3.1180\n",
      "Epoch 153/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 4.0577e-05 - val_accuracy: 0.7403 - val_loss: 3.1266\n",
      "Epoch 154/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 3.7405e-05 - val_accuracy: 0.7403 - val_loss: 3.1289\n",
      "Epoch 155/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 4.3494e-05 - val_accuracy: 0.7403 - val_loss: 3.1363\n",
      "Epoch 156/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 3.8161e-05 - val_accuracy: 0.7403 - val_loss: 3.1410\n",
      "Epoch 157/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 4.6058e-05 - val_accuracy: 0.7403 - val_loss: 3.1450\n",
      "Epoch 158/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 4.3717e-05 - val_accuracy: 0.7403 - val_loss: 3.1486\n",
      "Epoch 159/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 4.6572e-05 - val_accuracy: 0.7403 - val_loss: 3.1524\n",
      "Epoch 160/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 4.1640e-05 - val_accuracy: 0.7403 - val_loss: 3.1564\n",
      "Epoch 161/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 4.1056e-05 - val_accuracy: 0.7403 - val_loss: 3.1619\n",
      "Epoch 162/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 3.7821e-05 - val_accuracy: 0.7403 - val_loss: 3.1662\n",
      "Epoch 163/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 4.4411e-05 - val_accuracy: 0.7403 - val_loss: 3.1709\n",
      "Epoch 164/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 3.1336e-05 - val_accuracy: 0.7403 - val_loss: 3.1756\n",
      "Epoch 165/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 3.1512e-05 - val_accuracy: 0.7403 - val_loss: 3.1806\n",
      "Epoch 166/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8532e-05 - val_accuracy: 0.7403 - val_loss: 3.1835\n",
      "Epoch 167/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 4.1645e-05 - val_accuracy: 0.7403 - val_loss: 3.1883\n",
      "Epoch 168/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 5.9995e-05 - val_accuracy: 0.7403 - val_loss: 3.1938\n",
      "Epoch 169/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 4.0888e-05 - val_accuracy: 0.7403 - val_loss: 3.1980\n",
      "Epoch 170/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 3.1933e-05 - val_accuracy: 0.7403 - val_loss: 3.2007\n",
      "Epoch 171/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 4.8509e-05 - val_accuracy: 0.7403 - val_loss: 3.2046\n",
      "Epoch 172/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 3.8023e-05 - val_accuracy: 0.7403 - val_loss: 3.2086\n",
      "Epoch 173/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 2.7855e-05 - val_accuracy: 0.7403 - val_loss: 3.2166\n",
      "Epoch 174/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 3.0231e-05 - val_accuracy: 0.7403 - val_loss: 3.2217\n",
      "Epoch 175/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 3.2171e-05 - val_accuracy: 0.7403 - val_loss: 3.2244\n",
      "Epoch 176/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 4.0324e-05 - val_accuracy: 0.7403 - val_loss: 3.2262\n",
      "Epoch 177/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 4.4447e-05 - val_accuracy: 0.7403 - val_loss: 3.2332\n",
      "Epoch 178/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 2.8343e-05 - val_accuracy: 0.7403 - val_loss: 3.2359\n",
      "Epoch 179/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 3.3683e-05 - val_accuracy: 0.7403 - val_loss: 3.2418\n",
      "Epoch 180/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 3.7021e-05 - val_accuracy: 0.7403 - val_loss: 3.2469\n",
      "Epoch 181/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.0728e-05 - val_accuracy: 0.7403 - val_loss: 3.2501\n",
      "Epoch 182/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 3.5405e-05 - val_accuracy: 0.7403 - val_loss: 3.2517\n",
      "Epoch 183/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 2.5854e-05 - val_accuracy: 0.7338 - val_loss: 3.2613\n",
      "Epoch 184/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 2.3365e-05 - val_accuracy: 0.7403 - val_loss: 3.2612\n",
      "Epoch 185/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 3.1651e-05 - val_accuracy: 0.7403 - val_loss: 3.2674\n",
      "Epoch 186/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 3.1606e-05 - val_accuracy: 0.7403 - val_loss: 3.2713\n",
      "Epoch 187/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 2.7104e-05 - val_accuracy: 0.7403 - val_loss: 3.2773\n",
      "Epoch 188/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 3.0486e-05 - val_accuracy: 0.7403 - val_loss: 3.2765\n",
      "Epoch 189/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 2.8100e-05 - val_accuracy: 0.7403 - val_loss: 3.2846\n",
      "Epoch 190/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 2.6380e-05 - val_accuracy: 0.7403 - val_loss: 3.2884\n",
      "Epoch 191/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 2.4567e-05 - val_accuracy: 0.7403 - val_loss: 3.2929\n",
      "Epoch 192/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 3.9981e-05 - val_accuracy: 0.7403 - val_loss: 3.2988\n",
      "Epoch 193/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 2.9813e-05 - val_accuracy: 0.7403 - val_loss: 3.3023\n",
      "Epoch 194/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8801e-05 - val_accuracy: 0.7403 - val_loss: 3.3077\n",
      "Epoch 195/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 3.8775e-05 - val_accuracy: 0.7403 - val_loss: 3.3068\n",
      "Epoch 196/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 4.8480e-05 - val_accuracy: 0.7338 - val_loss: 3.3182\n",
      "Epoch 197/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 2.7362e-05 - val_accuracy: 0.7338 - val_loss: 3.3214\n",
      "Epoch 198/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 2.7225e-05 - val_accuracy: 0.7338 - val_loss: 3.3248\n",
      "Epoch 199/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.7074e-05 - val_accuracy: 0.7338 - val_loss: 3.3306\n",
      "Epoch 200/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 1.9470e-05 - val_accuracy: 0.7338 - val_loss: 3.3352\n",
      "Epoch 201/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 1.8773e-05 - val_accuracy: 0.7403 - val_loss: 3.3402\n",
      "Epoch 202/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 2.5252e-05 - val_accuracy: 0.7403 - val_loss: 3.3453\n",
      "Epoch 203/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 2.4236e-05 - val_accuracy: 0.7338 - val_loss: 3.3518\n",
      "Epoch 204/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 2.3300e-05 - val_accuracy: 0.7338 - val_loss: 3.3549\n",
      "Epoch 205/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 2.3476e-05 - val_accuracy: 0.7338 - val_loss: 3.3604\n",
      "Epoch 206/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 2.3106e-05 - val_accuracy: 0.7338 - val_loss: 3.3634\n",
      "Epoch 207/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 2.0900e-05 - val_accuracy: 0.7338 - val_loss: 3.3677\n",
      "Epoch 208/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1259e-05 - val_accuracy: 0.7338 - val_loss: 3.3750\n",
      "Epoch 209/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 2.7801e-05 - val_accuracy: 0.7338 - val_loss: 3.3731\n",
      "Epoch 210/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 2.3582e-05 - val_accuracy: 0.7338 - val_loss: 3.3800\n",
      "Epoch 211/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.8151e-05 - val_accuracy: 0.7338 - val_loss: 3.3861\n",
      "Epoch 212/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 2.0026e-05 - val_accuracy: 0.7338 - val_loss: 3.3902\n",
      "Epoch 213/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 2.3060e-05 - val_accuracy: 0.7338 - val_loss: 3.3953\n",
      "Epoch 214/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 2.0651e-05 - val_accuracy: 0.7338 - val_loss: 3.3999\n",
      "Epoch 215/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 2.0516e-05 - val_accuracy: 0.7338 - val_loss: 3.4030\n",
      "Epoch 216/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 2.1011e-05 - val_accuracy: 0.7338 - val_loss: 3.4081\n",
      "Epoch 217/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 1.5975e-05 - val_accuracy: 0.7338 - val_loss: 3.4133\n",
      "Epoch 218/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 2.4809e-05 - val_accuracy: 0.7338 - val_loss: 3.4158\n",
      "Epoch 219/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.5597e-05 - val_accuracy: 0.7338 - val_loss: 3.4206\n",
      "Epoch 220/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6929e-05 - val_accuracy: 0.7338 - val_loss: 3.4291\n",
      "Epoch 221/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 1.8553e-05 - val_accuracy: 0.7338 - val_loss: 3.4323\n",
      "Epoch 222/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 2.0016e-05 - val_accuracy: 0.7338 - val_loss: 3.4351\n",
      "Epoch 223/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 1.4128e-05 - val_accuracy: 0.7338 - val_loss: 3.4417\n",
      "Epoch 224/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 1.8613e-05 - val_accuracy: 0.7403 - val_loss: 3.4428\n",
      "Epoch 225/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.6323e-05 - val_accuracy: 0.7403 - val_loss: 3.4473\n",
      "Epoch 226/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1144e-05 - val_accuracy: 0.7338 - val_loss: 3.4475\n",
      "Epoch 227/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4783e-05 - val_accuracy: 0.7338 - val_loss: 3.4551\n",
      "Epoch 228/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3896e-05 - val_accuracy: 0.7338 - val_loss: 3.4594\n",
      "Epoch 229/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6922e-05 - val_accuracy: 0.7403 - val_loss: 3.4626\n",
      "Epoch 230/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5356e-05 - val_accuracy: 0.7338 - val_loss: 3.4676\n",
      "Epoch 231/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3856e-05 - val_accuracy: 0.7338 - val_loss: 3.4738\n",
      "Epoch 232/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1690e-05 - val_accuracy: 0.7403 - val_loss: 3.4744\n",
      "Epoch 233/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 1.3552e-05 - val_accuracy: 0.7338 - val_loss: 3.4811\n",
      "Epoch 234/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 1.0000 - loss: 2.0734e-05 - val_accuracy: 0.7338 - val_loss: 3.4925\n",
      "Epoch 235/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 1.7680e-05 - val_accuracy: 0.7403 - val_loss: 3.4895\n",
      "Epoch 236/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1632e-05 - val_accuracy: 0.7403 - val_loss: 3.4925\n",
      "Epoch 237/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 1.4536e-05 - val_accuracy: 0.7338 - val_loss: 3.4999\n",
      "Epoch 238/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.6718e-05 - val_accuracy: 0.7338 - val_loss: 3.5044\n",
      "Epoch 239/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.2169e-05 - val_accuracy: 0.7338 - val_loss: 3.5078\n",
      "Epoch 240/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 1.4509e-05 - val_accuracy: 0.7338 - val_loss: 3.5139\n",
      "Epoch 241/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 1.4367e-05 - val_accuracy: 0.7338 - val_loss: 3.5161\n",
      "Epoch 242/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 1.3743e-05 - val_accuracy: 0.7338 - val_loss: 3.5215\n",
      "Epoch 243/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4542e-05 - val_accuracy: 0.7338 - val_loss: 3.5254\n",
      "Epoch 244/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 1.2398e-05 - val_accuracy: 0.7338 - val_loss: 3.5283\n",
      "Epoch 245/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 1.1084e-05 - val_accuracy: 0.7338 - val_loss: 3.5349\n",
      "Epoch 246/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 1.7922e-05 - val_accuracy: 0.7338 - val_loss: 3.5369\n",
      "Epoch 247/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 1.0497e-05 - val_accuracy: 0.7338 - val_loss: 3.5421\n",
      "Epoch 248/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.0349e-05 - val_accuracy: 0.7338 - val_loss: 3.5459\n",
      "Epoch 249/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 1.3020e-05 - val_accuracy: 0.7338 - val_loss: 3.5525\n",
      "Epoch 250/250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.2212e-05 - val_accuracy: 0.7338 - val_loss: 3.5537\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=250, batch_size=32, validation_split=.20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('kc_house.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  ...  zipcode_98146  zipcode_98148  zipcode_98155  \\\n",
       "0     1.0   65          0  ...              0              0              0   \n",
       "1     2.0   69          1  ...              0              0              0   \n",
       "2     1.0   87          0  ...              0              0              0   \n",
       "3     1.0   55          0  ...              0              0              0   \n",
       "4     1.0   33          0  ...              0              0              0   \n",
       "\n",
       "   zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  zipcode_98188  \\\n",
       "0              0              0              0              1              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98198  zipcode_98199  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('price', axis=1)\n",
    "y=df[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(80,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7516235776.0000 - val_loss: 8339601920.0000\n",
      "Epoch 2/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7527260672.0000 - val_loss: 8410697728.0000\n",
      "Epoch 3/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7746241024.0000 - val_loss: 8703656960.0000\n",
      "Epoch 4/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7938613248.0000 - val_loss: 8418258944.0000\n",
      "Epoch 5/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7378997248.0000 - val_loss: 8661309440.0000\n",
      "Epoch 6/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7562857984.0000 - val_loss: 8259750912.0000\n",
      "Epoch 7/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7621135360.0000 - val_loss: 8367982080.0000\n",
      "Epoch 8/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7628353536.0000 - val_loss: 8279217664.0000\n",
      "Epoch 9/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7321374720.0000 - val_loss: 8252849664.0000\n",
      "Epoch 10/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7316865536.0000 - val_loss: 8521768448.0000\n",
      "Epoch 11/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7598061056.0000 - val_loss: 8604807168.0000\n",
      "Epoch 12/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7530233344.0000 - val_loss: 8360108544.0000\n",
      "Epoch 13/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7367294464.0000 - val_loss: 8263011840.0000\n",
      "Epoch 14/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7338606080.0000 - val_loss: 8429729792.0000\n",
      "Epoch 15/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8073108480.0000 - val_loss: 9206559744.0000\n",
      "Epoch 16/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8005228544.0000 - val_loss: 8296167424.0000\n",
      "Epoch 17/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7530439680.0000 - val_loss: 8297689088.0000\n",
      "Epoch 18/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7531569152.0000 - val_loss: 8430731264.0000\n",
      "Epoch 19/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7579763712.0000 - val_loss: 8555180032.0000\n",
      "Epoch 20/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7539251712.0000 - val_loss: 8284647424.0000\n",
      "Epoch 21/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7347413504.0000 - val_loss: 8312832512.0000\n",
      "Epoch 22/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7342136832.0000 - val_loss: 8244356608.0000\n",
      "Epoch 23/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7518840832.0000 - val_loss: 9092597760.0000\n",
      "Epoch 24/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7829560832.0000 - val_loss: 9022632960.0000\n",
      "Epoch 25/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7818384896.0000 - val_loss: 10548518912.0000\n",
      "Epoch 26/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8553590272.0000 - val_loss: 8270705152.0000\n",
      "Epoch 27/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7669393920.0000 - val_loss: 9156776960.0000\n",
      "Epoch 28/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7698966016.0000 - val_loss: 8537011200.0000\n",
      "Epoch 29/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7706171904.0000 - val_loss: 8500013056.0000\n",
      "Epoch 30/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7485288448.0000 - val_loss: 8739971072.0000\n",
      "Epoch 31/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7450832896.0000 - val_loss: 8384782336.0000\n",
      "Epoch 32/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7425804800.0000 - val_loss: 8303919104.0000\n",
      "Epoch 33/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7417662976.0000 - val_loss: 8529358336.0000\n",
      "Epoch 34/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7403484160.0000 - val_loss: 8490303488.0000\n",
      "Epoch 35/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7701431808.0000 - val_loss: 8392784896.0000\n",
      "Epoch 36/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7686423552.0000 - val_loss: 8218129408.0000\n",
      "Epoch 37/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7457640448.0000 - val_loss: 8226518016.0000\n",
      "Epoch 38/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7280182272.0000 - val_loss: 8231211520.0000\n",
      "Epoch 39/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7562643456.0000 - val_loss: 8392120320.0000\n",
      "Epoch 40/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7526281728.0000 - val_loss: 9192299520.0000\n",
      "Epoch 41/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7978024448.0000 - val_loss: 8520115712.0000\n",
      "Epoch 42/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7569894912.0000 - val_loss: 8240668672.0000\n",
      "Epoch 43/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7521967616.0000 - val_loss: 8548708352.0000\n",
      "Epoch 44/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7369960448.0000 - val_loss: 8926730240.0000\n",
      "Epoch 45/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7515589632.0000 - val_loss: 8435113984.0000\n",
      "Epoch 46/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7518035968.0000 - val_loss: 8220906496.0000\n",
      "Epoch 47/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7763736064.0000 - val_loss: 8244999680.0000\n",
      "Epoch 48/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7428788224.0000 - val_loss: 8387377664.0000\n",
      "Epoch 49/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7353366528.0000 - val_loss: 8227313152.0000\n",
      "Epoch 50/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7228141056.0000 - val_loss: 9080047616.0000\n",
      "Epoch 51/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7834630656.0000 - val_loss: 8245933056.0000\n",
      "Epoch 52/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7223260160.0000 - val_loss: 8246482432.0000\n",
      "Epoch 53/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7548977664.0000 - val_loss: 8214113280.0000\n",
      "Epoch 54/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7558946816.0000 - val_loss: 8271570944.0000\n",
      "Epoch 55/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7964882944.0000 - val_loss: 9332144128.0000\n",
      "Epoch 56/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7929433600.0000 - val_loss: 8265882112.0000\n",
      "Epoch 57/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7809341440.0000 - val_loss: 8683706368.0000\n",
      "Epoch 58/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7665575936.0000 - val_loss: 8475111936.0000\n",
      "Epoch 59/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7603607552.0000 - val_loss: 8383251456.0000\n",
      "Epoch 60/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7366571008.0000 - val_loss: 8290545664.0000\n",
      "Epoch 61/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7551266304.0000 - val_loss: 8505417728.0000\n",
      "Epoch 62/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7608840192.0000 - val_loss: 8635171840.0000\n",
      "Epoch 63/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7720226816.0000 - val_loss: 8212749312.0000\n",
      "Epoch 64/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7435805184.0000 - val_loss: 8207412224.0000\n",
      "Epoch 65/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7273423360.0000 - val_loss: 8282869248.0000\n",
      "Epoch 66/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7384817152.0000 - val_loss: 8219333120.0000\n",
      "Epoch 67/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7382923264.0000 - val_loss: 8643572736.0000\n",
      "Epoch 68/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7714594816.0000 - val_loss: 8280693248.0000\n",
      "Epoch 69/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7477316608.0000 - val_loss: 8222968832.0000\n",
      "Epoch 70/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7444315648.0000 - val_loss: 8317139456.0000\n",
      "Epoch 71/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7709214720.0000 - val_loss: 8586781184.0000\n",
      "Epoch 72/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7498322944.0000 - val_loss: 8246388736.0000\n",
      "Epoch 73/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7516656128.0000 - val_loss: 8278704128.0000\n",
      "Epoch 74/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7219833344.0000 - val_loss: 8246703616.0000\n",
      "Epoch 75/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7330341376.0000 - val_loss: 8516609536.0000\n",
      "Epoch 76/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7298935296.0000 - val_loss: 8284293120.0000\n",
      "Epoch 77/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7479761920.0000 - val_loss: 8498777088.0000\n",
      "Epoch 78/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7872629760.0000 - val_loss: 8532241920.0000\n",
      "Epoch 79/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7358618624.0000 - val_loss: 8184594944.0000\n",
      "Epoch 80/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7091969024.0000 - val_loss: 8216046080.0000\n",
      "Epoch 81/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7303313408.0000 - val_loss: 8202624512.0000\n",
      "Epoch 82/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7468296704.0000 - val_loss: 8947630080.0000\n",
      "Epoch 83/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7826600960.0000 - val_loss: 8323514368.0000\n",
      "Epoch 84/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7555048448.0000 - val_loss: 8490596352.0000\n",
      "Epoch 85/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7409513472.0000 - val_loss: 8607040512.0000\n",
      "Epoch 86/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7649179136.0000 - val_loss: 8193436672.0000\n",
      "Epoch 87/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7424979456.0000 - val_loss: 8280590848.0000\n",
      "Epoch 88/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7223048704.0000 - val_loss: 8767760384.0000\n",
      "Epoch 89/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7567803904.0000 - val_loss: 8216017920.0000\n",
      "Epoch 90/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7399960576.0000 - val_loss: 8259705344.0000\n",
      "Epoch 91/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7427821056.0000 - val_loss: 8291173376.0000\n",
      "Epoch 92/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7395164672.0000 - val_loss: 9860719616.0000\n",
      "Epoch 93/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8147441152.0000 - val_loss: 8234008064.0000\n",
      "Epoch 94/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7446195200.0000 - val_loss: 8335104000.0000\n",
      "Epoch 95/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7407966720.0000 - val_loss: 8201746432.0000\n",
      "Epoch 96/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7418746880.0000 - val_loss: 8267829760.0000\n",
      "Epoch 97/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7631158784.0000 - val_loss: 8218221056.0000\n",
      "Epoch 98/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7220064768.0000 - val_loss: 8271060480.0000\n",
      "Epoch 99/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7257572352.0000 - val_loss: 8394155008.0000\n",
      "Epoch 100/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7154945024.0000 - val_loss: 8396712448.0000\n",
      "Epoch 101/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7335438848.0000 - val_loss: 8211938304.0000\n",
      "Epoch 102/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7524340736.0000 - val_loss: 8246621696.0000\n",
      "Epoch 103/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7250062336.0000 - val_loss: 8191708160.0000\n",
      "Epoch 104/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7348801024.0000 - val_loss: 8451141120.0000\n",
      "Epoch 105/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7393933824.0000 - val_loss: 9926307840.0000\n",
      "Epoch 106/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8720653312.0000 - val_loss: 8188611072.0000\n",
      "Epoch 107/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7334770688.0000 - val_loss: 8663081984.0000\n",
      "Epoch 108/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7562428928.0000 - val_loss: 8227578368.0000\n",
      "Epoch 109/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7902605824.0000 - val_loss: 8209202176.0000\n",
      "Epoch 110/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7581284864.0000 - val_loss: 8180387840.0000\n",
      "Epoch 111/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7344256512.0000 - val_loss: 8612557824.0000\n",
      "Epoch 112/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7825886208.0000 - val_loss: 8181688832.0000\n",
      "Epoch 113/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7260145152.0000 - val_loss: 8245328384.0000\n",
      "Epoch 114/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7296495616.0000 - val_loss: 8412490752.0000\n",
      "Epoch 115/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7439491584.0000 - val_loss: 8320329728.0000\n",
      "Epoch 116/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7421956096.0000 - val_loss: 8178311680.0000\n",
      "Epoch 117/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7298027008.0000 - val_loss: 8601565184.0000\n",
      "Epoch 118/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7897436160.0000 - val_loss: 8196142080.0000\n",
      "Epoch 119/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7285970432.0000 - val_loss: 8524756992.0000\n",
      "Epoch 120/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7630714880.0000 - val_loss: 8193805312.0000\n",
      "Epoch 121/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7306871296.0000 - val_loss: 8577859584.0000\n",
      "Epoch 122/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7650919424.0000 - val_loss: 8897890304.0000\n",
      "Epoch 123/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7375352320.0000 - val_loss: 8347226624.0000\n",
      "Epoch 124/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7211422720.0000 - val_loss: 8169260544.0000\n",
      "Epoch 125/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7218321920.0000 - val_loss: 8177559040.0000\n",
      "Epoch 126/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7180315648.0000 - val_loss: 8380369920.0000\n",
      "Epoch 127/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7448263168.0000 - val_loss: 9757983744.0000\n",
      "Epoch 128/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8243163136.0000 - val_loss: 8281728512.0000\n",
      "Epoch 129/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7740091904.0000 - val_loss: 8167049216.0000\n",
      "Epoch 130/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7287901184.0000 - val_loss: 8212907520.0000\n",
      "Epoch 131/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7177307136.0000 - val_loss: 8198502400.0000\n",
      "Epoch 132/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7109593600.0000 - val_loss: 8177380352.0000\n",
      "Epoch 133/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7481014272.0000 - val_loss: 8431579648.0000\n",
      "Epoch 134/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7719670784.0000 - val_loss: 8599026688.0000\n",
      "Epoch 135/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7331341312.0000 - val_loss: 8345445376.0000\n",
      "Epoch 136/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7657597952.0000 - val_loss: 8343141376.0000\n",
      "Epoch 137/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7443734528.0000 - val_loss: 8788211712.0000\n",
      "Epoch 138/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7759035904.0000 - val_loss: 8285186560.0000\n",
      "Epoch 139/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7280086528.0000 - val_loss: 8608047104.0000\n",
      "Epoch 140/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7491288576.0000 - val_loss: 8797395968.0000\n",
      "Epoch 141/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7518185984.0000 - val_loss: 8207370240.0000\n",
      "Epoch 142/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7416930304.0000 - val_loss: 9057988608.0000\n",
      "Epoch 143/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7426564096.0000 - val_loss: 8387949568.0000\n",
      "Epoch 144/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7160246784.0000 - val_loss: 8696888320.0000\n",
      "Epoch 145/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7614807552.0000 - val_loss: 8596541440.0000\n",
      "Epoch 146/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7387374592.0000 - val_loss: 8231767040.0000\n",
      "Epoch 147/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7377257984.0000 - val_loss: 8862240768.0000\n",
      "Epoch 148/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7601857024.0000 - val_loss: 8316954624.0000\n",
      "Epoch 149/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7133694976.0000 - val_loss: 8155567616.0000\n",
      "Epoch 150/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7194447872.0000 - val_loss: 8444993536.0000\n",
      "Epoch 151/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7290491904.0000 - val_loss: 8187457536.0000\n",
      "Epoch 152/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7346235392.0000 - val_loss: 8156995584.0000\n",
      "Epoch 153/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7456699392.0000 - val_loss: 8286185472.0000\n",
      "Epoch 154/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7386694656.0000 - val_loss: 8506489856.0000\n",
      "Epoch 155/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7371744256.0000 - val_loss: 8180912640.0000\n",
      "Epoch 156/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7207383040.0000 - val_loss: 8175104512.0000\n",
      "Epoch 157/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7268154368.0000 - val_loss: 8382251008.0000\n",
      "Epoch 158/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7209070080.0000 - val_loss: 8834818048.0000\n",
      "Epoch 159/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7661282304.0000 - val_loss: 8344480256.0000\n",
      "Epoch 160/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7311980032.0000 - val_loss: 8458924544.0000\n",
      "Epoch 161/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7616207360.0000 - val_loss: 8691305472.0000\n",
      "Epoch 162/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7466344960.0000 - val_loss: 8609510400.0000\n",
      "Epoch 163/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7581859840.0000 - val_loss: 9093167104.0000\n",
      "Epoch 164/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7679749120.0000 - val_loss: 8522388992.0000\n",
      "Epoch 165/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7509654528.0000 - val_loss: 8170316288.0000\n",
      "Epoch 166/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7168426496.0000 - val_loss: 8578488320.0000\n",
      "Epoch 167/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7329723904.0000 - val_loss: 8172165632.0000\n",
      "Epoch 168/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6985447424.0000 - val_loss: 8256081408.0000\n",
      "Epoch 169/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7319377920.0000 - val_loss: 8858337280.0000\n",
      "Epoch 170/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7560440832.0000 - val_loss: 8479022080.0000\n",
      "Epoch 171/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7517468160.0000 - val_loss: 8207472128.0000\n",
      "Epoch 172/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7445740544.0000 - val_loss: 8263547392.0000\n",
      "Epoch 173/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7166721536.0000 - val_loss: 8178147840.0000\n",
      "Epoch 174/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7386467840.0000 - val_loss: 8167831040.0000\n",
      "Epoch 175/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7391507968.0000 - val_loss: 8405842432.0000\n",
      "Epoch 176/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7460580864.0000 - val_loss: 9680323584.0000\n",
      "Epoch 177/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7917218816.0000 - val_loss: 8202251776.0000\n",
      "Epoch 178/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7260416512.0000 - val_loss: 8287320576.0000\n",
      "Epoch 179/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7679955456.0000 - val_loss: 8807362560.0000\n",
      "Epoch 180/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7726740992.0000 - val_loss: 8275886080.0000\n",
      "Epoch 181/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7289607168.0000 - val_loss: 8358952448.0000\n",
      "Epoch 182/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7240919040.0000 - val_loss: 8269790208.0000\n",
      "Epoch 183/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7185069056.0000 - val_loss: 8658021376.0000\n",
      "Epoch 184/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7358206976.0000 - val_loss: 8149419520.0000\n",
      "Epoch 185/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7263451136.0000 - val_loss: 8314786816.0000\n",
      "Epoch 186/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7591502848.0000 - val_loss: 8149191168.0000\n",
      "Epoch 187/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7184911872.0000 - val_loss: 8202143232.0000\n",
      "Epoch 188/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7342761984.0000 - val_loss: 8167541248.0000\n",
      "Epoch 189/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7208182784.0000 - val_loss: 8173414912.0000\n",
      "Epoch 190/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7363650048.0000 - val_loss: 8599329792.0000\n",
      "Epoch 191/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7567942656.0000 - val_loss: 8453774336.0000\n",
      "Epoch 192/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7445189120.0000 - val_loss: 8209462784.0000\n",
      "Epoch 193/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7271231488.0000 - val_loss: 8165701120.0000\n",
      "Epoch 194/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7142007296.0000 - val_loss: 8145262592.0000\n",
      "Epoch 195/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7341510656.0000 - val_loss: 8171525120.0000\n",
      "Epoch 196/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7206982144.0000 - val_loss: 8159374336.0000\n",
      "Epoch 197/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6959989760.0000 - val_loss: 8419194368.0000\n",
      "Epoch 198/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7600698880.0000 - val_loss: 8132416512.0000\n",
      "Epoch 199/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7208148992.0000 - val_loss: 8227426304.0000\n",
      "Epoch 200/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7288416256.0000 - val_loss: 8204596224.0000\n",
      "Epoch 201/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7287859200.0000 - val_loss: 8376334848.0000\n",
      "Epoch 202/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7228389376.0000 - val_loss: 8234928640.0000\n",
      "Epoch 203/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7300911616.0000 - val_loss: 8153903616.0000\n",
      "Epoch 204/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7207349760.0000 - val_loss: 8140892672.0000\n",
      "Epoch 205/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7178038784.0000 - val_loss: 8215766016.0000\n",
      "Epoch 206/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7153371648.0000 - val_loss: 8265871360.0000\n",
      "Epoch 207/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7383353344.0000 - val_loss: 8128844800.0000\n",
      "Epoch 208/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7238895616.0000 - val_loss: 8164105728.0000\n",
      "Epoch 209/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7337311232.0000 - val_loss: 8728011776.0000\n",
      "Epoch 210/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7390985216.0000 - val_loss: 8607728640.0000\n",
      "Epoch 211/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7617955840.0000 - val_loss: 8371806208.0000\n",
      "Epoch 212/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7520286208.0000 - val_loss: 9548685312.0000\n",
      "Epoch 213/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7995543552.0000 - val_loss: 8155673600.0000\n",
      "Epoch 214/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7207457792.0000 - val_loss: 9453505536.0000\n",
      "Epoch 215/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7719283200.0000 - val_loss: 8681695232.0000\n",
      "Epoch 216/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7870988800.0000 - val_loss: 9297546240.0000\n",
      "Epoch 217/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8006525440.0000 - val_loss: 8810256384.0000\n",
      "Epoch 218/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7757794816.0000 - val_loss: 8173182976.0000\n",
      "Epoch 219/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7272782336.0000 - val_loss: 8255085056.0000\n",
      "Epoch 220/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7653096448.0000 - val_loss: 8198408192.0000\n",
      "Epoch 221/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7344625664.0000 - val_loss: 8198987264.0000\n",
      "Epoch 222/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7298869760.0000 - val_loss: 8173116416.0000\n",
      "Epoch 223/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7665145856.0000 - val_loss: 8158630912.0000\n",
      "Epoch 224/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7343134720.0000 - val_loss: 8197575680.0000\n",
      "Epoch 225/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7413141504.0000 - val_loss: 8360076288.0000\n",
      "Epoch 226/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7338670080.0000 - val_loss: 8242156544.0000\n",
      "Epoch 227/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7343359488.0000 - val_loss: 8138853376.0000\n",
      "Epoch 228/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7349953536.0000 - val_loss: 8162796032.0000\n",
      "Epoch 229/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7201806848.0000 - val_loss: 8166644224.0000\n",
      "Epoch 230/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7107220480.0000 - val_loss: 8194104832.0000\n",
      "Epoch 231/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7127432704.0000 - val_loss: 9279326208.0000\n",
      "Epoch 232/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7665991168.0000 - val_loss: 8156481536.0000\n",
      "Epoch 233/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7338476544.0000 - val_loss: 8242455552.0000\n",
      "Epoch 234/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7340573696.0000 - val_loss: 8418128896.0000\n",
      "Epoch 235/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7377999360.0000 - val_loss: 8230745600.0000\n",
      "Epoch 236/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7349285376.0000 - val_loss: 8406330368.0000\n",
      "Epoch 237/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7230713856.0000 - val_loss: 8198948864.0000\n",
      "Epoch 238/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7414263808.0000 - val_loss: 8146311680.0000\n",
      "Epoch 239/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7408068608.0000 - val_loss: 8225143808.0000\n",
      "Epoch 240/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7148103168.0000 - val_loss: 8299900928.0000\n",
      "Epoch 241/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7276554240.0000 - val_loss: 8185161216.0000\n",
      "Epoch 242/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7367871488.0000 - val_loss: 8581652992.0000\n",
      "Epoch 243/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7669109760.0000 - val_loss: 8149897728.0000\n",
      "Epoch 244/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7079284736.0000 - val_loss: 8722893824.0000\n",
      "Epoch 245/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7537471488.0000 - val_loss: 8533935616.0000\n",
      "Epoch 246/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7461854208.0000 - val_loss: 8363124224.0000\n",
      "Epoch 247/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7370175488.0000 - val_loss: 8117718016.0000\n",
      "Epoch 248/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7605417472.0000 - val_loss: 8708963328.0000\n",
      "Epoch 249/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7714094592.0000 - val_loss: 8421903872.0000\n",
      "Epoch 250/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7356995072.0000 - val_loss: 8150803968.0000\n",
      "Epoch 251/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7246953984.0000 - val_loss: 8211409920.0000\n",
      "Epoch 252/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7344131584.0000 - val_loss: 8209711104.0000\n",
      "Epoch 253/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7283297792.0000 - val_loss: 8542526464.0000\n",
      "Epoch 254/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7508985344.0000 - val_loss: 9140292608.0000\n",
      "Epoch 255/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7576223744.0000 - val_loss: 8966307840.0000\n",
      "Epoch 256/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7566469120.0000 - val_loss: 8142928896.0000\n",
      "Epoch 257/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7176218624.0000 - val_loss: 8194341376.0000\n",
      "Epoch 258/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7102705664.0000 - val_loss: 8137669120.0000\n",
      "Epoch 259/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7134876672.0000 - val_loss: 9346116608.0000\n",
      "Epoch 260/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7883100160.0000 - val_loss: 8165514240.0000\n",
      "Epoch 261/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7321792512.0000 - val_loss: 8364567552.0000\n",
      "Epoch 262/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7359236608.0000 - val_loss: 8127734272.0000\n",
      "Epoch 263/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7293952000.0000 - val_loss: 8167591424.0000\n",
      "Epoch 264/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7071605760.0000 - val_loss: 8147554304.0000\n",
      "Epoch 265/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7231652864.0000 - val_loss: 8473937920.0000\n",
      "Epoch 266/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7509165056.0000 - val_loss: 8515034112.0000\n",
      "Epoch 267/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7655439872.0000 - val_loss: 8487434752.0000\n",
      "Epoch 268/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7350166528.0000 - val_loss: 8454098432.0000\n",
      "Epoch 269/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7527932928.0000 - val_loss: 8848075776.0000\n",
      "Epoch 270/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7576099328.0000 - val_loss: 8148945920.0000\n",
      "Epoch 271/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7352324096.0000 - val_loss: 8813944832.0000\n",
      "Epoch 272/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7624303104.0000 - val_loss: 8659615744.0000\n",
      "Epoch 273/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7339075584.0000 - val_loss: 8481666048.0000\n",
      "Epoch 274/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7848236544.0000 - val_loss: 8132246016.0000\n",
      "Epoch 275/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7419643904.0000 - val_loss: 8241209856.0000\n",
      "Epoch 276/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7189101568.0000 - val_loss: 8439151104.0000\n",
      "Epoch 277/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7280419840.0000 - val_loss: 9070020608.0000\n",
      "Epoch 278/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7307093504.0000 - val_loss: 8642334720.0000\n",
      "Epoch 279/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7528918528.0000 - val_loss: 8136472576.0000\n",
      "Epoch 280/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7544042496.0000 - val_loss: 8246293504.0000\n",
      "Epoch 281/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7020636672.0000 - val_loss: 8094210560.0000\n",
      "Epoch 282/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7109706752.0000 - val_loss: 8317061120.0000\n",
      "Epoch 283/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7348839936.0000 - val_loss: 8180686336.0000\n",
      "Epoch 284/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7241145856.0000 - val_loss: 8107453440.0000\n",
      "Epoch 285/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7155296768.0000 - val_loss: 8161396224.0000\n",
      "Epoch 286/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7519951872.0000 - val_loss: 8096663552.0000\n",
      "Epoch 287/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7614980096.0000 - val_loss: 8123152896.0000\n",
      "Epoch 288/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7209519616.0000 - val_loss: 8113067520.0000\n",
      "Epoch 289/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7811928064.0000 - val_loss: 9216779264.0000\n",
      "Epoch 290/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7777442816.0000 - val_loss: 10075085824.0000\n",
      "Epoch 291/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8448796672.0000 - val_loss: 8235560448.0000\n",
      "Epoch 292/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7732263424.0000 - val_loss: 8382143488.0000\n",
      "Epoch 293/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7306438656.0000 - val_loss: 8113453568.0000\n",
      "Epoch 294/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7090454016.0000 - val_loss: 8123248128.0000\n",
      "Epoch 295/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7251288576.0000 - val_loss: 8184036864.0000\n",
      "Epoch 296/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7126671872.0000 - val_loss: 8458629120.0000\n",
      "Epoch 297/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7392308224.0000 - val_loss: 9339481088.0000\n",
      "Epoch 298/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7763825664.0000 - val_loss: 8103872512.0000\n",
      "Epoch 299/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7443496960.0000 - val_loss: 8116157952.0000\n",
      "Epoch 300/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7256499200.0000 - val_loss: 8542626816.0000\n",
      "Epoch 301/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7411810304.0000 - val_loss: 9029393408.0000\n",
      "Epoch 302/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7677815808.0000 - val_loss: 8607586304.0000\n",
      "Epoch 303/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7318047744.0000 - val_loss: 8775016448.0000\n",
      "Epoch 304/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7485048320.0000 - val_loss: 8238105088.0000\n",
      "Epoch 305/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7318272000.0000 - val_loss: 8101798400.0000\n",
      "Epoch 306/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7106969088.0000 - val_loss: 8118609408.0000\n",
      "Epoch 307/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7316408832.0000 - val_loss: 8134871040.0000\n",
      "Epoch 308/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7252560384.0000 - val_loss: 8110377984.0000\n",
      "Epoch 309/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7025960448.0000 - val_loss: 8158944256.0000\n",
      "Epoch 310/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7356503040.0000 - val_loss: 8208241664.0000\n",
      "Epoch 311/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7399852544.0000 - val_loss: 8234971136.0000\n",
      "Epoch 312/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7075588096.0000 - val_loss: 8131040256.0000\n",
      "Epoch 313/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7216471040.0000 - val_loss: 8163903488.0000\n",
      "Epoch 314/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7267628032.0000 - val_loss: 8202895360.0000\n",
      "Epoch 315/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7275014144.0000 - val_loss: 8338883072.0000\n",
      "Epoch 316/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7378635776.0000 - val_loss: 8243802624.0000\n",
      "Epoch 317/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7197648896.0000 - val_loss: 8142492672.0000\n",
      "Epoch 318/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6944595456.0000 - val_loss: 8103460352.0000\n",
      "Epoch 319/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7050425856.0000 - val_loss: 8117831680.0000\n",
      "Epoch 320/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7037134848.0000 - val_loss: 8471576576.0000\n",
      "Epoch 321/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7442392064.0000 - val_loss: 8497561088.0000\n",
      "Epoch 322/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7172448768.0000 - val_loss: 9636895744.0000\n",
      "Epoch 323/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7620937728.0000 - val_loss: 8191919616.0000\n",
      "Epoch 324/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7131216384.0000 - val_loss: 8375293440.0000\n",
      "Epoch 325/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7316924416.0000 - val_loss: 8168401408.0000\n",
      "Epoch 326/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7322096640.0000 - val_loss: 8173709312.0000\n",
      "Epoch 327/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7117330432.0000 - val_loss: 8107458560.0000\n",
      "Epoch 328/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7012324352.0000 - val_loss: 9484839936.0000\n",
      "Epoch 329/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7673067520.0000 - val_loss: 8300972032.0000\n",
      "Epoch 330/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7376616960.0000 - val_loss: 8090689024.0000\n",
      "Epoch 331/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7086340096.0000 - val_loss: 8178981888.0000\n",
      "Epoch 332/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7197326848.0000 - val_loss: 8980661248.0000\n",
      "Epoch 333/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7607734784.0000 - val_loss: 8305487872.0000\n",
      "Epoch 334/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7263746048.0000 - val_loss: 8303186432.0000\n",
      "Epoch 335/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7363001856.0000 - val_loss: 8539271680.0000\n",
      "Epoch 336/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7301697536.0000 - val_loss: 8487485440.0000\n",
      "Epoch 337/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7395466752.0000 - val_loss: 9216165888.0000\n",
      "Epoch 338/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7865959936.0000 - val_loss: 10006635520.0000\n",
      "Epoch 339/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7671590912.0000 - val_loss: 8218045952.0000\n",
      "Epoch 340/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7316164608.0000 - val_loss: 8132893184.0000\n",
      "Epoch 341/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7052110336.0000 - val_loss: 8143165440.0000\n",
      "Epoch 342/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7127397888.0000 - val_loss: 8637318144.0000\n",
      "Epoch 343/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7446514688.0000 - val_loss: 8098663424.0000\n",
      "Epoch 344/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7337285120.0000 - val_loss: 8201932288.0000\n",
      "Epoch 345/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6985544704.0000 - val_loss: 8124950528.0000\n",
      "Epoch 346/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7134386176.0000 - val_loss: 8110442496.0000\n",
      "Epoch 347/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7070861312.0000 - val_loss: 8146200064.0000\n",
      "Epoch 348/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7261070336.0000 - val_loss: 8256133632.0000\n",
      "Epoch 349/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7295166976.0000 - val_loss: 8285918720.0000\n",
      "Epoch 350/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7210948096.0000 - val_loss: 8096297984.0000\n",
      "Epoch 351/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7478028288.0000 - val_loss: 8129629696.0000\n",
      "Epoch 352/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7267964928.0000 - val_loss: 9268725760.0000\n",
      "Epoch 353/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7833791488.0000 - val_loss: 8136721920.0000\n",
      "Epoch 354/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7355301888.0000 - val_loss: 8090501120.0000\n",
      "Epoch 355/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7674263040.0000 - val_loss: 8410062848.0000\n",
      "Epoch 356/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7220067840.0000 - val_loss: 8537671168.0000\n",
      "Epoch 357/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7432158208.0000 - val_loss: 8180248064.0000\n",
      "Epoch 358/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7267639808.0000 - val_loss: 8130201600.0000\n",
      "Epoch 359/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7380043776.0000 - val_loss: 8167614464.0000\n",
      "Epoch 360/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7046007808.0000 - val_loss: 8143400960.0000\n",
      "Epoch 361/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7103055872.0000 - val_loss: 8428434432.0000\n",
      "Epoch 362/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7415859200.0000 - val_loss: 9263789056.0000\n",
      "Epoch 363/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7795790336.0000 - val_loss: 8109200384.0000\n",
      "Epoch 364/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7022159872.0000 - val_loss: 8105051648.0000\n",
      "Epoch 365/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7171548672.0000 - val_loss: 8329005056.0000\n",
      "Epoch 366/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7464995328.0000 - val_loss: 8612924416.0000\n",
      "Epoch 367/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7392322048.0000 - val_loss: 8181934080.0000\n",
      "Epoch 368/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7149486592.0000 - val_loss: 8125582848.0000\n",
      "Epoch 369/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7220941312.0000 - val_loss: 8246538752.0000\n",
      "Epoch 370/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7252625408.0000 - val_loss: 8134583808.0000\n",
      "Epoch 371/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7252058112.0000 - val_loss: 8578839552.0000\n",
      "Epoch 372/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7327632896.0000 - val_loss: 8235550208.0000\n",
      "Epoch 373/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7170961920.0000 - val_loss: 8443405312.0000\n",
      "Epoch 374/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7297093120.0000 - val_loss: 8420807680.0000\n",
      "Epoch 375/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7216303104.0000 - val_loss: 8312443904.0000\n",
      "Epoch 376/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7340296704.0000 - val_loss: 8313895936.0000\n",
      "Epoch 377/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7524236288.0000 - val_loss: 8170240000.0000\n",
      "Epoch 378/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7164028416.0000 - val_loss: 8074954240.0000\n",
      "Epoch 379/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7151653376.0000 - val_loss: 8325696512.0000\n",
      "Epoch 380/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7196085760.0000 - val_loss: 8253719552.0000\n",
      "Epoch 381/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7236896768.0000 - val_loss: 8225174528.0000\n",
      "Epoch 382/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7484147712.0000 - val_loss: 10183507968.0000\n",
      "Epoch 383/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8401555456.0000 - val_loss: 9186829312.0000\n",
      "Epoch 384/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7670972928.0000 - val_loss: 8095449600.0000\n",
      "Epoch 385/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7515371520.0000 - val_loss: 8752606208.0000\n",
      "Epoch 386/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7180032512.0000 - val_loss: 8109782016.0000\n",
      "Epoch 387/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6967662080.0000 - val_loss: 8144673280.0000\n",
      "Epoch 388/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7064435712.0000 - val_loss: 8231704064.0000\n",
      "Epoch 389/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7220528640.0000 - val_loss: 8068926976.0000\n",
      "Epoch 390/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7069585920.0000 - val_loss: 8325009920.0000\n",
      "Epoch 391/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7083688960.0000 - val_loss: 8267597824.0000\n",
      "Epoch 392/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7234949120.0000 - val_loss: 8285046784.0000\n",
      "Epoch 393/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7235215360.0000 - val_loss: 8351768064.0000\n",
      "Epoch 394/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7150127104.0000 - val_loss: 8177056768.0000\n",
      "Epoch 395/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7237269504.0000 - val_loss: 8340436992.0000\n",
      "Epoch 396/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7145244160.0000 - val_loss: 8116686848.0000\n",
      "Epoch 397/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6837907456.0000 - val_loss: 8090266112.0000\n",
      "Epoch 398/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7254250496.0000 - val_loss: 8695616512.0000\n",
      "Epoch 399/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7528537600.0000 - val_loss: 8090106880.0000\n",
      "Epoch 400/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7119592448.0000 - val_loss: 8560358400.0000\n",
      "Epoch 401/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7483938816.0000 - val_loss: 8439571968.0000\n",
      "Epoch 402/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7260380672.0000 - val_loss: 8294536192.0000\n",
      "Epoch 403/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7444167168.0000 - val_loss: 8267318272.0000\n",
      "Epoch 404/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7140233728.0000 - val_loss: 8356046336.0000\n",
      "Epoch 405/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7238908416.0000 - val_loss: 8850876416.0000\n",
      "Epoch 406/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7538579456.0000 - val_loss: 8414521856.0000\n",
      "Epoch 407/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7792644608.0000 - val_loss: 10224694272.0000\n",
      "Epoch 408/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8050434048.0000 - val_loss: 8110576640.0000\n",
      "Epoch 409/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7229294592.0000 - val_loss: 8082704896.0000\n",
      "Epoch 410/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7077268992.0000 - val_loss: 9031068672.0000\n",
      "Epoch 411/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7390103040.0000 - val_loss: 8157282304.0000\n",
      "Epoch 412/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7373109248.0000 - val_loss: 8156864000.0000\n",
      "Epoch 413/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7184311296.0000 - val_loss: 9286383616.0000\n",
      "Epoch 414/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7639812096.0000 - val_loss: 8715805696.0000\n",
      "Epoch 415/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7511083008.0000 - val_loss: 8248410624.0000\n",
      "Epoch 416/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7200337920.0000 - val_loss: 8360788992.0000\n",
      "Epoch 417/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7197825024.0000 - val_loss: 8051341312.0000\n",
      "Epoch 418/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7249867264.0000 - val_loss: 8442597888.0000\n",
      "Epoch 419/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7260024320.0000 - val_loss: 8173643264.0000\n",
      "Epoch 420/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7447475200.0000 - val_loss: 8195098112.0000\n",
      "Epoch 421/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7222350336.0000 - val_loss: 8113101824.0000\n",
      "Epoch 422/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7139119104.0000 - val_loss: 8090679808.0000\n",
      "Epoch 423/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7121289216.0000 - val_loss: 8313746944.0000\n",
      "Epoch 424/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7312201216.0000 - val_loss: 8123794432.0000\n",
      "Epoch 425/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6969025536.0000 - val_loss: 8100808704.0000\n",
      "Epoch 426/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7167860224.0000 - val_loss: 8204090880.0000\n",
      "Epoch 427/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7330853376.0000 - val_loss: 8230109184.0000\n",
      "Epoch 428/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7008507904.0000 - val_loss: 8170018304.0000\n",
      "Epoch 429/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6878964224.0000 - val_loss: 8200363008.0000\n",
      "Epoch 430/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7214851584.0000 - val_loss: 8783471616.0000\n",
      "Epoch 431/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7518139392.0000 - val_loss: 8123372544.0000\n",
      "Epoch 432/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7180360704.0000 - val_loss: 8221913088.0000\n",
      "Epoch 433/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8018715648.0000 - val_loss: 8238445568.0000\n",
      "Epoch 434/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7998680576.0000 - val_loss: 8310154752.0000\n",
      "Epoch 435/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7550670848.0000 - val_loss: 8096506368.0000\n",
      "Epoch 436/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7673031680.0000 - val_loss: 8071737344.0000\n",
      "Epoch 437/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7182917632.0000 - val_loss: 8523868160.0000\n",
      "Epoch 438/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7162943488.0000 - val_loss: 8112202752.0000\n",
      "Epoch 439/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7327143936.0000 - val_loss: 8112178688.0000\n",
      "Epoch 440/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7333682176.0000 - val_loss: 8380361216.0000\n",
      "Epoch 441/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7383841280.0000 - val_loss: 8400753664.0000\n",
      "Epoch 442/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7209156608.0000 - val_loss: 9419443200.0000\n",
      "Epoch 443/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7643184128.0000 - val_loss: 8483442688.0000\n",
      "Epoch 444/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7152473088.0000 - val_loss: 8076207616.0000\n",
      "Epoch 445/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7326912000.0000 - val_loss: 8048363520.0000\n",
      "Epoch 446/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7066017280.0000 - val_loss: 8062147072.0000\n",
      "Epoch 447/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7038840320.0000 - val_loss: 8051676160.0000\n",
      "Epoch 448/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7217966592.0000 - val_loss: 8116568576.0000\n",
      "Epoch 449/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7123865088.0000 - val_loss: 8270028800.0000\n",
      "Epoch 450/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7309118976.0000 - val_loss: 8101223424.0000\n",
      "Epoch 451/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7300470272.0000 - val_loss: 8105999360.0000\n",
      "Epoch 452/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7219404800.0000 - val_loss: 8088509440.0000\n",
      "Epoch 453/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6971983872.0000 - val_loss: 8760059904.0000\n",
      "Epoch 454/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7240386560.0000 - val_loss: 8046129152.0000\n",
      "Epoch 455/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7218958848.0000 - val_loss: 8614927360.0000\n",
      "Epoch 456/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7269861376.0000 - val_loss: 8071307776.0000\n",
      "Epoch 457/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7352016896.0000 - val_loss: 8221858304.0000\n",
      "Epoch 458/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7132867584.0000 - val_loss: 8195388928.0000\n",
      "Epoch 459/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6905164288.0000 - val_loss: 8057216000.0000\n",
      "Epoch 460/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7127480832.0000 - val_loss: 8242269184.0000\n",
      "Epoch 461/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7050138112.0000 - val_loss: 8569929728.0000\n",
      "Epoch 462/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7175008256.0000 - val_loss: 8168614400.0000\n",
      "Epoch 463/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7363611648.0000 - val_loss: 8396015616.0000\n",
      "Epoch 464/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7322739712.0000 - val_loss: 8755067904.0000\n",
      "Epoch 465/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7185382400.0000 - val_loss: 8118035968.0000\n",
      "Epoch 466/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7131916288.0000 - val_loss: 8083634688.0000\n",
      "Epoch 467/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7053580288.0000 - val_loss: 9234373632.0000\n",
      "Epoch 468/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7596904448.0000 - val_loss: 8146897920.0000\n",
      "Epoch 469/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7352057856.0000 - val_loss: 8193214464.0000\n",
      "Epoch 470/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7132687872.0000 - val_loss: 8038020096.0000\n",
      "Epoch 471/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7091565568.0000 - val_loss: 8030641664.0000\n",
      "Epoch 472/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7058452992.0000 - val_loss: 8083337216.0000\n",
      "Epoch 473/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7236740096.0000 - val_loss: 8125253120.0000\n",
      "Epoch 474/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7180297216.0000 - val_loss: 8044539392.0000\n",
      "Epoch 475/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7052124672.0000 - val_loss: 8041802752.0000\n",
      "Epoch 476/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7158315008.0000 - val_loss: 8038987264.0000\n",
      "Epoch 477/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7137839104.0000 - val_loss: 8593277952.0000\n",
      "Epoch 478/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7706718720.0000 - val_loss: 8470156288.0000\n",
      "Epoch 479/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7573203456.0000 - val_loss: 8153525760.0000\n",
      "Epoch 480/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7297575936.0000 - val_loss: 8221400064.0000\n",
      "Epoch 481/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6986015232.0000 - val_loss: 8085415424.0000\n",
      "Epoch 482/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7344642048.0000 - val_loss: 8167222272.0000\n",
      "Epoch 483/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7024665088.0000 - val_loss: 8058043904.0000\n",
      "Epoch 484/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7071031808.0000 - val_loss: 8727355392.0000\n",
      "Epoch 485/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7389940224.0000 - val_loss: 8052069888.0000\n",
      "Epoch 486/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6856592896.0000 - val_loss: 8060783616.0000\n",
      "Epoch 487/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7174318080.0000 - val_loss: 8194922496.0000\n",
      "Epoch 488/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7159560704.0000 - val_loss: 8067704320.0000\n",
      "Epoch 489/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7261934080.0000 - val_loss: 8032033792.0000\n",
      "Epoch 490/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7045432832.0000 - val_loss: 8109992448.0000\n",
      "Epoch 491/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7112873472.0000 - val_loss: 8051383296.0000\n",
      "Epoch 492/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7029643776.0000 - val_loss: 8433064448.0000\n",
      "Epoch 493/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7871345152.0000 - val_loss: 8784901120.0000\n",
      "Epoch 494/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7353117184.0000 - val_loss: 8369059328.0000\n",
      "Epoch 495/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7154234368.0000 - val_loss: 8109778944.0000\n",
      "Epoch 496/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6988706816.0000 - val_loss: 8825654272.0000\n",
      "Epoch 497/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7405232128.0000 - val_loss: 8052412416.0000\n",
      "Epoch 498/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7240787968.0000 - val_loss: 8027607552.0000\n",
      "Epoch 499/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7077255680.0000 - val_loss: 8049393152.0000\n",
      "Epoch 500/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6868701696.0000 - val_loss: 8321151488.0000\n",
      "Epoch 501/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7365636608.0000 - val_loss: 8426057728.0000\n",
      "Epoch 502/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7028696064.0000 - val_loss: 8263674368.0000\n",
      "Epoch 503/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6947961344.0000 - val_loss: 8026489856.0000\n",
      "Epoch 504/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7071950848.0000 - val_loss: 8446922752.0000\n",
      "Epoch 505/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7400295936.0000 - val_loss: 8119725568.0000\n",
      "Epoch 506/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7115244032.0000 - val_loss: 8064748032.0000\n",
      "Epoch 507/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7195576832.0000 - val_loss: 8038321152.0000\n",
      "Epoch 508/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6983827968.0000 - val_loss: 8162697216.0000\n",
      "Epoch 509/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7104470528.0000 - val_loss: 9294832640.0000\n",
      "Epoch 510/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7800928256.0000 - val_loss: 8031277056.0000\n",
      "Epoch 511/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7476787712.0000 - val_loss: 8361451520.0000\n",
      "Epoch 512/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7191246848.0000 - val_loss: 8269311488.0000\n",
      "Epoch 513/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7508856320.0000 - val_loss: 8039754240.0000\n",
      "Epoch 514/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7033365504.0000 - val_loss: 8128819712.0000\n",
      "Epoch 515/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7031905280.0000 - val_loss: 8579550720.0000\n",
      "Epoch 516/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7282513920.0000 - val_loss: 8023187456.0000\n",
      "Epoch 517/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6846770688.0000 - val_loss: 8463699968.0000\n",
      "Epoch 518/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7495302656.0000 - val_loss: 8167019520.0000\n",
      "Epoch 519/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7216208896.0000 - val_loss: 8152916480.0000\n",
      "Epoch 520/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7060879360.0000 - val_loss: 8414906880.0000\n",
      "Epoch 521/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7423641600.0000 - val_loss: 8083906560.0000\n",
      "Epoch 522/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7175630848.0000 - val_loss: 8102759424.0000\n",
      "Epoch 523/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7010520576.0000 - val_loss: 8425581056.0000\n",
      "Epoch 524/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7171039232.0000 - val_loss: 8002290688.0000\n",
      "Epoch 525/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6963374592.0000 - val_loss: 8055676416.0000\n",
      "Epoch 526/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7552678912.0000 - val_loss: 9762153472.0000\n",
      "Epoch 527/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7962757632.0000 - val_loss: 8666940416.0000\n",
      "Epoch 528/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7864881152.0000 - val_loss: 8060577280.0000\n",
      "Epoch 529/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7197349888.0000 - val_loss: 8483460608.0000\n",
      "Epoch 530/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7540555264.0000 - val_loss: 8127395840.0000\n",
      "Epoch 531/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7105481728.0000 - val_loss: 8327471616.0000\n",
      "Epoch 532/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7057560064.0000 - val_loss: 8733447168.0000\n",
      "Epoch 533/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7157862912.0000 - val_loss: 8392801280.0000\n",
      "Epoch 534/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7011661312.0000 - val_loss: 8044207616.0000\n",
      "Epoch 535/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7209464320.0000 - val_loss: 9291777024.0000\n",
      "Epoch 536/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7547340800.0000 - val_loss: 9687283712.0000\n",
      "Epoch 537/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7916763648.0000 - val_loss: 8336952832.0000\n",
      "Epoch 538/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7410154496.0000 - val_loss: 8382725120.0000\n",
      "Epoch 539/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7101816320.0000 - val_loss: 8072911872.0000\n",
      "Epoch 540/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6984459264.0000 - val_loss: 8922437632.0000\n",
      "Epoch 541/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7678956032.0000 - val_loss: 8045633024.0000\n",
      "Epoch 542/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7116762624.0000 - val_loss: 8390332928.0000\n",
      "Epoch 543/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6979763200.0000 - val_loss: 8027831808.0000\n",
      "Epoch 544/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6920393216.0000 - val_loss: 8077849088.0000\n",
      "Epoch 545/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7108396032.0000 - val_loss: 8053781504.0000\n",
      "Epoch 546/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6903741952.0000 - val_loss: 8212981248.0000\n",
      "Epoch 547/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7288034304.0000 - val_loss: 8002875904.0000\n",
      "Epoch 548/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6972382208.0000 - val_loss: 8417338368.0000\n",
      "Epoch 549/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7243552256.0000 - val_loss: 8855902208.0000\n",
      "Epoch 550/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7439790592.0000 - val_loss: 8081129984.0000\n",
      "Epoch 551/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7048263680.0000 - val_loss: 8025854464.0000\n",
      "Epoch 552/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6970543616.0000 - val_loss: 8039400960.0000\n",
      "Epoch 553/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7019842560.0000 - val_loss: 8036348416.0000\n",
      "Epoch 554/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7361387008.0000 - val_loss: 8924077056.0000\n",
      "Epoch 555/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7325447168.0000 - val_loss: 8291871232.0000\n",
      "Epoch 556/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7107417088.0000 - val_loss: 8570057216.0000\n",
      "Epoch 557/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7337586688.0000 - val_loss: 8575409664.0000\n",
      "Epoch 558/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7427418624.0000 - val_loss: 10028975104.0000\n",
      "Epoch 559/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7758125056.0000 - val_loss: 8553851904.0000\n",
      "Epoch 560/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7608923648.0000 - val_loss: 7995530240.0000\n",
      "Epoch 561/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6881882112.0000 - val_loss: 8008574464.0000\n",
      "Epoch 562/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7142439936.0000 - val_loss: 8003086336.0000\n",
      "Epoch 563/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7122389504.0000 - val_loss: 8389664768.0000\n",
      "Epoch 564/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7141013504.0000 - val_loss: 8292932608.0000\n",
      "Epoch 565/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7580329984.0000 - val_loss: 8535866368.0000\n",
      "Epoch 566/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7091190784.0000 - val_loss: 8067410944.0000\n",
      "Epoch 567/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7321339904.0000 - val_loss: 8307173888.0000\n",
      "Epoch 568/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7023299584.0000 - val_loss: 8199843328.0000\n",
      "Epoch 569/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7628389888.0000 - val_loss: 8078890496.0000\n",
      "Epoch 570/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7130859520.0000 - val_loss: 8619517952.0000\n",
      "Epoch 571/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7222188544.0000 - val_loss: 8176897536.0000\n",
      "Epoch 572/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7105589248.0000 - val_loss: 8282335232.0000\n",
      "Epoch 573/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7235553792.0000 - val_loss: 8029847552.0000\n",
      "Epoch 574/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7151148544.0000 - val_loss: 8035308032.0000\n",
      "Epoch 575/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6879373312.0000 - val_loss: 8631116800.0000\n",
      "Epoch 576/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7627631616.0000 - val_loss: 8035198976.0000\n",
      "Epoch 577/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6880578048.0000 - val_loss: 8448640000.0000\n",
      "Epoch 578/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7227779584.0000 - val_loss: 8502448128.0000\n",
      "Epoch 579/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7311148544.0000 - val_loss: 8534066688.0000\n",
      "Epoch 580/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7167463424.0000 - val_loss: 8011169280.0000\n",
      "Epoch 581/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7003486720.0000 - val_loss: 8018041344.0000\n",
      "Epoch 582/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6870891008.0000 - val_loss: 9147838464.0000\n",
      "Epoch 583/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7563513344.0000 - val_loss: 8055657472.0000\n",
      "Epoch 584/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7078236672.0000 - val_loss: 8014937600.0000\n",
      "Epoch 585/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7239659008.0000 - val_loss: 8121592832.0000\n",
      "Epoch 586/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7089125376.0000 - val_loss: 8012224512.0000\n",
      "Epoch 587/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7048835584.0000 - val_loss: 8151360512.0000\n",
      "Epoch 588/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7057936384.0000 - val_loss: 8028348416.0000\n",
      "Epoch 589/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6873786880.0000 - val_loss: 8025580544.0000\n",
      "Epoch 590/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6930671616.0000 - val_loss: 8001674240.0000\n",
      "Epoch 591/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7315478016.0000 - val_loss: 7991405056.0000\n",
      "Epoch 592/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6953449984.0000 - val_loss: 8069563392.0000\n",
      "Epoch 593/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7046738432.0000 - val_loss: 8288193024.0000\n",
      "Epoch 594/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7209836032.0000 - val_loss: 8052439040.0000\n",
      "Epoch 595/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7169274368.0000 - val_loss: 8501832704.0000\n",
      "Epoch 596/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6964049408.0000 - val_loss: 8328255488.0000\n",
      "Epoch 597/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7198168064.0000 - val_loss: 8045630976.0000\n",
      "Epoch 598/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7089135104.0000 - val_loss: 8000617472.0000\n",
      "Epoch 599/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7061146112.0000 - val_loss: 8047885312.0000\n",
      "Epoch 600/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6796301312.0000 - val_loss: 8072642048.0000\n",
      "Epoch 601/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7195426304.0000 - val_loss: 8104354304.0000\n",
      "Epoch 602/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7350183424.0000 - val_loss: 9678526464.0000\n",
      "Epoch 603/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7624865792.0000 - val_loss: 8007190528.0000\n",
      "Epoch 604/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7359880704.0000 - val_loss: 8760489984.0000\n",
      "Epoch 605/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7261385728.0000 - val_loss: 8189751808.0000\n",
      "Epoch 606/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7475996160.0000 - val_loss: 7999090688.0000\n",
      "Epoch 607/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7054170624.0000 - val_loss: 8298750464.0000\n",
      "Epoch 608/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7114224640.0000 - val_loss: 8488685568.0000\n",
      "Epoch 609/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7107080704.0000 - val_loss: 8164380672.0000\n",
      "Epoch 610/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6922077696.0000 - val_loss: 8059698688.0000\n",
      "Epoch 611/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7193623552.0000 - val_loss: 8588876800.0000\n",
      "Epoch 612/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7395870208.0000 - val_loss: 8132311040.0000\n",
      "Epoch 613/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7181615616.0000 - val_loss: 8124597760.0000\n",
      "Epoch 614/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6884800512.0000 - val_loss: 8005419520.0000\n",
      "Epoch 615/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7146659328.0000 - val_loss: 8223091200.0000\n",
      "Epoch 616/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6946463232.0000 - val_loss: 8343645184.0000\n",
      "Epoch 617/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7357269504.0000 - val_loss: 8067036672.0000\n",
      "Epoch 618/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6874007552.0000 - val_loss: 8183070720.0000\n",
      "Epoch 619/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7256757760.0000 - val_loss: 8108317696.0000\n",
      "Epoch 620/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6892534272.0000 - val_loss: 8118941696.0000\n",
      "Epoch 621/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6996477952.0000 - val_loss: 8056079872.0000\n",
      "Epoch 622/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7126077440.0000 - val_loss: 8095836160.0000\n",
      "Epoch 623/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6945245696.0000 - val_loss: 8236134400.0000\n",
      "Epoch 624/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7073735168.0000 - val_loss: 8034170880.0000\n",
      "Epoch 625/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6988734976.0000 - val_loss: 8004431872.0000\n",
      "Epoch 626/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7174228480.0000 - val_loss: 8289390592.0000\n",
      "Epoch 627/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7198426624.0000 - val_loss: 8023538176.0000\n",
      "Epoch 628/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7159695360.0000 - val_loss: 8333763584.0000\n",
      "Epoch 629/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7371701760.0000 - val_loss: 7993390080.0000\n",
      "Epoch 630/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7091173376.0000 - val_loss: 8249095168.0000\n",
      "Epoch 631/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7318408704.0000 - val_loss: 8169573888.0000\n",
      "Epoch 632/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6946948608.0000 - val_loss: 8140284416.0000\n",
      "Epoch 633/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7066887680.0000 - val_loss: 8499691520.0000\n",
      "Epoch 634/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7656204800.0000 - val_loss: 8797377536.0000\n",
      "Epoch 635/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7575047680.0000 - val_loss: 8001402368.0000\n",
      "Epoch 636/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7220195328.0000 - val_loss: 8136447488.0000\n",
      "Epoch 637/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6925817344.0000 - val_loss: 8038136832.0000\n",
      "Epoch 638/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7185227264.0000 - val_loss: 8041091584.0000\n",
      "Epoch 639/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7352134656.0000 - val_loss: 9506129920.0000\n",
      "Epoch 640/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8004798976.0000 - val_loss: 8421661696.0000\n",
      "Epoch 641/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7793543168.0000 - val_loss: 8024364032.0000\n",
      "Epoch 642/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7481380352.0000 - val_loss: 8210305024.0000\n",
      "Epoch 643/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7373253120.0000 - val_loss: 8505650176.0000\n",
      "Epoch 644/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7240330752.0000 - val_loss: 8884463616.0000\n",
      "Epoch 645/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7367357440.0000 - val_loss: 8045124096.0000\n",
      "Epoch 646/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7185137664.0000 - val_loss: 8265337856.0000\n",
      "Epoch 647/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6966118912.0000 - val_loss: 8350983680.0000\n",
      "Epoch 648/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7134169088.0000 - val_loss: 8927220736.0000\n",
      "Epoch 649/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8505517056.0000 - val_loss: 9867037696.0000\n",
      "Epoch 650/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7925806592.0000 - val_loss: 8082869248.0000\n",
      "Epoch 651/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7003214848.0000 - val_loss: 8706564096.0000\n",
      "Epoch 652/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7241078272.0000 - val_loss: 8023967744.0000\n",
      "Epoch 653/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7199329280.0000 - val_loss: 8462877184.0000\n",
      "Epoch 654/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7284481024.0000 - val_loss: 8479277056.0000\n",
      "Epoch 655/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7196876288.0000 - val_loss: 8126781440.0000\n",
      "Epoch 656/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7175378944.0000 - val_loss: 8942678016.0000\n",
      "Epoch 657/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7367673856.0000 - val_loss: 8004445184.0000\n",
      "Epoch 658/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6860442112.0000 - val_loss: 8757072896.0000\n",
      "Epoch 659/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7165201920.0000 - val_loss: 8138115584.0000\n",
      "Epoch 660/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6915331072.0000 - val_loss: 8025130496.0000\n",
      "Epoch 661/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6882869760.0000 - val_loss: 8952757248.0000\n",
      "Epoch 662/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7284036096.0000 - val_loss: 7987381248.0000\n",
      "Epoch 663/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6904049664.0000 - val_loss: 7984175104.0000\n",
      "Epoch 664/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6961074688.0000 - val_loss: 8121659392.0000\n",
      "Epoch 665/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7149193216.0000 - val_loss: 8056593408.0000\n",
      "Epoch 666/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6857188864.0000 - val_loss: 8199203328.0000\n",
      "Epoch 667/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7467255808.0000 - val_loss: 10002817024.0000\n",
      "Epoch 668/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7645407232.0000 - val_loss: 8694178816.0000\n",
      "Epoch 669/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7074764288.0000 - val_loss: 8467805184.0000\n",
      "Epoch 670/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7300326912.0000 - val_loss: 8052281344.0000\n",
      "Epoch 671/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7311225856.0000 - val_loss: 8011404800.0000\n",
      "Epoch 672/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6872023552.0000 - val_loss: 8254929408.0000\n",
      "Epoch 673/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7131268608.0000 - val_loss: 8323635200.0000\n",
      "Epoch 674/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7288652288.0000 - val_loss: 8216524288.0000\n",
      "Epoch 675/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7029976064.0000 - val_loss: 8030713344.0000\n",
      "Epoch 676/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7050819584.0000 - val_loss: 8220242432.0000\n",
      "Epoch 677/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7110680576.0000 - val_loss: 8067527168.0000\n",
      "Epoch 678/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6907858944.0000 - val_loss: 7988860416.0000\n",
      "Epoch 679/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7137813504.0000 - val_loss: 9236964352.0000\n",
      "Epoch 680/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7461703168.0000 - val_loss: 8263147008.0000\n",
      "Epoch 681/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7269907456.0000 - val_loss: 8111551488.0000\n",
      "Epoch 682/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7045856256.0000 - val_loss: 8085068288.0000\n",
      "Epoch 683/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7229049856.0000 - val_loss: 8117136384.0000\n",
      "Epoch 684/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7025040896.0000 - val_loss: 8050872832.0000\n",
      "Epoch 685/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7376233472.0000 - val_loss: 8159161344.0000\n",
      "Epoch 686/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6945919488.0000 - val_loss: 7991564800.0000\n",
      "Epoch 687/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6830037504.0000 - val_loss: 7997143552.0000\n",
      "Epoch 688/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7112193024.0000 - val_loss: 8715279360.0000\n",
      "Epoch 689/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7445531136.0000 - val_loss: 8002653184.0000\n",
      "Epoch 690/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7126430720.0000 - val_loss: 8065547776.0000\n",
      "Epoch 691/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7090496512.0000 - val_loss: 8263272448.0000\n",
      "Epoch 692/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6946961408.0000 - val_loss: 7983462912.0000\n",
      "Epoch 693/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6851272704.0000 - val_loss: 8069221376.0000\n",
      "Epoch 694/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6788929024.0000 - val_loss: 7999942656.0000\n",
      "Epoch 695/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6818332672.0000 - val_loss: 7978176512.0000\n",
      "Epoch 696/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6921077760.0000 - val_loss: 8162012160.0000\n",
      "Epoch 697/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6943004672.0000 - val_loss: 8277383168.0000\n",
      "Epoch 698/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7553329152.0000 - val_loss: 8000056832.0000\n",
      "Epoch 699/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6846922752.0000 - val_loss: 7972255232.0000\n",
      "Epoch 700/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7035843072.0000 - val_loss: 7973017600.0000\n",
      "Epoch 701/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7221806080.0000 - val_loss: 8104320000.0000\n",
      "Epoch 702/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6823411712.0000 - val_loss: 8226409984.0000\n",
      "Epoch 703/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7009728000.0000 - val_loss: 8004509696.0000\n",
      "Epoch 704/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6771921408.0000 - val_loss: 8219754496.0000\n",
      "Epoch 705/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7090449920.0000 - val_loss: 8153914880.0000\n",
      "Epoch 706/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7368775168.0000 - val_loss: 7997268480.0000\n",
      "Epoch 707/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7028328960.0000 - val_loss: 8261441536.0000\n",
      "Epoch 708/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7380390912.0000 - val_loss: 8036150784.0000\n",
      "Epoch 709/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7187850240.0000 - val_loss: 7969539072.0000\n",
      "Epoch 710/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6818204672.0000 - val_loss: 8037922304.0000\n",
      "Epoch 711/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7145910784.0000 - val_loss: 8050811392.0000\n",
      "Epoch 712/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7433274368.0000 - val_loss: 8206791680.0000\n",
      "Epoch 713/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7269736960.0000 - val_loss: 7992880128.0000\n",
      "Epoch 714/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7033502720.0000 - val_loss: 8135101440.0000\n",
      "Epoch 715/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7083670528.0000 - val_loss: 8164290048.0000\n",
      "Epoch 716/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7437110784.0000 - val_loss: 8055610368.0000\n",
      "Epoch 717/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7334991360.0000 - val_loss: 8059624960.0000\n",
      "Epoch 718/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7127329792.0000 - val_loss: 8911099904.0000\n",
      "Epoch 719/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7852702720.0000 - val_loss: 8463132160.0000\n",
      "Epoch 720/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7188204032.0000 - val_loss: 8029409280.0000\n",
      "Epoch 721/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6956365824.0000 - val_loss: 8127597056.0000\n",
      "Epoch 722/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7053828096.0000 - val_loss: 7983894016.0000\n",
      "Epoch 723/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7078382080.0000 - val_loss: 8183354880.0000\n",
      "Epoch 724/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6853549056.0000 - val_loss: 8409015808.0000\n",
      "Epoch 725/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6994719744.0000 - val_loss: 8234477056.0000\n",
      "Epoch 726/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7055649280.0000 - val_loss: 8116205056.0000\n",
      "Epoch 727/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6954531328.0000 - val_loss: 8057250304.0000\n",
      "Epoch 728/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7080060928.0000 - val_loss: 7979522560.0000\n",
      "Epoch 729/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6801457152.0000 - val_loss: 8220236800.0000\n",
      "Epoch 730/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7075344896.0000 - val_loss: 8185830400.0000\n",
      "Epoch 731/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7213748224.0000 - val_loss: 8708451328.0000\n",
      "Epoch 732/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7469614080.0000 - val_loss: 8065579520.0000\n",
      "Epoch 733/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7112571392.0000 - val_loss: 8011405824.0000\n",
      "Epoch 734/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6950478336.0000 - val_loss: 8360532992.0000\n",
      "Epoch 735/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7118047232.0000 - val_loss: 10691887104.0000\n",
      "Epoch 736/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8025122304.0000 - val_loss: 8194023936.0000\n",
      "Epoch 737/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7218509312.0000 - val_loss: 7984810496.0000\n",
      "Epoch 738/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6897767936.0000 - val_loss: 8019027456.0000\n",
      "Epoch 739/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7149069824.0000 - val_loss: 9225194496.0000\n",
      "Epoch 740/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7480858112.0000 - val_loss: 9115061248.0000\n",
      "Epoch 741/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7521776640.0000 - val_loss: 8001302016.0000\n",
      "Epoch 742/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7299328512.0000 - val_loss: 8136005632.0000\n",
      "Epoch 743/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6884028928.0000 - val_loss: 8263616512.0000\n",
      "Epoch 744/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6800705536.0000 - val_loss: 8032024064.0000\n",
      "Epoch 745/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6910957056.0000 - val_loss: 7992365568.0000\n",
      "Epoch 746/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7010176000.0000 - val_loss: 9192157184.0000\n",
      "Epoch 747/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7551298560.0000 - val_loss: 8486152192.0000\n",
      "Epoch 748/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7312560128.0000 - val_loss: 8060397568.0000\n",
      "Epoch 749/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6899048960.0000 - val_loss: 8197949440.0000\n",
      "Epoch 750/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7100942848.0000 - val_loss: 8421899264.0000\n",
      "Epoch 751/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7122976768.0000 - val_loss: 8163087872.0000\n",
      "Epoch 752/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7029739520.0000 - val_loss: 8069492224.0000\n",
      "Epoch 753/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6975617536.0000 - val_loss: 7978733056.0000\n",
      "Epoch 754/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6976135680.0000 - val_loss: 8085922816.0000\n",
      "Epoch 755/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6866734592.0000 - val_loss: 7955534336.0000\n",
      "Epoch 756/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6724606464.0000 - val_loss: 7995141120.0000\n",
      "Epoch 757/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7473981440.0000 - val_loss: 7986207744.0000\n",
      "Epoch 758/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7121036288.0000 - val_loss: 8046809088.0000\n",
      "Epoch 759/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7088636416.0000 - val_loss: 8096217088.0000\n",
      "Epoch 760/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6772766208.0000 - val_loss: 8387564544.0000\n",
      "Epoch 761/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7259583488.0000 - val_loss: 8336019968.0000\n",
      "Epoch 762/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7197165568.0000 - val_loss: 8208889344.0000\n",
      "Epoch 763/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7280726528.0000 - val_loss: 8178496512.0000\n",
      "Epoch 764/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7158945792.0000 - val_loss: 8127649280.0000\n",
      "Epoch 765/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6911478784.0000 - val_loss: 8019896832.0000\n",
      "Epoch 766/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7073918976.0000 - val_loss: 8053813760.0000\n",
      "Epoch 767/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6996628480.0000 - val_loss: 9036465152.0000\n",
      "Epoch 768/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7424819200.0000 - val_loss: 8146606592.0000\n",
      "Epoch 769/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7261362688.0000 - val_loss: 8215099904.0000\n",
      "Epoch 770/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6808559616.0000 - val_loss: 8224531456.0000\n",
      "Epoch 771/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6814811648.0000 - val_loss: 8507433984.0000\n",
      "Epoch 772/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7145816064.0000 - val_loss: 8359987200.0000\n",
      "Epoch 773/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7053272064.0000 - val_loss: 8120631808.0000\n",
      "Epoch 774/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7239240192.0000 - val_loss: 8521290240.0000\n",
      "Epoch 775/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7362699264.0000 - val_loss: 9791967232.0000\n",
      "Epoch 776/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7670174208.0000 - val_loss: 8102720000.0000\n",
      "Epoch 777/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7349503488.0000 - val_loss: 8383083008.0000\n",
      "Epoch 778/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7206757888.0000 - val_loss: 8739536896.0000\n",
      "Epoch 779/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7518755328.0000 - val_loss: 8715160576.0000\n",
      "Epoch 780/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7112360448.0000 - val_loss: 7961181184.0000\n",
      "Epoch 781/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7306095104.0000 - val_loss: 8738913280.0000\n",
      "Epoch 782/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7235274240.0000 - val_loss: 7969496064.0000\n",
      "Epoch 783/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6911902720.0000 - val_loss: 8370061312.0000\n",
      "Epoch 784/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6906011136.0000 - val_loss: 8398097920.0000\n",
      "Epoch 785/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7166748672.0000 - val_loss: 7972636672.0000\n",
      "Epoch 786/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6977222144.0000 - val_loss: 7970193920.0000\n",
      "Epoch 787/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7023968256.0000 - val_loss: 7990015488.0000\n",
      "Epoch 788/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6763404288.0000 - val_loss: 8814128128.0000\n",
      "Epoch 789/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7454852096.0000 - val_loss: 8537903616.0000\n",
      "Epoch 790/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7335997952.0000 - val_loss: 8026330624.0000\n",
      "Epoch 791/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6873003008.0000 - val_loss: 8079908864.0000\n",
      "Epoch 792/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7015059456.0000 - val_loss: 8489652736.0000\n",
      "Epoch 793/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7274310656.0000 - val_loss: 7966299648.0000\n",
      "Epoch 794/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6949739008.0000 - val_loss: 8238267904.0000\n",
      "Epoch 795/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6790834176.0000 - val_loss: 7928120320.0000\n",
      "Epoch 796/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6993015296.0000 - val_loss: 8098601472.0000\n",
      "Epoch 797/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6952817152.0000 - val_loss: 8432270336.0000\n",
      "Epoch 798/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6976256000.0000 - val_loss: 8175545344.0000\n",
      "Epoch 799/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7137890816.0000 - val_loss: 7987246592.0000\n",
      "Epoch 800/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6856590848.0000 - val_loss: 7945721856.0000\n",
      "Epoch 801/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7339776000.0000 - val_loss: 7999929344.0000\n",
      "Epoch 802/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6771704320.0000 - val_loss: 7969104896.0000\n",
      "Epoch 803/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6947747328.0000 - val_loss: 7960905216.0000\n",
      "Epoch 804/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6853137920.0000 - val_loss: 7968204288.0000\n",
      "Epoch 805/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6625258496.0000 - val_loss: 7964483584.0000\n",
      "Epoch 806/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6757515776.0000 - val_loss: 7994595840.0000\n",
      "Epoch 807/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6877557760.0000 - val_loss: 8900638720.0000\n",
      "Epoch 808/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7897383936.0000 - val_loss: 8156019712.0000\n",
      "Epoch 809/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7088849920.0000 - val_loss: 8178122240.0000\n",
      "Epoch 810/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7147198976.0000 - val_loss: 8522992640.0000\n",
      "Epoch 811/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7079811584.0000 - val_loss: 7969700864.0000\n",
      "Epoch 812/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6936515584.0000 - val_loss: 7946644480.0000\n",
      "Epoch 813/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6764267520.0000 - val_loss: 8058671616.0000\n",
      "Epoch 814/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6776005120.0000 - val_loss: 8341948416.0000\n",
      "Epoch 815/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7160309760.0000 - val_loss: 7976585216.0000\n",
      "Epoch 816/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7063261184.0000 - val_loss: 8110728704.0000\n",
      "Epoch 817/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7068397056.0000 - val_loss: 7972868096.0000\n",
      "Epoch 818/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6961155072.0000 - val_loss: 8050046464.0000\n",
      "Epoch 819/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6903455232.0000 - val_loss: 8443983872.0000\n",
      "Epoch 820/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7157869568.0000 - val_loss: 8106060288.0000\n",
      "Epoch 821/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6846242816.0000 - val_loss: 8574330880.0000\n",
      "Epoch 822/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7136803840.0000 - val_loss: 8036517888.0000\n",
      "Epoch 823/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6943920128.0000 - val_loss: 8058451968.0000\n",
      "Epoch 824/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7037964800.0000 - val_loss: 8954875904.0000\n",
      "Epoch 825/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7709032448.0000 - val_loss: 8133640704.0000\n",
      "Epoch 826/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6914524672.0000 - val_loss: 7996218368.0000\n",
      "Epoch 827/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7061655552.0000 - val_loss: 8211111936.0000\n",
      "Epoch 828/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7072257536.0000 - val_loss: 7970770944.0000\n",
      "Epoch 829/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6780191232.0000 - val_loss: 8005393408.0000\n",
      "Epoch 830/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6861170688.0000 - val_loss: 7991127040.0000\n",
      "Epoch 831/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6835319808.0000 - val_loss: 8121352192.0000\n",
      "Epoch 832/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6999126016.0000 - val_loss: 8261834752.0000\n",
      "Epoch 833/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7470839296.0000 - val_loss: 8092772864.0000\n",
      "Epoch 834/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7436905472.0000 - val_loss: 8142765056.0000\n",
      "Epoch 835/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6958749184.0000 - val_loss: 7966537216.0000\n",
      "Epoch 836/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6999993856.0000 - val_loss: 8300176896.0000\n",
      "Epoch 837/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7007440896.0000 - val_loss: 8025208832.0000\n",
      "Epoch 838/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7060301824.0000 - val_loss: 8005959168.0000\n",
      "Epoch 839/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6882575360.0000 - val_loss: 8319969792.0000\n",
      "Epoch 840/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6932510208.0000 - val_loss: 8002127872.0000\n",
      "Epoch 841/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6865712128.0000 - val_loss: 7960043520.0000\n",
      "Epoch 842/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6967716864.0000 - val_loss: 8527924224.0000\n",
      "Epoch 843/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7103260672.0000 - val_loss: 8890396672.0000\n",
      "Epoch 844/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7790683136.0000 - val_loss: 8460633600.0000\n",
      "Epoch 845/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7316857344.0000 - val_loss: 8525358080.0000\n",
      "Epoch 846/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6891100160.0000 - val_loss: 7954882560.0000\n",
      "Epoch 847/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7036216320.0000 - val_loss: 7999972352.0000\n",
      "Epoch 848/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7011323904.0000 - val_loss: 8030874624.0000\n",
      "Epoch 849/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6984439296.0000 - val_loss: 7986696192.0000\n",
      "Epoch 850/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6857123840.0000 - val_loss: 7940436480.0000\n",
      "Epoch 851/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7020992512.0000 - val_loss: 8175301632.0000\n",
      "Epoch 852/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7103829504.0000 - val_loss: 7951701504.0000\n",
      "Epoch 853/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6750586368.0000 - val_loss: 7967987200.0000\n",
      "Epoch 854/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6801774080.0000 - val_loss: 7959407616.0000\n",
      "Epoch 855/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6957078528.0000 - val_loss: 7957582848.0000\n",
      "Epoch 856/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6937310208.0000 - val_loss: 7972036608.0000\n",
      "Epoch 857/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6823459840.0000 - val_loss: 8084490752.0000\n",
      "Epoch 858/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7008560640.0000 - val_loss: 7932362240.0000\n",
      "Epoch 859/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7047437312.0000 - val_loss: 8086517248.0000\n",
      "Epoch 860/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6991448064.0000 - val_loss: 8204185088.0000\n",
      "Epoch 861/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7322413568.0000 - val_loss: 8131425280.0000\n",
      "Epoch 862/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6940741632.0000 - val_loss: 8060944384.0000\n",
      "Epoch 863/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6942653440.0000 - val_loss: 8029131776.0000\n",
      "Epoch 864/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6787291136.0000 - val_loss: 8230235136.0000\n",
      "Epoch 865/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7008317952.0000 - val_loss: 8160854016.0000\n",
      "Epoch 866/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7376182272.0000 - val_loss: 7942369792.0000\n",
      "Epoch 867/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7224711680.0000 - val_loss: 7939728896.0000\n",
      "Epoch 868/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6825133056.0000 - val_loss: 9524825088.0000\n",
      "Epoch 869/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7597134848.0000 - val_loss: 8137569792.0000\n",
      "Epoch 870/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7713620992.0000 - val_loss: 8027315712.0000\n",
      "Epoch 871/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7153043456.0000 - val_loss: 7961117696.0000\n",
      "Epoch 872/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6987774464.0000 - val_loss: 7931458560.0000\n",
      "Epoch 873/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6637137920.0000 - val_loss: 8027925504.0000\n",
      "Epoch 874/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6909372928.0000 - val_loss: 7935658496.0000\n",
      "Epoch 875/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7118761472.0000 - val_loss: 7979544064.0000\n",
      "Epoch 876/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6841457664.0000 - val_loss: 7961527808.0000\n",
      "Epoch 877/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6982906880.0000 - val_loss: 7994912256.0000\n",
      "Epoch 878/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6945186816.0000 - val_loss: 8558475264.0000\n",
      "Epoch 879/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7013571584.0000 - val_loss: 7939797504.0000\n",
      "Epoch 880/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6795322368.0000 - val_loss: 8003241472.0000\n",
      "Epoch 881/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6774376960.0000 - val_loss: 8167825920.0000\n",
      "Epoch 882/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6782722048.0000 - val_loss: 7932117504.0000\n",
      "Epoch 883/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7167596032.0000 - val_loss: 9011695616.0000\n",
      "Epoch 884/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7297354752.0000 - val_loss: 7996560896.0000\n",
      "Epoch 885/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6972139520.0000 - val_loss: 8012304896.0000\n",
      "Epoch 886/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6916367872.0000 - val_loss: 8775642112.0000\n",
      "Epoch 887/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7436657152.0000 - val_loss: 8113448960.0000\n",
      "Epoch 888/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6744691200.0000 - val_loss: 7915585024.0000\n",
      "Epoch 889/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6857401856.0000 - val_loss: 9194948608.0000\n",
      "Epoch 890/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7282373632.0000 - val_loss: 8055880192.0000\n",
      "Epoch 891/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7005231616.0000 - val_loss: 9022787584.0000\n",
      "Epoch 892/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7359782400.0000 - val_loss: 8185938944.0000\n",
      "Epoch 893/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7190884352.0000 - val_loss: 8002411008.0000\n",
      "Epoch 894/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6992728064.0000 - val_loss: 7957661696.0000\n",
      "Epoch 895/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7017104384.0000 - val_loss: 7941309952.0000\n",
      "Epoch 896/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7009641984.0000 - val_loss: 9243370496.0000\n",
      "Epoch 897/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7348356608.0000 - val_loss: 8666894336.0000\n",
      "Epoch 898/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7274603008.0000 - val_loss: 8074837504.0000\n",
      "Epoch 899/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6820679168.0000 - val_loss: 8010975744.0000\n",
      "Epoch 900/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6635960320.0000 - val_loss: 7954148864.0000\n",
      "Epoch 901/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6833571328.0000 - val_loss: 7925835776.0000\n",
      "Epoch 902/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6916291584.0000 - val_loss: 7975294464.0000\n",
      "Epoch 903/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6973347840.0000 - val_loss: 8560197632.0000\n",
      "Epoch 904/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6971188224.0000 - val_loss: 7922697216.0000\n",
      "Epoch 905/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6854610432.0000 - val_loss: 8908736512.0000\n",
      "Epoch 906/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7292482048.0000 - val_loss: 7934046208.0000\n",
      "Epoch 907/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6834994176.0000 - val_loss: 8114728960.0000\n",
      "Epoch 908/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6751005696.0000 - val_loss: 8440144896.0000\n",
      "Epoch 909/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7092135936.0000 - val_loss: 8224365056.0000\n",
      "Epoch 910/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6833306112.0000 - val_loss: 8768759808.0000\n",
      "Epoch 911/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7300892160.0000 - val_loss: 7951872512.0000\n",
      "Epoch 912/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7201535488.0000 - val_loss: 8242122240.0000\n",
      "Epoch 913/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7464418816.0000 - val_loss: 7974147584.0000\n",
      "Epoch 914/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6882405888.0000 - val_loss: 8026536960.0000\n",
      "Epoch 915/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7005650944.0000 - val_loss: 8209820672.0000\n",
      "Epoch 916/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7059483648.0000 - val_loss: 8055853568.0000\n",
      "Epoch 917/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6975486976.0000 - val_loss: 8274939392.0000\n",
      "Epoch 918/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7035299328.0000 - val_loss: 7928982528.0000\n",
      "Epoch 919/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7114313728.0000 - val_loss: 9618607104.0000\n",
      "Epoch 920/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7970919936.0000 - val_loss: 8429613568.0000\n",
      "Epoch 921/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7489907712.0000 - val_loss: 7942666752.0000\n",
      "Epoch 922/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7471661056.0000 - val_loss: 8041719808.0000\n",
      "Epoch 923/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6942076416.0000 - val_loss: 8484891136.0000\n",
      "Epoch 924/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7049789440.0000 - val_loss: 7969294336.0000\n",
      "Epoch 925/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6937388032.0000 - val_loss: 8193590272.0000\n",
      "Epoch 926/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6962292736.0000 - val_loss: 8006908928.0000\n",
      "Epoch 927/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6871284736.0000 - val_loss: 8311204352.0000\n",
      "Epoch 928/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6875932672.0000 - val_loss: 8341337088.0000\n",
      "Epoch 929/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7145263616.0000 - val_loss: 7948296192.0000\n",
      "Epoch 930/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7100531200.0000 - val_loss: 8393592320.0000\n",
      "Epoch 931/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7151178240.0000 - val_loss: 7986269696.0000\n",
      "Epoch 932/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6706113024.0000 - val_loss: 7955953152.0000\n",
      "Epoch 933/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6895616000.0000 - val_loss: 8474407936.0000\n",
      "Epoch 934/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6971148288.0000 - val_loss: 8020061696.0000\n",
      "Epoch 935/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6748262912.0000 - val_loss: 8118131712.0000\n",
      "Epoch 936/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6873661440.0000 - val_loss: 8265130496.0000\n",
      "Epoch 937/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6913692672.0000 - val_loss: 8004954624.0000\n",
      "Epoch 938/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7099447296.0000 - val_loss: 8098006016.0000\n",
      "Epoch 939/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6818806784.0000 - val_loss: 8087205888.0000\n",
      "Epoch 940/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7103921664.0000 - val_loss: 8080065024.0000\n",
      "Epoch 941/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6903174656.0000 - val_loss: 7933304320.0000\n",
      "Epoch 942/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6792593920.0000 - val_loss: 8185297408.0000\n",
      "Epoch 943/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7094173696.0000 - val_loss: 8200012800.0000\n",
      "Epoch 944/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7271473664.0000 - val_loss: 7932830208.0000\n",
      "Epoch 945/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6805746688.0000 - val_loss: 8048303104.0000\n",
      "Epoch 946/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6837896704.0000 - val_loss: 8013398528.0000\n",
      "Epoch 947/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7203345920.0000 - val_loss: 8077911552.0000\n",
      "Epoch 948/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6995142656.0000 - val_loss: 7943258112.0000\n",
      "Epoch 949/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6866416640.0000 - val_loss: 7924291072.0000\n",
      "Epoch 950/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6796660224.0000 - val_loss: 7938721280.0000\n",
      "Epoch 951/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6922822656.0000 - val_loss: 8284981760.0000\n",
      "Epoch 952/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7021480448.0000 - val_loss: 7962336768.0000\n",
      "Epoch 953/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7182076928.0000 - val_loss: 8140506112.0000\n",
      "Epoch 954/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6926870016.0000 - val_loss: 7944721408.0000\n",
      "Epoch 955/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6929358336.0000 - val_loss: 8035660800.0000\n",
      "Epoch 956/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7072835584.0000 - val_loss: 7974824448.0000\n",
      "Epoch 957/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7110136320.0000 - val_loss: 8217986560.0000\n",
      "Epoch 958/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7126160384.0000 - val_loss: 8035480576.0000\n",
      "Epoch 959/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7029451776.0000 - val_loss: 8720050176.0000\n",
      "Epoch 960/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7073789440.0000 - val_loss: 7961389568.0000\n",
      "Epoch 961/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6739182592.0000 - val_loss: 8068883456.0000\n",
      "Epoch 962/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6987027968.0000 - val_loss: 8240823296.0000\n",
      "Epoch 963/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7001416192.0000 - val_loss: 7931407872.0000\n",
      "Epoch 964/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7183301120.0000 - val_loss: 8395205632.0000\n",
      "Epoch 965/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7070282752.0000 - val_loss: 8020597248.0000\n",
      "Epoch 966/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6994180608.0000 - val_loss: 8376473088.0000\n",
      "Epoch 967/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7016845312.0000 - val_loss: 7916156928.0000\n",
      "Epoch 968/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6868564992.0000 - val_loss: 7927015424.0000\n",
      "Epoch 969/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7004487168.0000 - val_loss: 9079263232.0000\n",
      "Epoch 970/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7396362752.0000 - val_loss: 8253989376.0000\n",
      "Epoch 971/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7402354688.0000 - val_loss: 8634673152.0000\n",
      "Epoch 972/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7552555520.0000 - val_loss: 9484277760.0000\n",
      "Epoch 973/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7555611648.0000 - val_loss: 8821374976.0000\n",
      "Epoch 974/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7506819584.0000 - val_loss: 8466135040.0000\n",
      "Epoch 975/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7360185344.0000 - val_loss: 8024887808.0000\n",
      "Epoch 976/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6732183040.0000 - val_loss: 7924621312.0000\n",
      "Epoch 977/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6887716352.0000 - val_loss: 7989288448.0000\n",
      "Epoch 978/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7149138944.0000 - val_loss: 8176409600.0000\n",
      "Epoch 979/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7142034432.0000 - val_loss: 7942516736.0000\n",
      "Epoch 980/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7689791488.0000 - val_loss: 8025629184.0000\n",
      "Epoch 981/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7438337024.0000 - val_loss: 8678882304.0000\n",
      "Epoch 982/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7050800128.0000 - val_loss: 8338538496.0000\n",
      "Epoch 983/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6930262016.0000 - val_loss: 7990513664.0000\n",
      "Epoch 984/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6859559936.0000 - val_loss: 8181057536.0000\n",
      "Epoch 985/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7227684352.0000 - val_loss: 7896721920.0000\n",
      "Epoch 986/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6908591104.0000 - val_loss: 8271888896.0000\n",
      "Epoch 987/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6965310976.0000 - val_loss: 7942085632.0000\n",
      "Epoch 988/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6825336320.0000 - val_loss: 7938230784.0000\n",
      "Epoch 989/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6661177344.0000 - val_loss: 7985256448.0000\n",
      "Epoch 990/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6931914752.0000 - val_loss: 8015787520.0000\n",
      "Epoch 991/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7435618304.0000 - val_loss: 7987624960.0000\n",
      "Epoch 992/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6906302464.0000 - val_loss: 8749348864.0000\n",
      "Epoch 993/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7268607488.0000 - val_loss: 8874705920.0000\n",
      "Epoch 994/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7239718912.0000 - val_loss: 7981517824.0000\n",
      "Epoch 995/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7022036480.0000 - val_loss: 7945335296.0000\n",
      "Epoch 996/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7088525824.0000 - val_loss: 7940804608.0000\n",
      "Epoch 997/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6863268864.0000 - val_loss: 8019386368.0000\n",
      "Epoch 998/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6985708032.0000 - val_loss: 8186768896.0000\n",
      "Epoch 999/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7122641408.0000 - val_loss: 7957868544.0000\n",
      "Epoch 1000/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6965491200.0000 - val_loss: 7913656832.0000\n",
      "Epoch 1001/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6798194688.0000 - val_loss: 7892909056.0000\n",
      "Epoch 1002/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6967010304.0000 - val_loss: 7981157888.0000\n",
      "Epoch 1003/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6879038464.0000 - val_loss: 7922027008.0000\n",
      "Epoch 1004/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7000495104.0000 - val_loss: 7998604288.0000\n",
      "Epoch 1005/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6877753856.0000 - val_loss: 7888449024.0000\n",
      "Epoch 1006/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6809034752.0000 - val_loss: 7893474304.0000\n",
      "Epoch 1007/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6801929216.0000 - val_loss: 7971163648.0000\n",
      "Epoch 1008/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6853367808.0000 - val_loss: 7938903552.0000\n",
      "Epoch 1009/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6701034496.0000 - val_loss: 8634350592.0000\n",
      "Epoch 1010/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7026599936.0000 - val_loss: 8218593280.0000\n",
      "Epoch 1011/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6839815168.0000 - val_loss: 8170125312.0000\n",
      "Epoch 1012/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6880994304.0000 - val_loss: 7971770368.0000\n",
      "Epoch 1013/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7004836864.0000 - val_loss: 7923473408.0000\n",
      "Epoch 1014/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6736956416.0000 - val_loss: 7920652800.0000\n",
      "Epoch 1015/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6799319040.0000 - val_loss: 8138855424.0000\n",
      "Epoch 1016/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7001191936.0000 - val_loss: 7926367744.0000\n",
      "Epoch 1017/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6944624640.0000 - val_loss: 8552758784.0000\n",
      "Epoch 1018/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6999324672.0000 - val_loss: 7976993280.0000\n",
      "Epoch 1019/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7028941824.0000 - val_loss: 7958167552.0000\n",
      "Epoch 1020/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6713700352.0000 - val_loss: 8044062720.0000\n",
      "Epoch 1021/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6760174592.0000 - val_loss: 8019680768.0000\n",
      "Epoch 1022/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6757003264.0000 - val_loss: 8251857408.0000\n",
      "Epoch 1023/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6988976128.0000 - val_loss: 8323619840.0000\n",
      "Epoch 1024/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7375661056.0000 - val_loss: 7969993216.0000\n",
      "Epoch 1025/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6822896640.0000 - val_loss: 7913788928.0000\n",
      "Epoch 1026/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6766351360.0000 - val_loss: 8247863808.0000\n",
      "Epoch 1027/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7219061248.0000 - val_loss: 8156017152.0000\n",
      "Epoch 1028/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7035858944.0000 - val_loss: 8120759808.0000\n",
      "Epoch 1029/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7045836288.0000 - val_loss: 7930398208.0000\n",
      "Epoch 1030/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6764783616.0000 - val_loss: 8107443712.0000\n",
      "Epoch 1031/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7174391808.0000 - val_loss: 7914229248.0000\n",
      "Epoch 1032/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6759537664.0000 - val_loss: 7986339328.0000\n",
      "Epoch 1033/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6935732224.0000 - val_loss: 7926689792.0000\n",
      "Epoch 1034/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6790272000.0000 - val_loss: 8056425984.0000\n",
      "Epoch 1035/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6940727296.0000 - val_loss: 8964609024.0000\n",
      "Epoch 1036/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7759435776.0000 - val_loss: 8771994624.0000\n",
      "Epoch 1037/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7310117376.0000 - val_loss: 8031225856.0000\n",
      "Epoch 1038/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6544701952.0000 - val_loss: 8028890624.0000\n",
      "Epoch 1039/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6644470272.0000 - val_loss: 7912205824.0000\n",
      "Epoch 1040/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6868172800.0000 - val_loss: 7903259648.0000\n",
      "Epoch 1041/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6770505216.0000 - val_loss: 7946111488.0000\n",
      "Epoch 1042/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6735168512.0000 - val_loss: 7902589440.0000\n",
      "Epoch 1043/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6733839360.0000 - val_loss: 8316189184.0000\n",
      "Epoch 1044/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6796569088.0000 - val_loss: 8741891072.0000\n",
      "Epoch 1045/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7141307392.0000 - val_loss: 8221650432.0000\n",
      "Epoch 1046/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7909720576.0000 - val_loss: 8594648064.0000\n",
      "Epoch 1047/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7298614272.0000 - val_loss: 8301444608.0000\n",
      "Epoch 1048/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7361432576.0000 - val_loss: 9231578112.0000\n",
      "Epoch 1049/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7997224960.0000 - val_loss: 8924747776.0000\n",
      "Epoch 1050/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7243843584.0000 - val_loss: 8133657600.0000\n",
      "Epoch 1051/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6806177280.0000 - val_loss: 8045393920.0000\n",
      "Epoch 1052/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6952945664.0000 - val_loss: 8579682816.0000\n",
      "Epoch 1053/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7500767744.0000 - val_loss: 8485406720.0000\n",
      "Epoch 1054/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7107089408.0000 - val_loss: 8146270208.0000\n",
      "Epoch 1055/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6941819392.0000 - val_loss: 8058511872.0000\n",
      "Epoch 1056/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6922872832.0000 - val_loss: 10852836352.0000\n",
      "Epoch 1057/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8074395648.0000 - val_loss: 8406398976.0000\n",
      "Epoch 1058/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7223654912.0000 - val_loss: 8031854592.0000\n",
      "Epoch 1059/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6988417536.0000 - val_loss: 7989705216.0000\n",
      "Epoch 1060/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7050158080.0000 - val_loss: 8142392320.0000\n",
      "Epoch 1061/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6891894272.0000 - val_loss: 8156874240.0000\n",
      "Epoch 1062/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6917446144.0000 - val_loss: 8139559424.0000\n",
      "Epoch 1063/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6892283904.0000 - val_loss: 8399908864.0000\n",
      "Epoch 1064/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7121846272.0000 - val_loss: 8379335680.0000\n",
      "Epoch 1065/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7355516928.0000 - val_loss: 8232779776.0000\n",
      "Epoch 1066/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6922147328.0000 - val_loss: 7960875008.0000\n",
      "Epoch 1067/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6899614208.0000 - val_loss: 8004345344.0000\n",
      "Epoch 1068/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6966679040.0000 - val_loss: 7917367808.0000\n",
      "Epoch 1069/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6772810240.0000 - val_loss: 8214377984.0000\n",
      "Epoch 1070/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6977245184.0000 - val_loss: 7991068160.0000\n",
      "Epoch 1071/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6868209664.0000 - val_loss: 8073923072.0000\n",
      "Epoch 1072/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6844243968.0000 - val_loss: 8762068992.0000\n",
      "Epoch 1073/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6886310912.0000 - val_loss: 7886118912.0000\n",
      "Epoch 1074/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6924364288.0000 - val_loss: 8266442752.0000\n",
      "Epoch 1075/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6867563520.0000 - val_loss: 8090522112.0000\n",
      "Epoch 1076/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6950080512.0000 - val_loss: 7885337088.0000\n",
      "Epoch 1077/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6794462208.0000 - val_loss: 8058745856.0000\n",
      "Epoch 1078/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6795532288.0000 - val_loss: 8218366976.0000\n",
      "Epoch 1079/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6723296256.0000 - val_loss: 7925302272.0000\n",
      "Epoch 1080/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6678025728.0000 - val_loss: 8029731840.0000\n",
      "Epoch 1081/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6860552704.0000 - val_loss: 8622706688.0000\n",
      "Epoch 1082/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7032437248.0000 - val_loss: 8654124032.0000\n",
      "Epoch 1083/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7474043392.0000 - val_loss: 9456489472.0000\n",
      "Epoch 1084/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7961511936.0000 - val_loss: 8696554496.0000\n",
      "Epoch 1085/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7294804480.0000 - val_loss: 8656209920.0000\n",
      "Epoch 1086/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7107377664.0000 - val_loss: 8047698432.0000\n",
      "Epoch 1087/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7136017920.0000 - val_loss: 8020507648.0000\n",
      "Epoch 1088/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6858691584.0000 - val_loss: 8586530816.0000\n",
      "Epoch 1089/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7074439680.0000 - val_loss: 7936565248.0000\n",
      "Epoch 1090/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6848325632.0000 - val_loss: 7960499200.0000\n",
      "Epoch 1091/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7116168704.0000 - val_loss: 8095620608.0000\n",
      "Epoch 1092/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7090344448.0000 - val_loss: 8234313216.0000\n",
      "Epoch 1093/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7090950144.0000 - val_loss: 7965149184.0000\n",
      "Epoch 1094/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7008348160.0000 - val_loss: 7908234752.0000\n",
      "Epoch 1095/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6839342080.0000 - val_loss: 7921819136.0000\n",
      "Epoch 1096/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6757455872.0000 - val_loss: 7980772864.0000\n",
      "Epoch 1097/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6839304704.0000 - val_loss: 8601597952.0000\n",
      "Epoch 1098/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7568242176.0000 - val_loss: 9148416000.0000\n",
      "Epoch 1099/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7462137856.0000 - val_loss: 8454025216.0000\n",
      "Epoch 1100/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7123850752.0000 - val_loss: 7961744896.0000\n",
      "Epoch 1101/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6877149696.0000 - val_loss: 8495767552.0000\n",
      "Epoch 1102/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7300546560.0000 - val_loss: 8129137664.0000\n",
      "Epoch 1103/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7030031872.0000 - val_loss: 8130446336.0000\n",
      "Epoch 1104/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7057866240.0000 - val_loss: 8510856704.0000\n",
      "Epoch 1105/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7104322048.0000 - val_loss: 8021282304.0000\n",
      "Epoch 1106/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6935180800.0000 - val_loss: 7990187520.0000\n",
      "Epoch 1107/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6923857408.0000 - val_loss: 7966388224.0000\n",
      "Epoch 1108/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6836456960.0000 - val_loss: 7947118592.0000\n",
      "Epoch 1109/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6758430720.0000 - val_loss: 7940786688.0000\n",
      "Epoch 1110/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6932121600.0000 - val_loss: 7915016704.0000\n",
      "Epoch 1111/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6894696448.0000 - val_loss: 7943895040.0000\n",
      "Epoch 1112/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7104497152.0000 - val_loss: 7969155072.0000\n",
      "Epoch 1113/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6874748416.0000 - val_loss: 8190334976.0000\n",
      "Epoch 1114/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7005736448.0000 - val_loss: 8015075840.0000\n",
      "Epoch 1115/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7172480000.0000 - val_loss: 8012155392.0000\n",
      "Epoch 1116/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7376719872.0000 - val_loss: 7891716096.0000\n",
      "Epoch 1117/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6667369472.0000 - val_loss: 8109593600.0000\n",
      "Epoch 1118/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6673481216.0000 - val_loss: 7921971712.0000\n",
      "Epoch 1119/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6769222656.0000 - val_loss: 8086849024.0000\n",
      "Epoch 1120/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6913893888.0000 - val_loss: 7907572224.0000\n",
      "Epoch 1121/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6722877952.0000 - val_loss: 8160467968.0000\n",
      "Epoch 1122/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6971334656.0000 - val_loss: 8210953728.0000\n",
      "Epoch 1123/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7201549824.0000 - val_loss: 7901075456.0000\n",
      "Epoch 1124/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6760560128.0000 - val_loss: 8421251072.0000\n",
      "Epoch 1125/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7350658048.0000 - val_loss: 8037310464.0000\n",
      "Epoch 1126/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6879489024.0000 - val_loss: 7984951296.0000\n",
      "Epoch 1127/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7172002816.0000 - val_loss: 8104508928.0000\n",
      "Epoch 1128/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6909711872.0000 - val_loss: 7894607360.0000\n",
      "Epoch 1129/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6892569600.0000 - val_loss: 7926400000.0000\n",
      "Epoch 1130/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6693761024.0000 - val_loss: 8164751872.0000\n",
      "Epoch 1131/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6770835456.0000 - val_loss: 8102309888.0000\n",
      "Epoch 1132/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7117734400.0000 - val_loss: 8246416896.0000\n",
      "Epoch 1133/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7510770176.0000 - val_loss: 9103423488.0000\n",
      "Epoch 1134/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7219693056.0000 - val_loss: 8028981760.0000\n",
      "Epoch 1135/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6933832192.0000 - val_loss: 9054838784.0000\n",
      "Epoch 1136/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7263115264.0000 - val_loss: 8135195648.0000\n",
      "Epoch 1137/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7021737472.0000 - val_loss: 7941150208.0000\n",
      "Epoch 1138/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7011575808.0000 - val_loss: 8004343296.0000\n",
      "Epoch 1139/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6660512256.0000 - val_loss: 7922636288.0000\n",
      "Epoch 1140/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6797137920.0000 - val_loss: 8119998464.0000\n",
      "Epoch 1141/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6717298688.0000 - val_loss: 8054332416.0000\n",
      "Epoch 1142/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6902422528.0000 - val_loss: 9365808128.0000\n",
      "Epoch 1143/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7548209152.0000 - val_loss: 8160890880.0000\n",
      "Epoch 1144/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6822081024.0000 - val_loss: 8807456768.0000\n",
      "Epoch 1145/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7413412352.0000 - val_loss: 8087676416.0000\n",
      "Epoch 1146/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7042389504.0000 - val_loss: 8160083968.0000\n",
      "Epoch 1147/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7325723648.0000 - val_loss: 8296609792.0000\n",
      "Epoch 1148/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6922238976.0000 - val_loss: 7931807232.0000\n",
      "Epoch 1149/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6633408512.0000 - val_loss: 7975437312.0000\n",
      "Epoch 1150/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6832882176.0000 - val_loss: 7942646784.0000\n",
      "Epoch 1151/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6816915968.0000 - val_loss: 8356474880.0000\n",
      "Epoch 1152/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6931122176.0000 - val_loss: 8464410624.0000\n",
      "Epoch 1153/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6710085632.0000 - val_loss: 8128282112.0000\n",
      "Epoch 1154/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6912449024.0000 - val_loss: 8008759808.0000\n",
      "Epoch 1155/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6735694848.0000 - val_loss: 7904979968.0000\n",
      "Epoch 1156/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6969143296.0000 - val_loss: 8169417728.0000\n",
      "Epoch 1157/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7283062272.0000 - val_loss: 7872990720.0000\n",
      "Epoch 1158/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6721448960.0000 - val_loss: 7927185920.0000\n",
      "Epoch 1159/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6732847616.0000 - val_loss: 7882062848.0000\n",
      "Epoch 1160/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7039147008.0000 - val_loss: 8244835328.0000\n",
      "Epoch 1161/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6947176448.0000 - val_loss: 8116505088.0000\n",
      "Epoch 1162/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6900738560.0000 - val_loss: 8004587008.0000\n",
      "Epoch 1163/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7471095808.0000 - val_loss: 8249707520.0000\n",
      "Epoch 1164/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7379768832.0000 - val_loss: 8000999936.0000\n",
      "Epoch 1165/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6807825408.0000 - val_loss: 8005159936.0000\n",
      "Epoch 1166/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6850772992.0000 - val_loss: 7914676736.0000\n",
      "Epoch 1167/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6788759552.0000 - val_loss: 8090111488.0000\n",
      "Epoch 1168/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6831086080.0000 - val_loss: 7980521984.0000\n",
      "Epoch 1169/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6739366400.0000 - val_loss: 9533735936.0000\n",
      "Epoch 1170/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7460983296.0000 - val_loss: 9064205312.0000\n",
      "Epoch 1171/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7717748736.0000 - val_loss: 10427261952.0000\n",
      "Epoch 1172/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7814350336.0000 - val_loss: 8106118144.0000\n",
      "Epoch 1173/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6968176128.0000 - val_loss: 8290708992.0000\n",
      "Epoch 1174/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6897999360.0000 - val_loss: 8543234560.0000\n",
      "Epoch 1175/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7235016192.0000 - val_loss: 8540954624.0000\n",
      "Epoch 1176/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7113461248.0000 - val_loss: 7924829696.0000\n",
      "Epoch 1177/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7088449024.0000 - val_loss: 8094472192.0000\n",
      "Epoch 1178/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6907103744.0000 - val_loss: 7899948032.0000\n",
      "Epoch 1179/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6884367872.0000 - val_loss: 8563230208.0000\n",
      "Epoch 1180/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6997669888.0000 - val_loss: 8339142144.0000\n",
      "Epoch 1181/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6901642240.0000 - val_loss: 7922232320.0000\n",
      "Epoch 1182/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6755603456.0000 - val_loss: 7938597376.0000\n",
      "Epoch 1183/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6581268992.0000 - val_loss: 8121635328.0000\n",
      "Epoch 1184/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6764793344.0000 - val_loss: 7878084096.0000\n",
      "Epoch 1185/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6662020096.0000 - val_loss: 7920316928.0000\n",
      "Epoch 1186/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6805369856.0000 - val_loss: 7972283392.0000\n",
      "Epoch 1187/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6778434560.0000 - val_loss: 8347944960.0000\n",
      "Epoch 1188/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7168959488.0000 - val_loss: 7944747008.0000\n",
      "Epoch 1189/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6738165760.0000 - val_loss: 7884327424.0000\n",
      "Epoch 1190/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6775428096.0000 - val_loss: 7952072704.0000\n",
      "Epoch 1191/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6902063616.0000 - val_loss: 8616278016.0000\n",
      "Epoch 1192/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7191294464.0000 - val_loss: 9033540608.0000\n",
      "Epoch 1193/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7332735488.0000 - val_loss: 9392620544.0000\n",
      "Epoch 1194/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7570593280.0000 - val_loss: 8699483136.0000\n",
      "Epoch 1195/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7303063040.0000 - val_loss: 8470876160.0000\n",
      "Epoch 1196/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7428938752.0000 - val_loss: 7893009408.0000\n",
      "Epoch 1197/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7291781632.0000 - val_loss: 7894426624.0000\n",
      "Epoch 1198/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6764006400.0000 - val_loss: 7967927296.0000\n",
      "Epoch 1199/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6828615168.0000 - val_loss: 8033398272.0000\n",
      "Epoch 1200/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6786331648.0000 - val_loss: 8560944128.0000\n",
      "Epoch 1201/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6949427200.0000 - val_loss: 7899809792.0000\n",
      "Epoch 1202/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6855683072.0000 - val_loss: 8115773440.0000\n",
      "Epoch 1203/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6901574656.0000 - val_loss: 7967409664.0000\n",
      "Epoch 1204/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6720027136.0000 - val_loss: 7888976384.0000\n",
      "Epoch 1205/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6808230912.0000 - val_loss: 9049034752.0000\n",
      "Epoch 1206/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7574344704.0000 - val_loss: 7969469952.0000\n",
      "Epoch 1207/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6926834176.0000 - val_loss: 7934287872.0000\n",
      "Epoch 1208/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6771800576.0000 - val_loss: 7887661056.0000\n",
      "Epoch 1209/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6762950656.0000 - val_loss: 7904195584.0000\n",
      "Epoch 1210/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6734911488.0000 - val_loss: 7904717824.0000\n",
      "Epoch 1211/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6854269440.0000 - val_loss: 8242350592.0000\n",
      "Epoch 1212/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6936306176.0000 - val_loss: 8634785792.0000\n",
      "Epoch 1213/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7073489408.0000 - val_loss: 7941139968.0000\n",
      "Epoch 1214/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6663758336.0000 - val_loss: 8226698240.0000\n",
      "Epoch 1215/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7084531712.0000 - val_loss: 8835080192.0000\n",
      "Epoch 1216/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7342081536.0000 - val_loss: 9517339648.0000\n",
      "Epoch 1217/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7599179776.0000 - val_loss: 8573347840.0000\n",
      "Epoch 1218/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6901955072.0000 - val_loss: 7920038400.0000\n",
      "Epoch 1219/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6776365056.0000 - val_loss: 7916532736.0000\n",
      "Epoch 1220/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6753873920.0000 - val_loss: 7893320192.0000\n",
      "Epoch 1221/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6971683840.0000 - val_loss: 7970968064.0000\n",
      "Epoch 1222/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6991449088.0000 - val_loss: 7888879104.0000\n",
      "Epoch 1223/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6666613760.0000 - val_loss: 8034931200.0000\n",
      "Epoch 1224/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6798743552.0000 - val_loss: 7947924480.0000\n",
      "Epoch 1225/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6730382848.0000 - val_loss: 8208008192.0000\n",
      "Epoch 1226/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7001295360.0000 - val_loss: 10486834176.0000\n",
      "Epoch 1227/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8022821888.0000 - val_loss: 8757472256.0000\n",
      "Epoch 1228/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8110732288.0000 - val_loss: 8386264576.0000\n",
      "Epoch 1229/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7502916096.0000 - val_loss: 7961967616.0000\n",
      "Epoch 1230/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6794470912.0000 - val_loss: 8084598784.0000\n",
      "Epoch 1231/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6909377024.0000 - val_loss: 7988086272.0000\n",
      "Epoch 1232/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6957288960.0000 - val_loss: 7924089856.0000\n",
      "Epoch 1233/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6655463936.0000 - val_loss: 7881456128.0000\n",
      "Epoch 1234/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6873153024.0000 - val_loss: 9160226816.0000\n",
      "Epoch 1235/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7363637760.0000 - val_loss: 9695245312.0000\n",
      "Epoch 1236/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7306988544.0000 - val_loss: 7973317120.0000\n",
      "Epoch 1237/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7003768320.0000 - val_loss: 7852637184.0000\n",
      "Epoch 1238/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6856602112.0000 - val_loss: 8001053184.0000\n",
      "Epoch 1239/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6794322432.0000 - val_loss: 7873068544.0000\n",
      "Epoch 1240/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6727785472.0000 - val_loss: 7885838848.0000\n",
      "Epoch 1241/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6892535296.0000 - val_loss: 8251650560.0000\n",
      "Epoch 1242/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6889678336.0000 - val_loss: 7886519296.0000\n",
      "Epoch 1243/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6714582016.0000 - val_loss: 8081641472.0000\n",
      "Epoch 1244/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6969174528.0000 - val_loss: 8426905600.0000\n",
      "Epoch 1245/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6937166848.0000 - val_loss: 8067148288.0000\n",
      "Epoch 1246/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7473237504.0000 - val_loss: 7988815872.0000\n",
      "Epoch 1247/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6974068736.0000 - val_loss: 8252350976.0000\n",
      "Epoch 1248/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6737009664.0000 - val_loss: 7895464960.0000\n",
      "Epoch 1249/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6870320128.0000 - val_loss: 7879414784.0000\n",
      "Epoch 1250/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6335730688.0000 - val_loss: 7979207168.0000\n",
      "Epoch 1251/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6998367232.0000 - val_loss: 7854986240.0000\n",
      "Epoch 1252/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6499579904.0000 - val_loss: 7879247872.0000\n",
      "Epoch 1253/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6551509504.0000 - val_loss: 8101928960.0000\n",
      "Epoch 1254/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6779955200.0000 - val_loss: 7943372800.0000\n",
      "Epoch 1255/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6889821696.0000 - val_loss: 7933559808.0000\n",
      "Epoch 1256/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6725968896.0000 - val_loss: 8537576960.0000\n",
      "Epoch 1257/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6957544960.0000 - val_loss: 8105338368.0000\n",
      "Epoch 1258/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6905491968.0000 - val_loss: 8018027520.0000\n",
      "Epoch 1259/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6811553280.0000 - val_loss: 8016289280.0000\n",
      "Epoch 1260/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6885396992.0000 - val_loss: 7886010368.0000\n",
      "Epoch 1261/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6860100096.0000 - val_loss: 7917062144.0000\n",
      "Epoch 1262/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6702721536.0000 - val_loss: 7887783424.0000\n",
      "Epoch 1263/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6697957888.0000 - val_loss: 7941150208.0000\n",
      "Epoch 1264/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6746469376.0000 - val_loss: 7848304640.0000\n",
      "Epoch 1265/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6931824128.0000 - val_loss: 8115769344.0000\n",
      "Epoch 1266/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6719048192.0000 - val_loss: 8365347840.0000\n",
      "Epoch 1267/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6902944256.0000 - val_loss: 8035523072.0000\n",
      "Epoch 1268/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6961476096.0000 - val_loss: 8181200384.0000\n",
      "Epoch 1269/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6928215552.0000 - val_loss: 8554020352.0000\n",
      "Epoch 1270/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7180987392.0000 - val_loss: 8340645888.0000\n",
      "Epoch 1271/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6909975040.0000 - val_loss: 7933829120.0000\n",
      "Epoch 1272/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6567755264.0000 - val_loss: 7895833600.0000\n",
      "Epoch 1273/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6858401280.0000 - val_loss: 8732436480.0000\n",
      "Epoch 1274/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7384099328.0000 - val_loss: 8759189504.0000\n",
      "Epoch 1275/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7118030848.0000 - val_loss: 7885889024.0000\n",
      "Epoch 1276/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6738104320.0000 - val_loss: 7907738112.0000\n",
      "Epoch 1277/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6785272832.0000 - val_loss: 7919846912.0000\n",
      "Epoch 1278/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6978466816.0000 - val_loss: 8907071488.0000\n",
      "Epoch 1279/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7340954624.0000 - val_loss: 8039958528.0000\n",
      "Epoch 1280/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6931729408.0000 - val_loss: 8165132288.0000\n",
      "Epoch 1281/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7035624448.0000 - val_loss: 7943968256.0000\n",
      "Epoch 1282/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6765533696.0000 - val_loss: 8062763520.0000\n",
      "Epoch 1283/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6907170816.0000 - val_loss: 7900227072.0000\n",
      "Epoch 1284/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7029481472.0000 - val_loss: 8424051712.0000\n",
      "Epoch 1285/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6941080064.0000 - val_loss: 8207475200.0000\n",
      "Epoch 1286/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7062319616.0000 - val_loss: 7974662656.0000\n",
      "Epoch 1287/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6886091776.0000 - val_loss: 7913908736.0000\n",
      "Epoch 1288/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6710658048.0000 - val_loss: 7898002944.0000\n",
      "Epoch 1289/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6779061760.0000 - val_loss: 7913799680.0000\n",
      "Epoch 1290/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6792881664.0000 - val_loss: 8158386176.0000\n",
      "Epoch 1291/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6950025216.0000 - val_loss: 8817303552.0000\n",
      "Epoch 1292/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7565534208.0000 - val_loss: 7935845376.0000\n",
      "Epoch 1293/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6662737408.0000 - val_loss: 9008148480.0000\n",
      "Epoch 1294/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7618502144.0000 - val_loss: 8378604032.0000\n",
      "Epoch 1295/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7286505472.0000 - val_loss: 7867063808.0000\n",
      "Epoch 1296/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7021882880.0000 - val_loss: 7936607232.0000\n",
      "Epoch 1297/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6886297600.0000 - val_loss: 8148796416.0000\n",
      "Epoch 1298/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7138002432.0000 - val_loss: 8242300416.0000\n",
      "Epoch 1299/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7138363392.0000 - val_loss: 8359956480.0000\n",
      "Epoch 1300/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6905495552.0000 - val_loss: 7908162560.0000\n",
      "Epoch 1301/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6722625024.0000 - val_loss: 7950802944.0000\n",
      "Epoch 1302/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6780431360.0000 - val_loss: 7953269248.0000\n",
      "Epoch 1303/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6610320896.0000 - val_loss: 9218962432.0000\n",
      "Epoch 1304/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7354325504.0000 - val_loss: 8339280384.0000\n",
      "Epoch 1305/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7281378304.0000 - val_loss: 8499807232.0000\n",
      "Epoch 1306/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7083217408.0000 - val_loss: 8011401728.0000\n",
      "Epoch 1307/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6615204864.0000 - val_loss: 7939120640.0000\n",
      "Epoch 1308/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6930267136.0000 - val_loss: 8469785088.0000\n",
      "Epoch 1309/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6923350016.0000 - val_loss: 8347581440.0000\n",
      "Epoch 1310/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6833617408.0000 - val_loss: 7850178048.0000\n",
      "Epoch 1311/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6687733760.0000 - val_loss: 7899384832.0000\n",
      "Epoch 1312/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6734380544.0000 - val_loss: 8230869504.0000\n",
      "Epoch 1313/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6897569280.0000 - val_loss: 7970611712.0000\n",
      "Epoch 1314/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6758454784.0000 - val_loss: 7955503104.0000\n",
      "Epoch 1315/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6911460864.0000 - val_loss: 8039667200.0000\n",
      "Epoch 1316/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6876373504.0000 - val_loss: 7951549952.0000\n",
      "Epoch 1317/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6783873536.0000 - val_loss: 8259969536.0000\n",
      "Epoch 1318/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7071462912.0000 - val_loss: 8070632448.0000\n",
      "Epoch 1319/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7265223680.0000 - val_loss: 9196534784.0000\n",
      "Epoch 1320/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7438085120.0000 - val_loss: 9159037952.0000\n",
      "Epoch 1321/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7146112512.0000 - val_loss: 8687369216.0000\n",
      "Epoch 1322/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7039017984.0000 - val_loss: 8853768192.0000\n",
      "Epoch 1323/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7161433088.0000 - val_loss: 8523111424.0000\n",
      "Epoch 1324/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7023354368.0000 - val_loss: 7846836736.0000\n",
      "Epoch 1325/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6537190912.0000 - val_loss: 8385297408.0000\n",
      "Epoch 1326/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6639364096.0000 - val_loss: 7880022528.0000\n",
      "Epoch 1327/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6719225856.0000 - val_loss: 7916248064.0000\n",
      "Epoch 1328/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7110597632.0000 - val_loss: 8168184832.0000\n",
      "Epoch 1329/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6957080576.0000 - val_loss: 8245801472.0000\n",
      "Epoch 1330/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7106033664.0000 - val_loss: 8436475392.0000\n",
      "Epoch 1331/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7388998144.0000 - val_loss: 7874917888.0000\n",
      "Epoch 1332/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6902557184.0000 - val_loss: 7960760832.0000\n",
      "Epoch 1333/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6955052032.0000 - val_loss: 7985955840.0000\n",
      "Epoch 1334/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6704814080.0000 - val_loss: 8133852672.0000\n",
      "Epoch 1335/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7109343744.0000 - val_loss: 8509293568.0000\n",
      "Epoch 1336/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7146525184.0000 - val_loss: 8086610432.0000\n",
      "Epoch 1337/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6706360832.0000 - val_loss: 7927323136.0000\n",
      "Epoch 1338/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6618503680.0000 - val_loss: 7986105344.0000\n",
      "Epoch 1339/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7034320896.0000 - val_loss: 7970889728.0000\n",
      "Epoch 1340/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6594794496.0000 - val_loss: 8077462528.0000\n",
      "Epoch 1341/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7032758784.0000 - val_loss: 8299922944.0000\n",
      "Epoch 1342/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6753446912.0000 - val_loss: 7910551040.0000\n",
      "Epoch 1343/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7093607936.0000 - val_loss: 8044210176.0000\n",
      "Epoch 1344/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7114084864.0000 - val_loss: 7925900800.0000\n",
      "Epoch 1345/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6620188160.0000 - val_loss: 7838529536.0000\n",
      "Epoch 1346/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6830736896.0000 - val_loss: 7968408064.0000\n",
      "Epoch 1347/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6873880576.0000 - val_loss: 7904095232.0000\n",
      "Epoch 1348/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6863361024.0000 - val_loss: 7920339968.0000\n",
      "Epoch 1349/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6835138048.0000 - val_loss: 7851091456.0000\n",
      "Epoch 1350/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6862045696.0000 - val_loss: 7937487872.0000\n",
      "Epoch 1351/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6742316032.0000 - val_loss: 7985121792.0000\n",
      "Epoch 1352/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6860107264.0000 - val_loss: 8352600064.0000\n",
      "Epoch 1353/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7291609600.0000 - val_loss: 7856437760.0000\n",
      "Epoch 1354/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6729701888.0000 - val_loss: 7850510848.0000\n",
      "Epoch 1355/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6314561536.0000 - val_loss: 8071657472.0000\n",
      "Epoch 1356/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6839419904.0000 - val_loss: 8045745152.0000\n",
      "Epoch 1357/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7084908032.0000 - val_loss: 7896183296.0000\n",
      "Epoch 1358/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7007393280.0000 - val_loss: 7925510656.0000\n",
      "Epoch 1359/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6544216064.0000 - val_loss: 7866497024.0000\n",
      "Epoch 1360/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6560590848.0000 - val_loss: 8230147584.0000\n",
      "Epoch 1361/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6851035648.0000 - val_loss: 7909689856.0000\n",
      "Epoch 1362/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6712939520.0000 - val_loss: 7910219776.0000\n",
      "Epoch 1363/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6561467392.0000 - val_loss: 8009862656.0000\n",
      "Epoch 1364/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7125209088.0000 - val_loss: 7939475456.0000\n",
      "Epoch 1365/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6841305600.0000 - val_loss: 7859945472.0000\n",
      "Epoch 1366/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6648277504.0000 - val_loss: 7871436288.0000\n",
      "Epoch 1367/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6930167296.0000 - val_loss: 7904043008.0000\n",
      "Epoch 1368/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6889668608.0000 - val_loss: 9053649920.0000\n",
      "Epoch 1369/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7220458496.0000 - val_loss: 8081910784.0000\n",
      "Epoch 1370/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6854341632.0000 - val_loss: 7886620672.0000\n",
      "Epoch 1371/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6858573312.0000 - val_loss: 7857174016.0000\n",
      "Epoch 1372/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6718479872.0000 - val_loss: 8596516864.0000\n",
      "Epoch 1373/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7190950912.0000 - val_loss: 7876389888.0000\n",
      "Epoch 1374/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6959780352.0000 - val_loss: 8309136384.0000\n",
      "Epoch 1375/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6964783616.0000 - val_loss: 7931908608.0000\n",
      "Epoch 1376/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6790656000.0000 - val_loss: 8195176448.0000\n",
      "Epoch 1377/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6702422528.0000 - val_loss: 7910790656.0000\n",
      "Epoch 1378/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6526233088.0000 - val_loss: 7897795072.0000\n",
      "Epoch 1379/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6921494528.0000 - val_loss: 9433749504.0000\n",
      "Epoch 1380/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7377651712.0000 - val_loss: 7883384832.0000\n",
      "Epoch 1381/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6686716928.0000 - val_loss: 8080010240.0000\n",
      "Epoch 1382/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6969720832.0000 - val_loss: 7895960064.0000\n",
      "Epoch 1383/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6711969792.0000 - val_loss: 7999916032.0000\n",
      "Epoch 1384/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6818996224.0000 - val_loss: 7989151744.0000\n",
      "Epoch 1385/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6696372224.0000 - val_loss: 7885256192.0000\n",
      "Epoch 1386/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7136999424.0000 - val_loss: 8940006400.0000\n",
      "Epoch 1387/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7192070656.0000 - val_loss: 8305826304.0000\n",
      "Epoch 1388/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7172672000.0000 - val_loss: 9248459776.0000\n",
      "Epoch 1389/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7748174336.0000 - val_loss: 7892847616.0000\n",
      "Epoch 1390/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7218771456.0000 - val_loss: 7866452992.0000\n",
      "Epoch 1391/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6909331456.0000 - val_loss: 8794635264.0000\n",
      "Epoch 1392/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7451654144.0000 - val_loss: 8264142848.0000\n",
      "Epoch 1393/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7522258944.0000 - val_loss: 8297281024.0000\n",
      "Epoch 1394/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6705356288.0000 - val_loss: 7920690688.0000\n",
      "Epoch 1395/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6653316096.0000 - val_loss: 7841939456.0000\n",
      "Epoch 1396/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6960699392.0000 - val_loss: 7881317376.0000\n",
      "Epoch 1397/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6867761152.0000 - val_loss: 7928634880.0000\n",
      "Epoch 1398/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6798924288.0000 - val_loss: 8250338816.0000\n",
      "Epoch 1399/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6737132544.0000 - val_loss: 8353948672.0000\n",
      "Epoch 1400/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7058925056.0000 - val_loss: 7853639680.0000\n",
      "Epoch 1401/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6826220032.0000 - val_loss: 8150475776.0000\n",
      "Epoch 1402/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6903987200.0000 - val_loss: 7895955968.0000\n",
      "Epoch 1403/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6628001280.0000 - val_loss: 7836896768.0000\n",
      "Epoch 1404/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6612658176.0000 - val_loss: 7896792064.0000\n",
      "Epoch 1405/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6800591360.0000 - val_loss: 8038748160.0000\n",
      "Epoch 1406/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6595313152.0000 - val_loss: 7921300992.0000\n",
      "Epoch 1407/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6588689408.0000 - val_loss: 7901628416.0000\n",
      "Epoch 1408/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6620470272.0000 - val_loss: 7879639040.0000\n",
      "Epoch 1409/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6649115136.0000 - val_loss: 8149693952.0000\n",
      "Epoch 1410/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7019081728.0000 - val_loss: 7843020288.0000\n",
      "Epoch 1411/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6677566976.0000 - val_loss: 7895151104.0000\n",
      "Epoch 1412/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6733138944.0000 - val_loss: 8147131392.0000\n",
      "Epoch 1413/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6765032960.0000 - val_loss: 7995748864.0000\n",
      "Epoch 1414/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6725103616.0000 - val_loss: 7906949632.0000\n",
      "Epoch 1415/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6561634816.0000 - val_loss: 9129226240.0000\n",
      "Epoch 1416/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7049588736.0000 - val_loss: 8053635072.0000\n",
      "Epoch 1417/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6966467584.0000 - val_loss: 8385168384.0000\n",
      "Epoch 1418/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6647670272.0000 - val_loss: 7936721920.0000\n",
      "Epoch 1419/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6863510016.0000 - val_loss: 7897560576.0000\n",
      "Epoch 1420/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6811298304.0000 - val_loss: 9235846144.0000\n",
      "Epoch 1421/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7051771392.0000 - val_loss: 8656820224.0000\n",
      "Epoch 1422/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7405412352.0000 - val_loss: 7885284864.0000\n",
      "Epoch 1423/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7411454976.0000 - val_loss: 8287931392.0000\n",
      "Epoch 1424/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6976005632.0000 - val_loss: 11527260160.0000\n",
      "Epoch 1425/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8393834496.0000 - val_loss: 8270187520.0000\n",
      "Epoch 1426/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7018843648.0000 - val_loss: 7849431040.0000\n",
      "Epoch 1427/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6805157888.0000 - val_loss: 7960928256.0000\n",
      "Epoch 1428/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6691549696.0000 - val_loss: 8080737792.0000\n",
      "Epoch 1429/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6777405440.0000 - val_loss: 9359713280.0000\n",
      "Epoch 1430/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7288217600.0000 - val_loss: 8616934400.0000\n",
      "Epoch 1431/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7053060608.0000 - val_loss: 8401232384.0000\n",
      "Epoch 1432/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7428017664.0000 - val_loss: 9421017088.0000\n",
      "Epoch 1433/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7397056512.0000 - val_loss: 7935700480.0000\n",
      "Epoch 1434/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6845198848.0000 - val_loss: 7993093120.0000\n",
      "Epoch 1435/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6874836992.0000 - val_loss: 7900815360.0000\n",
      "Epoch 1436/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6764277248.0000 - val_loss: 7850348032.0000\n",
      "Epoch 1437/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6826951680.0000 - val_loss: 8570176000.0000\n",
      "Epoch 1438/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7015313920.0000 - val_loss: 8029369856.0000\n",
      "Epoch 1439/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6681402880.0000 - val_loss: 9311430656.0000\n",
      "Epoch 1440/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7405617664.0000 - val_loss: 8356760576.0000\n",
      "Epoch 1441/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7130145792.0000 - val_loss: 8099358720.0000\n",
      "Epoch 1442/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7263750656.0000 - val_loss: 8152183296.0000\n",
      "Epoch 1443/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6771976704.0000 - val_loss: 7838099456.0000\n",
      "Epoch 1444/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6587147776.0000 - val_loss: 7916121600.0000\n",
      "Epoch 1445/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6732834304.0000 - val_loss: 8255739904.0000\n",
      "Epoch 1446/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7303682560.0000 - val_loss: 7885203968.0000\n",
      "Epoch 1447/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7102986752.0000 - val_loss: 8134236160.0000\n",
      "Epoch 1448/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7101699072.0000 - val_loss: 8505415680.0000\n",
      "Epoch 1449/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6953826304.0000 - val_loss: 7873952768.0000\n",
      "Epoch 1450/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6552463872.0000 - val_loss: 7937670144.0000\n",
      "Epoch 1451/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6549207552.0000 - val_loss: 7961537536.0000\n",
      "Epoch 1452/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6819147264.0000 - val_loss: 8107164672.0000\n",
      "Epoch 1453/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6563054080.0000 - val_loss: 8459687424.0000\n",
      "Epoch 1454/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6988085248.0000 - val_loss: 8226978816.0000\n",
      "Epoch 1455/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6880460288.0000 - val_loss: 7857378816.0000\n",
      "Epoch 1456/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6985081344.0000 - val_loss: 8062538240.0000\n",
      "Epoch 1457/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7025630208.0000 - val_loss: 8051447296.0000\n",
      "Epoch 1458/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6747911680.0000 - val_loss: 8053689856.0000\n",
      "Epoch 1459/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6723144704.0000 - val_loss: 8275540480.0000\n",
      "Epoch 1460/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7039683072.0000 - val_loss: 7988196864.0000\n",
      "Epoch 1461/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6958849024.0000 - val_loss: 8114201088.0000\n",
      "Epoch 1462/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6818840064.0000 - val_loss: 7900913152.0000\n",
      "Epoch 1463/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7122492416.0000 - val_loss: 7861413376.0000\n",
      "Epoch 1464/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6986530816.0000 - val_loss: 7911216640.0000\n",
      "Epoch 1465/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6461497344.0000 - val_loss: 8049119232.0000\n",
      "Epoch 1466/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6847078912.0000 - val_loss: 8488013312.0000\n",
      "Epoch 1467/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6914411520.0000 - val_loss: 7939821568.0000\n",
      "Epoch 1468/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6583937536.0000 - val_loss: 7893818368.0000\n",
      "Epoch 1469/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6843599872.0000 - val_loss: 8758255616.0000\n",
      "Epoch 1470/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6940079616.0000 - val_loss: 7895550976.0000\n",
      "Epoch 1471/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6708005376.0000 - val_loss: 7899862016.0000\n",
      "Epoch 1472/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6710382592.0000 - val_loss: 8905243648.0000\n",
      "Epoch 1473/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7255339520.0000 - val_loss: 9223653376.0000\n",
      "Epoch 1474/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7323720704.0000 - val_loss: 8192250880.0000\n",
      "Epoch 1475/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7395507712.0000 - val_loss: 7848384000.0000\n",
      "Epoch 1476/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7109899264.0000 - val_loss: 7885951488.0000\n",
      "Epoch 1477/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6858472960.0000 - val_loss: 7860002304.0000\n",
      "Epoch 1478/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6686433792.0000 - val_loss: 7871126016.0000\n",
      "Epoch 1479/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6836236800.0000 - val_loss: 8206605824.0000\n",
      "Epoch 1480/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6716692992.0000 - val_loss: 7866993664.0000\n",
      "Epoch 1481/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6721103360.0000 - val_loss: 7990586368.0000\n",
      "Epoch 1482/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6859101184.0000 - val_loss: 7837687296.0000\n",
      "Epoch 1483/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6785971200.0000 - val_loss: 7869922304.0000\n",
      "Epoch 1484/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6609742336.0000 - val_loss: 8393958400.0000\n",
      "Epoch 1485/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7095141376.0000 - val_loss: 8051150848.0000\n",
      "Epoch 1486/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7094173696.0000 - val_loss: 8089427456.0000\n",
      "Epoch 1487/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6984451584.0000 - val_loss: 8130884608.0000\n",
      "Epoch 1488/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6756198912.0000 - val_loss: 7998786048.0000\n",
      "Epoch 1489/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6796242944.0000 - val_loss: 8312316416.0000\n",
      "Epoch 1490/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6764385280.0000 - val_loss: 7947810304.0000\n",
      "Epoch 1491/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6836871168.0000 - val_loss: 8487455744.0000\n",
      "Epoch 1492/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6898877440.0000 - val_loss: 8007623168.0000\n",
      "Epoch 1493/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6663848448.0000 - val_loss: 8060277248.0000\n",
      "Epoch 1494/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6643145728.0000 - val_loss: 7899566080.0000\n",
      "Epoch 1495/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6779624960.0000 - val_loss: 7931440640.0000\n",
      "Epoch 1496/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6607652864.0000 - val_loss: 8537718784.0000\n",
      "Epoch 1497/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7102684160.0000 - val_loss: 8513094656.0000\n",
      "Epoch 1498/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6828690432.0000 - val_loss: 7836642816.0000\n",
      "Epoch 1499/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6508570624.0000 - val_loss: 8019732992.0000\n",
      "Epoch 1500/1500\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6640018432.0000 - val_loss: 8129214976.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train, validation_data=(x_test,y_test),batch_size=1218, epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8411974314460002"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,tahmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90162.16029215328"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,tahmin)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f=pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_f.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPUTER VISION WITH DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bing-image-downloader in /opt/anaconda3/lib/python3.12/site-packages (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bing-image-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bing_image_downloader import downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[%] Downloading Images to /Users/ahmetfarukizgordu/Desktop/Applied Data Science Bootcamp/Classes/Day9/dataset/bird\n",
      "\n",
      "\n",
      "[!!]Indexing page: 1\n",
      "\n",
      "[%] Indexed 95 Images on Page 1.\n",
      "\n",
      "===============================================\n",
      "\n",
      "[%] Downloading Image #1 from https://2.bp.blogspot.com/-g9STQqFQ9Ik/UScse2IifqI/AAAAAAAAA08/mh1immEtVZo/s1600/bluebird.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #2 from https://res.cloudinary.com/dk-find-out/image/upload/q_80,w_960,f_auto/DCTM_Penguin_UK_DK_AL526630_wkmzns.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #3 from https://www.lovethegarden.com/sites/default/files/content/articles/UK_wildbirds-01-robin.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #4 from http://hdqwalls.com/download/1/colorful-parrot-bird.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #5 from http://2.bp.blogspot.com/_LDF9z4ZzZHo/TQZI-CUPl2I/AAAAAAAAAfc/--DuSZRxywM/s1600/bird_1008.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #6 from https://www.gannett-cdn.com/-mm-/8e8c5aba0971002d1dd2467d975c43feb1ab2740/c=0-117-2250-1383/local/-/media/Springfield/2015/01/27/B9315970364Z.1_20150127190439_000_GH69ORKP1.1-0.jpg?width=3200&amp;height=1680&amp;fit=crop\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #7 from http://www.audubon.org/sites/default/files/styles/hero_cover_bird_page/public/Northern Mockingbird w27-10-007_V.jpg?itok=8Xt1zpQH\n",
      "[!] Issue getting: http://www.audubon.org/sites/default/files/styles/hero_cover_bird_page/public/Northern Mockingbird w27-10-007_V.jpg?itok=8Xt1zpQH\n",
      "[!] Error:: URL can't contain control characters. '/sites/default/files/styles/hero_cover_bird_page/public/Northern Mockingbird w27-10-007_V.jpg?itok=8Xt1zpQH' (found at least ' ')\n",
      "[%] Downloading Image #7 from http://4.bp.blogspot.com/_LDF9z4ZzZHo/TQZPzB2h_TI/AAAAAAAAAkA/tMyV8AJvBGI/s1600/Webshots_59014.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #8 from https://wallup.net/wp-content/uploads/2018/10/07/766927-warbler-bird-birds-nature-wildlife.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #9 from https://static.scientificamerican.com/sciam/cache/file/7A715AD8-449D-4B5A-ABA2C5D92D9B5A21_source.png\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #10 from http://www.australianwildlifejourneys.com/files/504_rainbowlorikeetvic.large.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #11 from https://www.australiangeographic.com.au/wp-content/uploads/2020/12/E1R8HC-scaled.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #12 from https://i.stack.imgur.com/VI6ve.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #13 from http://trevorhampel.com/wp-content/uploads/2013/08/IMG_0870-1600x1200.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #14 from http://4.bp.blogspot.com/-qOOra0Nr3-s/UNGhHiJilbI/AAAAAAAAIfg/myq1EyZ2gII/s1600/Australian+Magpie+2012_12_18+Victor+Harbour+Wetlands+01.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #15 from https://c.pxhere.com/photos/93/5f/kookaburra_australia_australianbirds_flickrsbestcreatures_publicdomaindedicationcc0-174963.jpg!d\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #16 from http://www.australianwildlifejourneys.com/files/429_dreamstime_xl_60283319.large.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #17 from https://images.squarespace-cdn.com/content/v1/587d6250d482e9eee8c47666/1609557580378-SM6G65VOV8P1B425ESM3/1D3F1580.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #18 from https://images.theconversation.com/files/3983/original/100_3311_Regent_Honeyeater.jpg?ixlib=rb-1.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=1130&amp;fit=crop&amp;dpr=2\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #19 from https://4.bp.blogspot.com/_66SXEMFIQQI/S7H0qxx9dtI/AAAAAAAAAAc/Urm4UGqNNEU/s1600/Galah_20070222_014.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #20 from https://usercontent2.hubstatic.com/4804439_f520.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #21 from https://www.worldatlas.com/r/w1200/upload/b3/e1/b4/shutterstock-457706305.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #22 from https://i.pinimg.com/736x/b0/a1/e8/b0a1e8b11f103b93033c50262f891c5f.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #23 from https://tntribune.com/wp-content/uploads/2020/12/thumbnail_IMG_7916.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #24 from https://www.animalspot.net/wp-content/uploads/2023/08/Birds-of-Australia.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #25 from http://3.bp.blogspot.com/_BSNlnDNEj_o/TP71dTuIKqI/AAAAAAAAADU/6DY6Yo2itEA/s1600/IMGP4911.JPG\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #26 from https://photographsofaustralia.com/wp-content/uploads/2020/10/Pacific_baza_MG_9988-2560x2192.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #27 from https://au.newhollandpublishers.com/pub/media/catalog/product/cache/32c3db8536f26a5ade98b0e2d5530502/u/r/urban_birds_working_cover.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #28 from https://www.petsmagazine.com.au/wp-content/uploads/2016/11/Budgerigar-Australian-bird.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #29 from https://i.pinimg.com/originals/d9/29/81/d92981864f638c43602e4e18166742b1.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #30 from https://mikelentzphotography.com/wp-content/uploads/2017/04/Ferruginous-Hawk-SLIDESHOW.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #31 from http://www.zastavki.com/pictures/1920x1200/2011/Animals_Birds_Birds_of_Prey_029766_.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #32 from http://countryasides.files.wordpress.com/2010/07/birds-of-prey.jpg\n",
      "[Error]Invalid image, not saving http://countryasides.files.wordpress.com/2010/07/birds-of-prey.jpg\n",
      "\n",
      "[!] Issue getting: http://countryasides.files.wordpress.com/2010/07/birds-of-prey.jpg\n",
      "[!] Error:: Invalid image, not saving http://countryasides.files.wordpress.com/2010/07/birds-of-prey.jpg\n",
      "\n",
      "[%] Downloading Image #32 from http://www.aboutbritain.com/images/attraction/big/international-centre-for-birds-of-prey-0832.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #33 from https://keyassets.timeincuk.net/inspirewp/live/wp-content/uploads/sites/8/2017/03/BF2GG8-1620x1078.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #34 from https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Birds_of_Prey_Diversity.jpg/1200px-Birds_of_Prey_Diversity.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #35 from https://i0.wp.com/birdwatchinghq.com/wp-content/uploads/2021/02/common-birds-of-prey-scaled.jpg\n",
      "[!] Issue getting: https://i0.wp.com/birdwatchinghq.com/wp-content/uploads/2021/02/common-birds-of-prey-scaled.jpg\n",
      "[!] Error:: HTTP Error 404: Not Found\n",
      "[%] Downloading Image #35 from https://cdn.naturettl.com/wp-content/uploads/2019/07/27062027/photograph-birds-of-prey-7.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #36 from https://www.publicdomainpictures.net/pictures/10000/velka/947-1264707128oSD4.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #37 from https://2.bp.blogspot.com/-dWNDdERz_OQ/T3RddbF11pI/AAAAAAAAHrw/R2k9_b6RD38/s1600/birds+of+prey+048e.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #38 from https://preview.redd.it/w6yogn2mgbmz.jpg?auto=webp&amp;s=2363c5b17e6952ecd1c16caf7d30796028359d21\n",
      "[Error]Invalid image, not saving https://preview.redd.it/w6yogn2mgbmz.jpg?auto=webp&amp;s=2363c5b17e6952ecd1c16caf7d30796028359d21\n",
      "\n",
      "[!] Issue getting: https://preview.redd.it/w6yogn2mgbmz.jpg?auto=webp&amp;s=2363c5b17e6952ecd1c16caf7d30796028359d21\n",
      "[!] Error:: Invalid image, not saving https://preview.redd.it/w6yogn2mgbmz.jpg?auto=webp&amp;s=2363c5b17e6952ecd1c16caf7d30796028359d21\n",
      "\n",
      "[%] Downloading Image #38 from https://4.bp.blogspot.com/-7aDSgAUyGH4/U0LAqXiQk8I/AAAAAAAADfg/8qyrYx2GYS4/s1600/sc+ch+18.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #39 from http://1.bp.blogspot.com/-flq9HR41PNo/TgnpFnLFilI/AAAAAAAABak/76rGKuef2nM/s640/Birds+Of+Prey.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #40 from http://deanwebleyphotography.co.uk/wp-content/uploads/2015/04/White-Bird-Of-Prey-With-Spread-Wings-The-International-Center-For-Birds-Of-Prey-Newent.jpg\n",
      "[!] Issue getting: http://deanwebleyphotography.co.uk/wp-content/uploads/2015/04/White-Bird-Of-Prey-With-Spread-Wings-The-International-Center-For-Birds-Of-Prey-Newent.jpg\n",
      "[!] Error:: HTTP Error 404: Not Found\n",
      "[%] Downloading Image #40 from http://www.lovethegarden.com/sites/default/files/content/articles/UK_birds-of-prey-sparrowhawk.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #41 from https://res.cloudinary.com/dk-find-out/image/upload/q_80,w_1920,f_auto/DCTM_Penguin_UK_DK_AL509900_x6xrny.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #42 from https://www.southernliving.com/thmb/r0UJ_Z0Vx7gWzgndWJFjcNL2Y8c=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/gettyimages-582179417-2000-bc657558a4aa4360a80c2743a5a459fd.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #43 from https://www.birdsandblooms.com/wp-content/uploads/2013/10/BNBbyc17_carol-spry-1.jpg?fit=680\n",
      "[!] Issue getting: https://www.birdsandblooms.com/wp-content/uploads/2013/10/BNBbyc17_carol-spry-1.jpg?fit=680\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[%] Downloading Image #43 from https://www.lovethegarden.com/sites/default/files/content/articles/UK_birds-of-prey-red-kite.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #44 from http://data.1freewallpapers.com/download/bird-of-prey.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #45 from https://2.bp.blogspot.com/-y1GOF1Q9BUc/UsF27ED2LnI/AAAAAAACCgk/oOuRq50yq1s/s1600/Common%2BKingfisher%2BFB%2B3049-704256.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #46 from https://4.bp.blogspot.com/-4xOKk8v6A8o/T_6QzOmXnzI/AAAAAAAAAJo/cDwpjero4us/s1600/untitled+(1+of+1)-3.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #47 from https://4.bp.blogspot.com/-QqsOeTyT9o8/T_6O9_yNYWI/AAAAAAAAAJQ/ievh0G-uSPg/s1600/2.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #48 from http://www.wildnest.in/wp-content/uploads/2015/06/red-headed-trogaon.jpg\n",
      "[Error]Invalid image, not saving http://www.wildnest.in/wp-content/uploads/2015/06/red-headed-trogaon.jpg\n",
      "\n",
      "[!] Issue getting: http://www.wildnest.in/wp-content/uploads/2015/06/red-headed-trogaon.jpg\n",
      "[!] Error:: Invalid image, not saving http://www.wildnest.in/wp-content/uploads/2015/06/red-headed-trogaon.jpg\n",
      "\n",
      "[%] Downloading Image #48 from http://2.bp.blogspot.com/-Knx1jELJq9o/T_6PfF2jkkI/AAAAAAAAAJg/hPcHgHYhZUs/s1600/peacock-bird-wallpaper.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #49 from https://i.redd.it/8puk5e8uect31.jpg\n",
      "[Error]Invalid image, not saving https://i.redd.it/8puk5e8uect31.jpg\n",
      "\n",
      "[!] Issue getting: https://i.redd.it/8puk5e8uect31.jpg\n",
      "[!] Error:: Invalid image, not saving https://i.redd.it/8puk5e8uect31.jpg\n",
      "\n",
      "[%] Downloading Image #49 from https://i.ytimg.com/vi/po059V_SYog/maxresdefault.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #50 from https://i.pinimg.com/736x/af/ed/0d/afed0de128015a74d759e551de149b49--the-festival-the-indians.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #51 from https://www.india-a2z.com/images/peacock-eyes.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #52 from http://4.bp.blogspot.com/_rDtcVgvGrqs/S_P2QWyJtaI/AAAAAAAAGpY/4oF7V1tawbA/s1600/5715+Indian+Roller+Jan+23,+2010+WP-789896.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #53 from https://bubobirding.com/wp-content/uploads/2020/03/Indian-Roller_200803236414E.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #54 from https://i.pinimg.com/originals/33/6b/f3/336bf3141c0164c22ffca1c3035a91ff.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #55 from https://webneel.com/daily/sites/default/files/images/daily/12-2013/48-bird-incredible-india.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #56 from http://3.bp.blogspot.com/-xI5viDwKYSU/ToGjAHWhhbI/AAAAAAAAAPs/1ia_a8PIdBE/s1600/National+Bird+of+India.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #57 from http://wildtrails.in/wp-content/uploads/2015/08/HornBillDandeli.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #58 from https://www.insideindianjungles.com/wp-content/uploads/2019/07/indian-birds-2.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #59 from https://www.omlet.co.uk/images/originals/parrots-the-different-types-of-parrot-large-five-talking-bird-species-to-consider-indian-ringneck-parrot-534042165-5b4bea3ec9e77c00370044a6_62bd7d5a.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #60 from https://a-z-animals.com/media/2023/01/shutterstock_1147396844.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #61 from https://bubobirding.com/wp-content/uploads/2019/11/Jungle-Babbler_20161010_0343.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #62 from https://ichef.bbci.co.uk/news/976/cpsprodpb/FB9E/production/_110941446_gettyimages-973115596-594x594.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #63 from https://insider.si.edu/wp-content/uploads/2017/04/SCTA-copy.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #64 from https://i.pinimg.com/originals/e2/d8/ca/e2d8ca85cd5174ff9f22f1685d525236.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #65 from http://upload.wikimedia.org/wikipedia/commons/2/24/Yellow_bird.JPG\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #66 from https://www.allaboutbirds.org/news/wp-content/uploads/2020/04/RBGull-Vyn-FI-1280x720.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #67 from https://c.pxhere.com/photos/68/e9/wild_turkey_male_bird_close_up_portrait_gobbler_thanksgiving_wildlife-1228633.jpg!d\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #68 from https://images.twinkl.co.uk/tw1n/image/private/t_630/u/ux/chafinch-flying-flight-bird-animal-ks1_ver_1.png\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #69 from http://upload.wikimedia.org/wikipedia/commons/9/9d/Bird_in_flight_wings_spread.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #70 from https://cdn.download.ams.birds.cornell.edu/api/v1/asset/202984001/1200\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #71 from https://2.bp.blogspot.com/-XrVLYVWXtw4/ThQq8jEt7KI/AAAAAAAAE8k/okJXwPLpknU/s1600/australian-parrots-pair-wallpaper.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #72 from https://res.cloudinary.com/dk-find-out/image/upload/q_80,w_1440,f_auto/DCTM_Penguin_UK_DK_AL520967_o5r5lz.png\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #73 from https://i.ytimg.com/vi/L0-JgcckxxM/maxresdefault.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #74 from https://i.pinimg.com/originals/cb/13/cc/cb13ccae547a8a5519acf9578ba6f0bd.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #75 from http://www.fllt.org/wp-content/uploads/2015/09/Wild-Turkeys_Read1.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #76 from https://cdn.britannica.com/83/96583-050-89E61044/turkeys-Texas.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #77 from https://i.natgeofe.com/n/a189dd67-bc78-4716-aa29-cdbaceb5e4d0/photo-ark-parrots-endangered-bird-world-intelligence-3_3x2.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #78 from https://i.ytimg.com/vi/YTR21os8gTA/maxresdefault.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #79 from https://media.audubon.org/aud_apa-2021_wild-turkey_a1_16368-3_ts_photo-melissa-james.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #80 from https://get.pxhere.com/photo/sea-bird-seabird-wildlife-gull-beak-fauna-puffin-ornithology-australia-birds-vertebrate-albatross-south-australia-charadriiformes-pacific-gull-621887.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #81 from https://www.activewild.com/wp-content/uploads/2021/06/What-is-a-bird.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #82 from https://bipbap.ru/wp-content/uploads/2017/08/6-1.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #83 from https://www.pbs.org/wnet/nature/files/2021/07/william-stark-g_eUvcUypDY-unsplash-scaled.jpg\n",
      "[!] Issue getting: https://www.pbs.org/wnet/nature/files/2021/07/william-stark-g_eUvcUypDY-unsplash-scaled.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[%] Downloading Image #83 from https://good-nature-blog-uploads.s3.amazonaws.com/uploads/2017/11/1-wild-turkey-CROP_Web.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #84 from https://www.activewild.com/wp-content/uploads/2022/02/Is-A-Bird-A-Mammal-Infographic.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #85 from https://merriam-webster.com/assets/ld/images/legacy_print_images/C9.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #86 from https://pup-assets.imgix.net/onix/images/9780691200163.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "\n",
      "\n",
      "[!!]Indexing page: 2\n",
      "\n",
      "[%] Indexed 95 Images on Page 2.\n",
      "\n",
      "===============================================\n",
      "\n",
      "[%] Downloading Image #87 from http://upload.wikimedia.org/wikipedia/commons/e/e6/Masked_Lovebird_(Agapornis_personata)_-Auckland_Zoo.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #88 from https://www.thesprucepets.com/thmb/Agf-EFUEF6Qh1YhgQ66hXqDoT1E=/2121x1414/filters:no_upscale():max_bytes(150000):strip_icc()/RainbowLorikeets-GettyImages-739246151-59ba9529b501e800140d7cfe.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #89 from https://www.hdwallpapers.in/download/saffron_finch_yellow_bird_is_sitting_on_purple_flower_4k_hd_birds-HD.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #90 from https://carolinabirds.org/People/Morffew_LG/Bluebird,_Eastern_Andy_Morffew.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #91 from https://images.pexels.com/photos/110812/pexels-photo-110812.jpeg?cs=srgb&amp;dl=birds-macro-branch-110812.jpg&amp;fm=jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #92 from https://4.bp.blogspot.com/-ZHtv88LI3xY/V8AcRofrX2I/AAAAAAAAAIQ/6NXulcRccdk_dq_qtsKPp9Yinn5YgRU8wCLcB/s1600/Pet+Birds+Australia+-+An+Introduction+to+Rosellas.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #93 from https://2.bp.blogspot.com/-xvZ-e0Ox_P8/Ufi0YZkTUGI/AAAAAAAABeo/fm8fH9TQalg/s1600/IMG_0870.JPG\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #94 from https://www.australiananimallearningzone.com/wp-content/uploads/2012/03/Rainbow-Lorikeet.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #95 from https://i.ytimg.com/vi/JY2E1R6jo6k/maxresdefault.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #96 from https://www.trevorsbirding.com/wp-content/uploads/2017/02/Cleland-Wildlife-Park_20060908_091.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #97 from https://images.squarespace-cdn.com/content/v1/587d6250d482e9eee8c47666/1609628325004-BQ6DGQL8QNGD7GNJJOK9/1D3F5673.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #98 from https://www.nespthreatenedspecies.edu.au/media/avjlnbqz/eastern_yellow_robin_graham-winterflood-cc-by-sa-2-0_w.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #99 from https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Cracticus_tibicen_hypoleuca_male_domain.jpg/1200px-Cracticus_tibicen_hypoleuca_male_domain.jpg\n",
      "[Error]Invalid image, not saving https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Cracticus_tibicen_hypoleuca_male_domain.jpg/1200px-Cracticus_tibicen_hypoleuca_male_domain.jpg\n",
      "\n",
      "[!] Issue getting: https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Cracticus_tibicen_hypoleuca_male_domain.jpg/1200px-Cracticus_tibicen_hypoleuca_male_domain.jpg\n",
      "[!] Error:: Invalid image, not saving https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Cracticus_tibicen_hypoleuca_male_domain.jpg/1200px-Cracticus_tibicen_hypoleuca_male_domain.jpg\n",
      "\n",
      "[%] Downloading Image #99 from http://www.survival.org.au/images/birds/masked_lapwing_big.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "[%] Downloading Image #100 from http://livingjunglepetshop.com.au/wp-content/uploads/2014/11/Eastern-Rosella-Parrot-Parakeet.jpg\n",
      "[%] File Downloaded !\n",
      "\n",
      "\n",
      "\n",
      "[%] Done. Downloaded 100 images.\n"
     ]
    }
   ],
   "source": [
    "downloader.download('bird',limit=100, adult_filter_off=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.mnist #el yazması rakamları tanıma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels),(test_images, test_labels)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[10000],cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[54],cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images/255.0\n",
    "test_images=test_images/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[54],cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Neural Network - CNNs - Image Classification (resim sınıflandırma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, InputLayer, Reshape, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(28,28)))\n",
    "model.add(Reshape(target_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10)) #10 farklı cevap (classification rakamları 0-9 olanlar)\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.5391 - val_accuracy: 0.9715 - val_loss: 0.1136\n",
      "Epoch 2/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.1266 - val_accuracy: 0.9758 - val_loss: 0.0908\n",
      "Epoch 3/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9751 - loss: 0.0888 - val_accuracy: 0.9805 - val_loss: 0.0721\n",
      "Epoch 4/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0719 - val_accuracy: 0.9825 - val_loss: 0.0658\n",
      "Epoch 5/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0617 - val_accuracy: 0.9813 - val_loss: 0.0674\n",
      "Epoch 6/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0513 - val_accuracy: 0.9835 - val_loss: 0.0597\n",
      "Epoch 7/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9857 - loss: 0.0470 - val_accuracy: 0.9813 - val_loss: 0.0620\n",
      "Epoch 8/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9874 - loss: 0.0427 - val_accuracy: 0.9840 - val_loss: 0.0601\n",
      "Epoch 9/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0405 - val_accuracy: 0.9838 - val_loss: 0.0586\n",
      "Epoch 10/10\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0340 - val_accuracy: 0.9853 - val_loss: 0.0545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x171fabb00>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,validation_split=.10,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.9784 - loss: 0.0702\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821000099182129"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('mymodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning başarı oranını arttırma yöntemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer sayısını ekleyerek\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(28,28)))\n",
    "model.add(Reshape(target_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(60)) #layer eklendi\n",
    "model.add(Dense(10)) \n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neuron sayısını ekleyerek\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(28,28)))\n",
    "model.add(Reshape(target_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(80)) #Neuron arttırıldı\n",
    "model.add(Dense(10)) \n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout layer eklenmesi ile overfitting engellenerek daha iyi öğrenmeyi sağlar\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(28,28)))\n",
    "model.add(Reshape(target_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(60))\n",
    "model.add(dropout(.25)) #with import Dropout\n",
    "model.add(Dense(10)) \n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batchnormalization\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(28,28)))\n",
    "model.add(Reshape(target_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters=12,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.app(BatchNormalization())\n",
    "model.add(Dense(60)) \n",
    "model.add(dropout(.25)) \n",
    "model.add(Dense(10)) #10 farklı cevap (classification rakamları 0-9 olanlar)\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
